{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNASOCopmJmW3pRky55+f1q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iampro3/deep-learning/blob/main/EarlyStopping_0807.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Early Stopping\n",
        "- 영상주소 : https://www.youtube.com/watch?v=5vzHujmhr14\n",
        "- github 주소 :https://github.com/NoCodeProgram/deepLearning/blob/main/nn/early_stopping.ipynb"
      ],
      "metadata": {
        "id": "38oFW75dXXly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Early stopping : Validation metrix이 더 이상 좋아지지 않는다면 그 때 학습을 멈춘다.\n",
        "  + Validation loss 값\n",
        "  + Accuracy\n",
        "  + Precision\n",
        "  + IoU : Intersection over Union (Computer vision problem)"
      ],
      "metadata": {
        "id": "Jq-Lwq4uchUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Computer vision : IoU\n",
        "  + 관련 블로그 : https://ballentain.tistory.com/12"
      ],
      "metadata": {
        "id": "XZlsNVDNdy0I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h25BGu3gXXQw",
        "outputId": "3e3a36c0-2043-4e0d-d3e1-75bbd476c234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepLearning'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 100 (delta 25), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (100/100), 3.90 MiB | 2.82 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NoCodeProgram/deepLearning.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Load the DataFrame from a CSV file\n",
        "df = pd.read_csv('./deepLearning/nn/swirl.csv')\n",
        "data = df[['x', 'y']].values\n",
        "labels = df['label'].values.reshape(-1, 1)\n",
        "\n",
        "# Print the shapes of the data and labels\n",
        "print('Data shape:', data.shape)\n",
        "print('Labels shape:', labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8N9bSddXpBt",
        "outputId": "b01e3469-80da-4b2a-c5d8-6f9e496be47d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (280, 2)\n",
            "Labels shape: (280, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(data[:,0], data[:,1], c=labels, cmap='viridis')\n",
        "# plt.scatter(val_data[:,0], val_data[:,1], c=val_labels, cmap='viridis')\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title('2D Synthetic Data')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "AkaFSLXeXqol",
        "outputId": "10ad8624-d2d4-4d0c-9e46-feac6c4d3658"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert the numpy arrays to PyTorch tensors\n",
        "data_torch = torch.tensor(data, dtype=torch.float32)\n",
        "labels_torch = torch.tensor(labels, dtype=torch.float32)\n",
        "data_length = len(data_torch)\n",
        "split_length = int(0.7*data_length)\n",
        "\n",
        "train_data = data_torch[:split_length]\n",
        "train_labels = labels_torch[:split_length]\n",
        "val_data = data_torch[split_length:]\n",
        "val_labels = labels_torch[split_length:]\n",
        "\n",
        "print(train_data.shape, train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtYjpIBOXuVu",
        "outputId": "361cfc6b-cb21-41ed-b809-1e39e3c5f541"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([196, 2]) torch.Size([196, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "g = torch.Generator().manual_seed(42)\n",
        "g.manual_seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class DNet(nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
        "        super().__init__()\n",
        "        self.seq_model = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.seq_model(x)\n",
        "\n",
        "\n",
        "dnet = DNet(input_size=2,hidden_size=16,output_size=1)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(dnet.parameters(), lr=0.01)\n",
        "\n",
        "t_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# early stopping\n",
        "#min_val_loss : float = float('inf')\n",
        "#patience = int =100\n",
        "\n",
        "for steps in range(50000):\n",
        "    dnet.train()\n",
        "\n",
        "    output = dnet(train_data)\n",
        "    train_loss = loss_fn(output, train_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if steps % 10 == 0:\n",
        "        dnet.eval()\n",
        "        output = dnet(val_data)\n",
        "        val_loss = loss_fn(output, val_labels)\n",
        "        output = dnet(train_data)\n",
        "        t_loss = loss_fn(output,train_labels)\n",
        "\n",
        "        #if val_loss < min_val_loss:\n",
        "        #  min_val_loss = val_loss\n",
        "        #else:\n",
        "        #   break\n",
        "\n",
        "        t_losses.append(t_loss.item())\n",
        "        val_losses.append(val_loss.item())\n",
        "        print(f\"{steps} val_loss: {val_loss.item()}, train_loss: {t_loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hHBrVDcXwGM",
        "outputId": "ff75ffe4-06bb-44cc-b198-5db098926189"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 val_loss: 0.6986284852027893, train_loss: 0.6956262588500977\n",
            "10 val_loss: 0.6983290910720825, train_loss: 0.6954140067100525\n",
            "20 val_loss: 0.6980547308921814, train_loss: 0.6952260136604309\n",
            "30 val_loss: 0.6977909207344055, train_loss: 0.6950458884239197\n",
            "40 val_loss: 0.6975520253181458, train_loss: 0.6948809027671814\n",
            "50 val_loss: 0.6973202228546143, train_loss: 0.6947291493415833\n",
            "60 val_loss: 0.697106659412384, train_loss: 0.6945889592170715\n",
            "70 val_loss: 0.6969023942947388, train_loss: 0.694453775882721\n",
            "80 val_loss: 0.6967265605926514, train_loss: 0.6943432688713074\n",
            "90 val_loss: 0.6965711712837219, train_loss: 0.6942458748817444\n",
            "100 val_loss: 0.6963969469070435, train_loss: 0.6941355466842651\n",
            "110 val_loss: 0.6962149143218994, train_loss: 0.6940233707427979\n",
            "120 val_loss: 0.6960594654083252, train_loss: 0.6939280033111572\n",
            "130 val_loss: 0.6959155797958374, train_loss: 0.6938427686691284\n",
            "140 val_loss: 0.6957721710205078, train_loss: 0.6937555074691772\n",
            "150 val_loss: 0.6956433057785034, train_loss: 0.6936823725700378\n",
            "160 val_loss: 0.6955013871192932, train_loss: 0.6936026811599731\n",
            "170 val_loss: 0.6953889727592468, train_loss: 0.6935348510742188\n",
            "180 val_loss: 0.6952803134918213, train_loss: 0.693469226360321\n",
            "190 val_loss: 0.69517982006073, train_loss: 0.6934119462966919\n",
            "200 val_loss: 0.6950823664665222, train_loss: 0.6933532953262329\n",
            "210 val_loss: 0.6949751973152161, train_loss: 0.6932919025421143\n",
            "220 val_loss: 0.69487065076828, train_loss: 0.6932324767112732\n",
            "230 val_loss: 0.6947720646858215, train_loss: 0.6931775808334351\n",
            "240 val_loss: 0.6946943998336792, train_loss: 0.6931345462799072\n",
            "250 val_loss: 0.6946194767951965, train_loss: 0.6930895447731018\n",
            "260 val_loss: 0.6945284605026245, train_loss: 0.6930378675460815\n",
            "270 val_loss: 0.6944741606712341, train_loss: 0.6930104494094849\n",
            "280 val_loss: 0.6944040060043335, train_loss: 0.6929692029953003\n",
            "290 val_loss: 0.6943312883377075, train_loss: 0.6929247975349426\n",
            "300 val_loss: 0.6942589282989502, train_loss: 0.6928823590278625\n",
            "310 val_loss: 0.6941876411437988, train_loss: 0.6928337216377258\n",
            "320 val_loss: 0.6941277384757996, train_loss: 0.6927957534790039\n",
            "330 val_loss: 0.6940689086914062, train_loss: 0.6927617788314819\n",
            "340 val_loss: 0.6940001845359802, train_loss: 0.6927222609519958\n",
            "350 val_loss: 0.6939187049865723, train_loss: 0.6926761269569397\n",
            "360 val_loss: 0.6938657760620117, train_loss: 0.6926460266113281\n",
            "370 val_loss: 0.6938067674636841, train_loss: 0.6926131248474121\n",
            "380 val_loss: 0.6937628984451294, train_loss: 0.6925860047340393\n",
            "390 val_loss: 0.6937115788459778, train_loss: 0.6925578117370605\n",
            "400 val_loss: 0.6936749815940857, train_loss: 0.6925363540649414\n",
            "410 val_loss: 0.6936265826225281, train_loss: 0.6925041675567627\n",
            "420 val_loss: 0.6935722827911377, train_loss: 0.6924688220024109\n",
            "430 val_loss: 0.6935286521911621, train_loss: 0.6924422979354858\n",
            "440 val_loss: 0.6934770941734314, train_loss: 0.6924112439155579\n",
            "450 val_loss: 0.693449854850769, train_loss: 0.6923899054527283\n",
            "460 val_loss: 0.6934068202972412, train_loss: 0.6923577189445496\n",
            "470 val_loss: 0.6933644413948059, train_loss: 0.6923279762268066\n",
            "480 val_loss: 0.6933189630508423, train_loss: 0.6922937631607056\n",
            "490 val_loss: 0.6932847499847412, train_loss: 0.692267119884491\n",
            "500 val_loss: 0.6932587027549744, train_loss: 0.6922488212585449\n",
            "510 val_loss: 0.6932300329208374, train_loss: 0.6922233700752258\n",
            "520 val_loss: 0.6932108998298645, train_loss: 0.6922035813331604\n",
            "530 val_loss: 0.6931703686714172, train_loss: 0.6921713948249817\n",
            "540 val_loss: 0.6931414604187012, train_loss: 0.6921424865722656\n",
            "550 val_loss: 0.6931197047233582, train_loss: 0.6921223998069763\n",
            "560 val_loss: 0.6931114196777344, train_loss: 0.6921142339706421\n",
            "570 val_loss: 0.6930915117263794, train_loss: 0.692094624042511\n",
            "580 val_loss: 0.6930646300315857, train_loss: 0.6920781135559082\n",
            "590 val_loss: 0.6930290460586548, train_loss: 0.6920514106750488\n",
            "600 val_loss: 0.6930047273635864, train_loss: 0.6920269727706909\n",
            "610 val_loss: 0.6929905414581299, train_loss: 0.692016065120697\n",
            "620 val_loss: 0.6929685473442078, train_loss: 0.6920006275177002\n",
            "630 val_loss: 0.6929546594619751, train_loss: 0.6919843554496765\n",
            "640 val_loss: 0.6929338574409485, train_loss: 0.69196617603302\n",
            "650 val_loss: 0.6929119229316711, train_loss: 0.6919479370117188\n",
            "660 val_loss: 0.6928809285163879, train_loss: 0.6919263005256653\n",
            "670 val_loss: 0.6928688883781433, train_loss: 0.6919142007827759\n",
            "680 val_loss: 0.6928431391716003, train_loss: 0.6918858885765076\n",
            "690 val_loss: 0.6928246021270752, train_loss: 0.6918659806251526\n",
            "700 val_loss: 0.6927960515022278, train_loss: 0.6918368339538574\n",
            "710 val_loss: 0.692772388458252, train_loss: 0.6918141841888428\n",
            "720 val_loss: 0.692754864692688, train_loss: 0.6917931437492371\n",
            "730 val_loss: 0.6927343010902405, train_loss: 0.6917738914489746\n",
            "740 val_loss: 0.6927043199539185, train_loss: 0.6917462944984436\n",
            "750 val_loss: 0.6926810145378113, train_loss: 0.691724419593811\n",
            "760 val_loss: 0.6926583051681519, train_loss: 0.6917038559913635\n",
            "770 val_loss: 0.6926455497741699, train_loss: 0.6916879415512085\n",
            "780 val_loss: 0.6926204562187195, train_loss: 0.691663384437561\n",
            "790 val_loss: 0.6925875544548035, train_loss: 0.6916377544403076\n",
            "800 val_loss: 0.6925516724586487, train_loss: 0.6916096806526184\n",
            "810 val_loss: 0.6925328373908997, train_loss: 0.6915898323059082\n",
            "820 val_loss: 0.6925240755081177, train_loss: 0.6915761232376099\n",
            "830 val_loss: 0.6925129890441895, train_loss: 0.691560685634613\n",
            "840 val_loss: 0.6924923658370972, train_loss: 0.6915425062179565\n",
            "850 val_loss: 0.6924713253974915, train_loss: 0.6915239095687866\n",
            "860 val_loss: 0.6924647092819214, train_loss: 0.6915143728256226\n",
            "870 val_loss: 0.6924501061439514, train_loss: 0.691502571105957\n",
            "880 val_loss: 0.6924378275871277, train_loss: 0.6914892196655273\n",
            "890 val_loss: 0.6924242973327637, train_loss: 0.691473662853241\n",
            "900 val_loss: 0.6924055218696594, train_loss: 0.6914568543434143\n",
            "910 val_loss: 0.6923907399177551, train_loss: 0.6914370656013489\n",
            "920 val_loss: 0.6923718452453613, train_loss: 0.6914179921150208\n",
            "930 val_loss: 0.6923605799674988, train_loss: 0.6914018988609314\n",
            "940 val_loss: 0.6923428177833557, train_loss: 0.6913840770721436\n",
            "950 val_loss: 0.69233638048172, train_loss: 0.6913688778877258\n",
            "960 val_loss: 0.6923170685768127, train_loss: 0.6913579702377319\n",
            "970 val_loss: 0.6923031806945801, train_loss: 0.691340446472168\n",
            "980 val_loss: 0.6922918558120728, train_loss: 0.6913243532180786\n",
            "990 val_loss: 0.6922798752784729, train_loss: 0.6913047432899475\n",
            "1000 val_loss: 0.6922621726989746, train_loss: 0.6912891864776611\n",
            "1010 val_loss: 0.6922515630722046, train_loss: 0.6912767887115479\n",
            "1020 val_loss: 0.692236602306366, train_loss: 0.6912553906440735\n",
            "1030 val_loss: 0.6922106742858887, train_loss: 0.6912365555763245\n",
            "1040 val_loss: 0.692196786403656, train_loss: 0.691223680973053\n",
            "1050 val_loss: 0.6921780109405518, train_loss: 0.691209077835083\n",
            "1060 val_loss: 0.6921636462211609, train_loss: 0.6911952495574951\n",
            "1070 val_loss: 0.6921475529670715, train_loss: 0.6911788582801819\n",
            "1080 val_loss: 0.692138135433197, train_loss: 0.6911671161651611\n",
            "1090 val_loss: 0.692126989364624, train_loss: 0.6911517381668091\n",
            "1100 val_loss: 0.6921061277389526, train_loss: 0.6911298632621765\n",
            "1110 val_loss: 0.6920973658561707, train_loss: 0.6911160349845886\n",
            "1120 val_loss: 0.6920884251594543, train_loss: 0.6910987496376038\n",
            "1130 val_loss: 0.6920693516731262, train_loss: 0.6910814046859741\n",
            "1140 val_loss: 0.6920628547668457, train_loss: 0.691070556640625\n",
            "1150 val_loss: 0.6920500993728638, train_loss: 0.6910476088523865\n",
            "1160 val_loss: 0.692035973072052, train_loss: 0.6910330057144165\n",
            "1170 val_loss: 0.6920252442359924, train_loss: 0.6910179853439331\n",
            "1180 val_loss: 0.692014217376709, train_loss: 0.6909952759742737\n",
            "1190 val_loss: 0.6920028328895569, train_loss: 0.690974235534668\n",
            "1200 val_loss: 0.691985011100769, train_loss: 0.6909500956535339\n",
            "1210 val_loss: 0.6919748187065125, train_loss: 0.6909341812133789\n",
            "1220 val_loss: 0.6919649243354797, train_loss: 0.6909209489822388\n",
            "1230 val_loss: 0.6919493079185486, train_loss: 0.690900981426239\n",
            "1240 val_loss: 0.6919366121292114, train_loss: 0.6908848881721497\n",
            "1250 val_loss: 0.6919170618057251, train_loss: 0.6908597946166992\n",
            "1260 val_loss: 0.6919034123420715, train_loss: 0.6908416152000427\n",
            "1270 val_loss: 0.6918920874595642, train_loss: 0.6908226609230042\n",
            "1280 val_loss: 0.6918691396713257, train_loss: 0.6907974481582642\n",
            "1290 val_loss: 0.691851019859314, train_loss: 0.6907755136489868\n",
            "1300 val_loss: 0.6918357610702515, train_loss: 0.6907569169998169\n",
            "1310 val_loss: 0.6918166875839233, train_loss: 0.6907298564910889\n",
            "1320 val_loss: 0.6917960047721863, train_loss: 0.6907076835632324\n",
            "1330 val_loss: 0.6917681694030762, train_loss: 0.6906811594963074\n",
            "1340 val_loss: 0.6917561888694763, train_loss: 0.6906625628471375\n",
            "1350 val_loss: 0.6917446851730347, train_loss: 0.6906423568725586\n",
            "1360 val_loss: 0.6917272210121155, train_loss: 0.6906164288520813\n",
            "1370 val_loss: 0.6917071342468262, train_loss: 0.6905851364135742\n",
            "1380 val_loss: 0.6916916966438293, train_loss: 0.6905617117881775\n",
            "1390 val_loss: 0.6916722655296326, train_loss: 0.6905422806739807\n",
            "1400 val_loss: 0.6916539669036865, train_loss: 0.6905158758163452\n",
            "1410 val_loss: 0.6916287541389465, train_loss: 0.6904816627502441\n",
            "1420 val_loss: 0.6916197538375854, train_loss: 0.6904690861701965\n",
            "1430 val_loss: 0.6916008591651917, train_loss: 0.6904368996620178\n",
            "1440 val_loss: 0.6915706396102905, train_loss: 0.690406084060669\n",
            "1450 val_loss: 0.6915440559387207, train_loss: 0.6903727650642395\n",
            "1460 val_loss: 0.6915192604064941, train_loss: 0.6903389692306519\n",
            "1470 val_loss: 0.6915010213851929, train_loss: 0.6903132200241089\n",
            "1480 val_loss: 0.6914942860603333, train_loss: 0.690294086933136\n",
            "1490 val_loss: 0.6914767026901245, train_loss: 0.690266489982605\n",
            "1500 val_loss: 0.6914582252502441, train_loss: 0.6902462840080261\n",
            "1510 val_loss: 0.6914315819740295, train_loss: 0.6902155876159668\n",
            "1520 val_loss: 0.6914120316505432, train_loss: 0.6901884078979492\n",
            "1530 val_loss: 0.6913885474205017, train_loss: 0.6901596188545227\n",
            "1540 val_loss: 0.6913641095161438, train_loss: 0.6901273727416992\n",
            "1550 val_loss: 0.6913371682167053, train_loss: 0.6900994181632996\n",
            "1560 val_loss: 0.691315233707428, train_loss: 0.6900695562362671\n",
            "1570 val_loss: 0.691291332244873, train_loss: 0.6900436878204346\n",
            "1580 val_loss: 0.6912596821784973, train_loss: 0.6900078654289246\n",
            "1590 val_loss: 0.691237211227417, train_loss: 0.6899755597114563\n",
            "1600 val_loss: 0.6912055015563965, train_loss: 0.6899443864822388\n",
            "1610 val_loss: 0.6911784410476685, train_loss: 0.6899073719978333\n",
            "1620 val_loss: 0.6911572217941284, train_loss: 0.6898866891860962\n",
            "1630 val_loss: 0.6911341547966003, train_loss: 0.6898476481437683\n",
            "1640 val_loss: 0.6911120414733887, train_loss: 0.6898120045661926\n",
            "1650 val_loss: 0.6910912394523621, train_loss: 0.6897832751274109\n",
            "1660 val_loss: 0.691057562828064, train_loss: 0.6897420287132263\n",
            "1670 val_loss: 0.6910298466682434, train_loss: 0.6897000670433044\n",
            "1680 val_loss: 0.6909996867179871, train_loss: 0.6896557807922363\n",
            "1690 val_loss: 0.6909661293029785, train_loss: 0.6896102428436279\n",
            "1700 val_loss: 0.6909412145614624, train_loss: 0.6895844340324402\n",
            "1710 val_loss: 0.6909106373786926, train_loss: 0.6895481944084167\n",
            "1720 val_loss: 0.6908907294273376, train_loss: 0.6895187497138977\n",
            "1730 val_loss: 0.6908695697784424, train_loss: 0.6894800662994385\n",
            "1740 val_loss: 0.6908442378044128, train_loss: 0.6894469857215881\n",
            "1750 val_loss: 0.6908164024353027, train_loss: 0.6894097328186035\n",
            "1760 val_loss: 0.6907896995544434, train_loss: 0.6893748641014099\n",
            "1770 val_loss: 0.6907707452774048, train_loss: 0.6893438100814819\n",
            "1780 val_loss: 0.6907382011413574, train_loss: 0.6893020272254944\n",
            "1790 val_loss: 0.6907153129577637, train_loss: 0.6892654895782471\n",
            "1800 val_loss: 0.6906826496124268, train_loss: 0.6892293691635132\n",
            "1810 val_loss: 0.6906470060348511, train_loss: 0.6891822814941406\n",
            "1820 val_loss: 0.6906132698059082, train_loss: 0.6891390681266785\n",
            "1830 val_loss: 0.6905993223190308, train_loss: 0.6891100406646729\n",
            "1840 val_loss: 0.6905620694160461, train_loss: 0.6890645027160645\n",
            "1850 val_loss: 0.690530002117157, train_loss: 0.6890336871147156\n",
            "1860 val_loss: 0.6904925107955933, train_loss: 0.688995361328125\n",
            "1870 val_loss: 0.6904618740081787, train_loss: 0.6889564990997314\n",
            "1880 val_loss: 0.690432608127594, train_loss: 0.6889203786849976\n",
            "1890 val_loss: 0.6904022097587585, train_loss: 0.6888826489448547\n",
            "1900 val_loss: 0.6903749704360962, train_loss: 0.6888465285301208\n",
            "1910 val_loss: 0.6903313994407654, train_loss: 0.6887904405593872\n",
            "1920 val_loss: 0.6902897953987122, train_loss: 0.6887481212615967\n",
            "1930 val_loss: 0.6902663111686707, train_loss: 0.6887120008468628\n",
            "1940 val_loss: 0.6902338862419128, train_loss: 0.6886650323867798\n",
            "1950 val_loss: 0.6902016997337341, train_loss: 0.688618540763855\n",
            "1960 val_loss: 0.6901675462722778, train_loss: 0.6885796189308167\n",
            "1970 val_loss: 0.6901300549507141, train_loss: 0.6885260939598083\n",
            "1980 val_loss: 0.6900779008865356, train_loss: 0.6884570121765137\n",
            "1990 val_loss: 0.6900317072868347, train_loss: 0.6883980631828308\n",
            "2000 val_loss: 0.6899824142456055, train_loss: 0.6883436441421509\n",
            "2010 val_loss: 0.6899378895759583, train_loss: 0.6882898807525635\n",
            "2020 val_loss: 0.6898915767669678, train_loss: 0.6882399916648865\n",
            "2030 val_loss: 0.6898589134216309, train_loss: 0.6882005929946899\n",
            "2040 val_loss: 0.689827024936676, train_loss: 0.688157320022583\n",
            "2050 val_loss: 0.6897832751274109, train_loss: 0.6881065368652344\n",
            "2060 val_loss: 0.6897432804107666, train_loss: 0.6880567669868469\n",
            "2070 val_loss: 0.6897016167640686, train_loss: 0.6880044937133789\n",
            "2080 val_loss: 0.6896569728851318, train_loss: 0.6879496574401855\n",
            "2090 val_loss: 0.6896092891693115, train_loss: 0.687892735004425\n",
            "2100 val_loss: 0.689567506313324, train_loss: 0.6878302693367004\n",
            "2110 val_loss: 0.689513087272644, train_loss: 0.6877636909484863\n",
            "2120 val_loss: 0.6894795298576355, train_loss: 0.6877114176750183\n",
            "2130 val_loss: 0.6894404888153076, train_loss: 0.6876633167266846\n",
            "2140 val_loss: 0.6894068717956543, train_loss: 0.6876072883605957\n",
            "2150 val_loss: 0.6893587112426758, train_loss: 0.6875470280647278\n",
            "2160 val_loss: 0.6893230676651001, train_loss: 0.6874876022338867\n",
            "2170 val_loss: 0.689283549785614, train_loss: 0.6874299049377441\n",
            "2180 val_loss: 0.6892324090003967, train_loss: 0.6873714923858643\n",
            "2190 val_loss: 0.6891814470291138, train_loss: 0.6873156428337097\n",
            "2200 val_loss: 0.6891320943832397, train_loss: 0.6872421503067017\n",
            "2210 val_loss: 0.6890916228294373, train_loss: 0.6871821284294128\n",
            "2220 val_loss: 0.6890391111373901, train_loss: 0.6871195435523987\n",
            "2230 val_loss: 0.6889798045158386, train_loss: 0.6870407462120056\n",
            "2240 val_loss: 0.6889335513114929, train_loss: 0.6869825124740601\n",
            "2250 val_loss: 0.6888781189918518, train_loss: 0.6869052052497864\n",
            "2260 val_loss: 0.6888406872749329, train_loss: 0.6868475079536438\n",
            "2270 val_loss: 0.6887839436531067, train_loss: 0.6867831349372864\n",
            "2280 val_loss: 0.6887232661247253, train_loss: 0.6867133378982544\n",
            "2290 val_loss: 0.6886705756187439, train_loss: 0.6866413950920105\n",
            "2300 val_loss: 0.6886164546012878, train_loss: 0.6865735650062561\n",
            "2310 val_loss: 0.6885595917701721, train_loss: 0.6865034103393555\n",
            "2320 val_loss: 0.6885008811950684, train_loss: 0.6864328980445862\n",
            "2330 val_loss: 0.6884319186210632, train_loss: 0.6863550543785095\n",
            "2340 val_loss: 0.6883702874183655, train_loss: 0.6862836480140686\n",
            "2350 val_loss: 0.6883163452148438, train_loss: 0.6862116456031799\n",
            "2360 val_loss: 0.6882431507110596, train_loss: 0.6861280202865601\n",
            "2370 val_loss: 0.6881850957870483, train_loss: 0.6860668659210205\n",
            "2380 val_loss: 0.6881208419799805, train_loss: 0.6859868764877319\n",
            "2390 val_loss: 0.688056230545044, train_loss: 0.6859013438224792\n",
            "2400 val_loss: 0.6879954934120178, train_loss: 0.6858255863189697\n",
            "2410 val_loss: 0.6879355311393738, train_loss: 0.6857544183731079\n",
            "2420 val_loss: 0.6878758668899536, train_loss: 0.6856762766838074\n",
            "2430 val_loss: 0.6878027319908142, train_loss: 0.6855952143669128\n",
            "2440 val_loss: 0.6877303719520569, train_loss: 0.6855109333992004\n",
            "2450 val_loss: 0.6876537203788757, train_loss: 0.6854230165481567\n",
            "2460 val_loss: 0.6875802278518677, train_loss: 0.6853382587432861\n",
            "2470 val_loss: 0.687519907951355, train_loss: 0.6852595210075378\n",
            "2480 val_loss: 0.6874342560768127, train_loss: 0.6851677298545837\n",
            "2490 val_loss: 0.6873689889907837, train_loss: 0.685089111328125\n",
            "2500 val_loss: 0.6872941255569458, train_loss: 0.6849958300590515\n",
            "2510 val_loss: 0.687226414680481, train_loss: 0.6849293112754822\n",
            "2520 val_loss: 0.687158465385437, train_loss: 0.6848507523536682\n",
            "2530 val_loss: 0.6870914697647095, train_loss: 0.684775710105896\n",
            "2540 val_loss: 0.68702232837677, train_loss: 0.6846987009048462\n",
            "2550 val_loss: 0.6869368553161621, train_loss: 0.6846069097518921\n",
            "2560 val_loss: 0.6868725419044495, train_loss: 0.6845331192016602\n",
            "2570 val_loss: 0.6867983937263489, train_loss: 0.6844323873519897\n",
            "2580 val_loss: 0.6867097616195679, train_loss: 0.6843317151069641\n",
            "2590 val_loss: 0.6866271495819092, train_loss: 0.6842278242111206\n",
            "2600 val_loss: 0.6865618228912354, train_loss: 0.6841474175453186\n",
            "2610 val_loss: 0.6864835619926453, train_loss: 0.6840459108352661\n",
            "2620 val_loss: 0.686405599117279, train_loss: 0.6839485764503479\n",
            "2630 val_loss: 0.6863144040107727, train_loss: 0.6838546395301819\n",
            "2640 val_loss: 0.6862189769744873, train_loss: 0.683738112449646\n",
            "2650 val_loss: 0.6861370205879211, train_loss: 0.6836290955543518\n",
            "2660 val_loss: 0.6860566735267639, train_loss: 0.6835197806358337\n",
            "2670 val_loss: 0.6859830021858215, train_loss: 0.6834197044372559\n",
            "2680 val_loss: 0.685883104801178, train_loss: 0.6832966804504395\n",
            "2690 val_loss: 0.6857705116271973, train_loss: 0.6831598281860352\n",
            "2700 val_loss: 0.6856814622879028, train_loss: 0.6830533742904663\n",
            "2710 val_loss: 0.6855835914611816, train_loss: 0.6829412579536438\n",
            "2720 val_loss: 0.6854984760284424, train_loss: 0.682830274105072\n",
            "2730 val_loss: 0.6854039430618286, train_loss: 0.6827121376991272\n",
            "2740 val_loss: 0.6853195428848267, train_loss: 0.6826143264770508\n",
            "2750 val_loss: 0.6852256059646606, train_loss: 0.6825017929077148\n",
            "2760 val_loss: 0.6851385831832886, train_loss: 0.6823908090591431\n",
            "2770 val_loss: 0.6850272417068481, train_loss: 0.6822555065155029\n",
            "2780 val_loss: 0.6849246621131897, train_loss: 0.6821354627609253\n",
            "2790 val_loss: 0.6848269701004028, train_loss: 0.6820258498191833\n",
            "2800 val_loss: 0.6847351789474487, train_loss: 0.6819305419921875\n",
            "2810 val_loss: 0.6846374869346619, train_loss: 0.6818094253540039\n",
            "2820 val_loss: 0.6845418214797974, train_loss: 0.6816882491111755\n",
            "2830 val_loss: 0.6844455003738403, train_loss: 0.6815800070762634\n",
            "2840 val_loss: 0.6843363046646118, train_loss: 0.6814542412757874\n",
            "2850 val_loss: 0.684222400188446, train_loss: 0.6813235282897949\n",
            "2860 val_loss: 0.6841199994087219, train_loss: 0.6811996102333069\n",
            "2870 val_loss: 0.6840071678161621, train_loss: 0.6810632944107056\n",
            "2880 val_loss: 0.6838974356651306, train_loss: 0.6809218525886536\n",
            "2890 val_loss: 0.6837819218635559, train_loss: 0.6807770729064941\n",
            "2900 val_loss: 0.683653712272644, train_loss: 0.6806368231773376\n",
            "2910 val_loss: 0.6835419535636902, train_loss: 0.6805069446563721\n",
            "2920 val_loss: 0.6833987236022949, train_loss: 0.6803532242774963\n",
            "2930 val_loss: 0.6832836866378784, train_loss: 0.6802029609680176\n",
            "2940 val_loss: 0.6831606030464172, train_loss: 0.6800618767738342\n",
            "2950 val_loss: 0.6830234527587891, train_loss: 0.6799282431602478\n",
            "2960 val_loss: 0.6828960180282593, train_loss: 0.6797894835472107\n",
            "2970 val_loss: 0.6827737092971802, train_loss: 0.6796431541442871\n",
            "2980 val_loss: 0.682640016078949, train_loss: 0.679484486579895\n",
            "2990 val_loss: 0.6824880838394165, train_loss: 0.6793243885040283\n",
            "3000 val_loss: 0.6823662519454956, train_loss: 0.6791813969612122\n",
            "3010 val_loss: 0.6822304725646973, train_loss: 0.6790086627006531\n",
            "3020 val_loss: 0.6820862293243408, train_loss: 0.6788432002067566\n",
            "3030 val_loss: 0.6819292902946472, train_loss: 0.6786704659461975\n",
            "3040 val_loss: 0.6817913055419922, train_loss: 0.6785138249397278\n",
            "3050 val_loss: 0.6816429495811462, train_loss: 0.6783322095870972\n",
            "3060 val_loss: 0.6814658045768738, train_loss: 0.6781457662582397\n",
            "3070 val_loss: 0.6813236474990845, train_loss: 0.6779929399490356\n",
            "3080 val_loss: 0.6811804175376892, train_loss: 0.6778222918510437\n",
            "3090 val_loss: 0.6810171008110046, train_loss: 0.6776348948478699\n",
            "3100 val_loss: 0.6808947920799255, train_loss: 0.677484393119812\n",
            "3110 val_loss: 0.6807200312614441, train_loss: 0.6772989630699158\n",
            "3120 val_loss: 0.6805298328399658, train_loss: 0.6770989298820496\n",
            "3130 val_loss: 0.6803514957427979, train_loss: 0.6769154667854309\n",
            "3140 val_loss: 0.6801959276199341, train_loss: 0.67673259973526\n",
            "3150 val_loss: 0.6800389289855957, train_loss: 0.6765666604042053\n",
            "3160 val_loss: 0.6798660159111023, train_loss: 0.6763773560523987\n",
            "3170 val_loss: 0.6797049641609192, train_loss: 0.6761947870254517\n",
            "3180 val_loss: 0.6795210242271423, train_loss: 0.6759944558143616\n",
            "3190 val_loss: 0.6793420910835266, train_loss: 0.6758154034614563\n",
            "3200 val_loss: 0.6791672110557556, train_loss: 0.6756299138069153\n",
            "3210 val_loss: 0.6789681315422058, train_loss: 0.6754162907600403\n",
            "3220 val_loss: 0.6787990927696228, train_loss: 0.6752163767814636\n",
            "3230 val_loss: 0.6786091923713684, train_loss: 0.6750059127807617\n",
            "3240 val_loss: 0.6784051060676575, train_loss: 0.6747629642486572\n",
            "3250 val_loss: 0.6782059669494629, train_loss: 0.6745402812957764\n",
            "3260 val_loss: 0.6780091524124146, train_loss: 0.6743173599243164\n",
            "3270 val_loss: 0.6778049468994141, train_loss: 0.6740887761116028\n",
            "3280 val_loss: 0.6775985360145569, train_loss: 0.6738564372062683\n",
            "3290 val_loss: 0.677370548248291, train_loss: 0.6736042499542236\n",
            "3300 val_loss: 0.6771513819694519, train_loss: 0.6733641624450684\n",
            "3310 val_loss: 0.6769598126411438, train_loss: 0.6731466054916382\n",
            "3320 val_loss: 0.6767439246177673, train_loss: 0.672923743724823\n",
            "3330 val_loss: 0.6765367984771729, train_loss: 0.6726910471916199\n",
            "3340 val_loss: 0.67634117603302, train_loss: 0.6724687814712524\n",
            "3350 val_loss: 0.6761616468429565, train_loss: 0.6722701191902161\n",
            "3360 val_loss: 0.6759305000305176, train_loss: 0.6720494031906128\n",
            "3370 val_loss: 0.6756699681282043, train_loss: 0.6717819571495056\n",
            "3380 val_loss: 0.6754422783851624, train_loss: 0.6715240478515625\n",
            "3390 val_loss: 0.6752182841300964, train_loss: 0.6712833046913147\n",
            "3400 val_loss: 0.6749598383903503, train_loss: 0.6710297465324402\n",
            "3410 val_loss: 0.674732506275177, train_loss: 0.6707600355148315\n",
            "3420 val_loss: 0.6745103001594543, train_loss: 0.6705187559127808\n",
            "3430 val_loss: 0.6742371320724487, train_loss: 0.6702239513397217\n",
            "3440 val_loss: 0.6740096211433411, train_loss: 0.6699671745300293\n",
            "3450 val_loss: 0.6737779974937439, train_loss: 0.669712245464325\n",
            "3460 val_loss: 0.6735438704490662, train_loss: 0.6694560647010803\n",
            "3470 val_loss: 0.6733148694038391, train_loss: 0.669194757938385\n",
            "3480 val_loss: 0.6730847358703613, train_loss: 0.668945848941803\n",
            "3490 val_loss: 0.6728745102882385, train_loss: 0.66872638463974\n",
            "3500 val_loss: 0.6726148724555969, train_loss: 0.6684350967407227\n",
            "3510 val_loss: 0.6723187565803528, train_loss: 0.6681380867958069\n",
            "3520 val_loss: 0.672082245349884, train_loss: 0.6678590774536133\n",
            "3530 val_loss: 0.6718408465385437, train_loss: 0.6675933003425598\n",
            "3540 val_loss: 0.6716315150260925, train_loss: 0.6673498153686523\n",
            "3550 val_loss: 0.6713353395462036, train_loss: 0.6670272350311279\n",
            "3560 val_loss: 0.6711193919181824, train_loss: 0.6667762994766235\n",
            "3570 val_loss: 0.6708605885505676, train_loss: 0.6664890646934509\n",
            "3580 val_loss: 0.6705051064491272, train_loss: 0.6661244630813599\n",
            "3590 val_loss: 0.6702367663383484, train_loss: 0.6658332347869873\n",
            "3600 val_loss: 0.6699241995811462, train_loss: 0.6655216813087463\n",
            "3610 val_loss: 0.6696974635124207, train_loss: 0.6652671694755554\n",
            "3620 val_loss: 0.6693475246429443, train_loss: 0.6649012565612793\n",
            "3630 val_loss: 0.6690069437026978, train_loss: 0.664538562297821\n",
            "3640 val_loss: 0.6686999201774597, train_loss: 0.6642091870307922\n",
            "3650 val_loss: 0.6683882474899292, train_loss: 0.6638575196266174\n",
            "3660 val_loss: 0.6680511832237244, train_loss: 0.663500189781189\n",
            "3670 val_loss: 0.6677173376083374, train_loss: 0.6631689071655273\n",
            "3680 val_loss: 0.6674045920372009, train_loss: 0.6628385186195374\n",
            "3690 val_loss: 0.6671286821365356, train_loss: 0.6625333428382874\n",
            "3700 val_loss: 0.6668460369110107, train_loss: 0.6622248888015747\n",
            "3710 val_loss: 0.6665595173835754, train_loss: 0.6619129776954651\n",
            "3720 val_loss: 0.6662733554840088, train_loss: 0.6616213917732239\n",
            "3730 val_loss: 0.6660227179527283, train_loss: 0.6613438129425049\n",
            "3740 val_loss: 0.6657189130783081, train_loss: 0.6610310077667236\n",
            "3750 val_loss: 0.665397047996521, train_loss: 0.6607089638710022\n",
            "3760 val_loss: 0.6651260852813721, train_loss: 0.6603991389274597\n",
            "3770 val_loss: 0.6648449897766113, train_loss: 0.660094141960144\n",
            "3780 val_loss: 0.6645330786705017, train_loss: 0.6597374677658081\n",
            "3790 val_loss: 0.6642142534255981, train_loss: 0.6594051718711853\n",
            "3800 val_loss: 0.6638689637184143, train_loss: 0.6590710282325745\n",
            "3810 val_loss: 0.6635787487030029, train_loss: 0.6587463021278381\n",
            "3820 val_loss: 0.6632794737815857, train_loss: 0.6584064960479736\n",
            "3830 val_loss: 0.6629632115364075, train_loss: 0.6580655574798584\n",
            "3840 val_loss: 0.6626483201980591, train_loss: 0.6577509641647339\n",
            "3850 val_loss: 0.6623532176017761, train_loss: 0.6573905348777771\n",
            "3860 val_loss: 0.6620136499404907, train_loss: 0.6570733785629272\n",
            "3870 val_loss: 0.6616677045822144, train_loss: 0.6567165851593018\n",
            "3880 val_loss: 0.6612891554832458, train_loss: 0.6563717722892761\n",
            "3890 val_loss: 0.6608981490135193, train_loss: 0.6559934020042419\n",
            "3900 val_loss: 0.6605575680732727, train_loss: 0.6556689739227295\n",
            "3910 val_loss: 0.6601865887641907, train_loss: 0.6552987098693848\n",
            "3920 val_loss: 0.6599080562591553, train_loss: 0.6549692153930664\n",
            "3930 val_loss: 0.6595736742019653, train_loss: 0.6546080708503723\n",
            "3940 val_loss: 0.6592251062393188, train_loss: 0.6542574167251587\n",
            "3950 val_loss: 0.6588683128356934, train_loss: 0.6539111733436584\n",
            "3960 val_loss: 0.6584904193878174, train_loss: 0.6535238027572632\n",
            "3970 val_loss: 0.6581861972808838, train_loss: 0.6531916260719299\n",
            "3980 val_loss: 0.6578164100646973, train_loss: 0.6527953743934631\n",
            "3990 val_loss: 0.6575042009353638, train_loss: 0.6524840593338013\n",
            "4000 val_loss: 0.6571910381317139, train_loss: 0.6521286964416504\n",
            "4010 val_loss: 0.6568347215652466, train_loss: 0.651756763458252\n",
            "4020 val_loss: 0.6564470529556274, train_loss: 0.6513856053352356\n",
            "4030 val_loss: 0.656082034111023, train_loss: 0.6509652733802795\n",
            "4040 val_loss: 0.6557002663612366, train_loss: 0.6505700945854187\n",
            "4050 val_loss: 0.6553157567977905, train_loss: 0.650200366973877\n",
            "4060 val_loss: 0.6549817323684692, train_loss: 0.6498505473136902\n",
            "4070 val_loss: 0.6546216011047363, train_loss: 0.6495019793510437\n",
            "4080 val_loss: 0.65430748462677, train_loss: 0.6491590738296509\n",
            "4090 val_loss: 0.6539564728736877, train_loss: 0.6487902998924255\n",
            "4100 val_loss: 0.6536321043968201, train_loss: 0.6484220623970032\n",
            "4110 val_loss: 0.6532770991325378, train_loss: 0.6480724811553955\n",
            "4120 val_loss: 0.6528486609458923, train_loss: 0.647644579410553\n",
            "4130 val_loss: 0.6524118781089783, train_loss: 0.6472321152687073\n",
            "4140 val_loss: 0.6520432829856873, train_loss: 0.6468913555145264\n",
            "4150 val_loss: 0.6516246795654297, train_loss: 0.646448016166687\n",
            "4160 val_loss: 0.6512885093688965, train_loss: 0.6460820436477661\n",
            "4170 val_loss: 0.6509448289871216, train_loss: 0.6456980109214783\n",
            "4180 val_loss: 0.6505653858184814, train_loss: 0.6453559398651123\n",
            "4190 val_loss: 0.6501297354698181, train_loss: 0.6449762582778931\n",
            "4200 val_loss: 0.6497454643249512, train_loss: 0.6445679664611816\n",
            "4210 val_loss: 0.6494072675704956, train_loss: 0.6442197561264038\n",
            "4220 val_loss: 0.6489575505256653, train_loss: 0.6437872052192688\n",
            "4230 val_loss: 0.6485190391540527, train_loss: 0.6433480978012085\n",
            "4240 val_loss: 0.6481132507324219, train_loss: 0.6429749131202698\n",
            "4250 val_loss: 0.6476853489875793, train_loss: 0.6425793766975403\n",
            "4260 val_loss: 0.6473187208175659, train_loss: 0.6422047019004822\n",
            "4270 val_loss: 0.6468843817710876, train_loss: 0.6418064832687378\n",
            "4280 val_loss: 0.6465620994567871, train_loss: 0.6414649486541748\n",
            "4290 val_loss: 0.6461247205734253, train_loss: 0.6410544514656067\n",
            "4300 val_loss: 0.6457533836364746, train_loss: 0.6406338214874268\n",
            "4310 val_loss: 0.6453465819358826, train_loss: 0.6402699947357178\n",
            "4320 val_loss: 0.6449648141860962, train_loss: 0.639858603477478\n",
            "4330 val_loss: 0.6445361375808716, train_loss: 0.6394486427307129\n",
            "4340 val_loss: 0.644116997718811, train_loss: 0.6390537023544312\n",
            "4350 val_loss: 0.6437774896621704, train_loss: 0.6386805772781372\n",
            "4360 val_loss: 0.6433550715446472, train_loss: 0.6382489204406738\n",
            "4370 val_loss: 0.6429513692855835, train_loss: 0.6378459334373474\n",
            "4380 val_loss: 0.6424883604049683, train_loss: 0.6374555826187134\n",
            "4390 val_loss: 0.6420525908470154, train_loss: 0.637068510055542\n",
            "4400 val_loss: 0.6417183876037598, train_loss: 0.6367300748825073\n",
            "4410 val_loss: 0.6413016319274902, train_loss: 0.6363852024078369\n",
            "4420 val_loss: 0.6408419013023376, train_loss: 0.6359789371490479\n",
            "4430 val_loss: 0.6404005885124207, train_loss: 0.6355195045471191\n",
            "4440 val_loss: 0.6399978399276733, train_loss: 0.6351870894432068\n",
            "4450 val_loss: 0.6396124362945557, train_loss: 0.6348695755004883\n",
            "4460 val_loss: 0.6392356157302856, train_loss: 0.6345523595809937\n",
            "4470 val_loss: 0.6388548016548157, train_loss: 0.6342344880104065\n",
            "4480 val_loss: 0.6385645866394043, train_loss: 0.633891761302948\n",
            "4490 val_loss: 0.6381444931030273, train_loss: 0.6334803104400635\n",
            "4500 val_loss: 0.637744128704071, train_loss: 0.6331325769424438\n",
            "4510 val_loss: 0.6373780369758606, train_loss: 0.63276207447052\n",
            "4520 val_loss: 0.6369490623474121, train_loss: 0.6323724985122681\n",
            "4530 val_loss: 0.6365941166877747, train_loss: 0.6320193409919739\n",
            "4540 val_loss: 0.6362647414207458, train_loss: 0.6316530108451843\n",
            "4550 val_loss: 0.6359801292419434, train_loss: 0.631313681602478\n",
            "4560 val_loss: 0.6356322765350342, train_loss: 0.6309595108032227\n",
            "4570 val_loss: 0.635254442691803, train_loss: 0.6306161284446716\n",
            "4580 val_loss: 0.6349316835403442, train_loss: 0.6303106546401978\n",
            "4590 val_loss: 0.6347107887268066, train_loss: 0.630050003528595\n",
            "4600 val_loss: 0.6343739032745361, train_loss: 0.6296653151512146\n",
            "4610 val_loss: 0.6340529322624207, train_loss: 0.6293330192565918\n",
            "4620 val_loss: 0.6338221430778503, train_loss: 0.6290804147720337\n",
            "4630 val_loss: 0.6334547996520996, train_loss: 0.6287146210670471\n",
            "4640 val_loss: 0.6330127716064453, train_loss: 0.6283670663833618\n",
            "4650 val_loss: 0.6326583027839661, train_loss: 0.6280271410942078\n",
            "4660 val_loss: 0.6322510838508606, train_loss: 0.6276863813400269\n",
            "4670 val_loss: 0.6318490505218506, train_loss: 0.627362847328186\n",
            "4680 val_loss: 0.6314399838447571, train_loss: 0.6270195245742798\n",
            "4690 val_loss: 0.6311321258544922, train_loss: 0.6267989277839661\n",
            "4700 val_loss: 0.6307411789894104, train_loss: 0.62645024061203\n",
            "4710 val_loss: 0.6304255723953247, train_loss: 0.6260395646095276\n",
            "4720 val_loss: 0.6302499771118164, train_loss: 0.6257703900337219\n",
            "4730 val_loss: 0.6298556327819824, train_loss: 0.6253865957260132\n",
            "4740 val_loss: 0.6295527815818787, train_loss: 0.6250001788139343\n",
            "4750 val_loss: 0.6291911005973816, train_loss: 0.624700129032135\n",
            "4760 val_loss: 0.6287514567375183, train_loss: 0.6243305802345276\n",
            "4770 val_loss: 0.6285086870193481, train_loss: 0.6240626573562622\n",
            "4780 val_loss: 0.628258466720581, train_loss: 0.6238453984260559\n",
            "4790 val_loss: 0.6277913451194763, train_loss: 0.6234244108200073\n",
            "4800 val_loss: 0.6274096965789795, train_loss: 0.6231170296669006\n",
            "4810 val_loss: 0.6269338130950928, train_loss: 0.6228386759757996\n",
            "4820 val_loss: 0.6264708042144775, train_loss: 0.6225278973579407\n",
            "4830 val_loss: 0.6260744333267212, train_loss: 0.6221376657485962\n",
            "4840 val_loss: 0.6257518529891968, train_loss: 0.6218537092208862\n",
            "4850 val_loss: 0.6254425644874573, train_loss: 0.6216901540756226\n",
            "4860 val_loss: 0.6251996755599976, train_loss: 0.6214622855186462\n",
            "4870 val_loss: 0.6249586343765259, train_loss: 0.6211389303207397\n",
            "4880 val_loss: 0.6245862245559692, train_loss: 0.6207728385925293\n",
            "4890 val_loss: 0.6242241859436035, train_loss: 0.6204591989517212\n",
            "4900 val_loss: 0.62403404712677, train_loss: 0.6201310157775879\n",
            "4910 val_loss: 0.6236864924430847, train_loss: 0.6198822855949402\n",
            "4920 val_loss: 0.6233546137809753, train_loss: 0.6196454763412476\n",
            "4930 val_loss: 0.6229913234710693, train_loss: 0.6193086504936218\n",
            "4940 val_loss: 0.6227152943611145, train_loss: 0.6190958023071289\n",
            "4950 val_loss: 0.6222962737083435, train_loss: 0.6188704371452332\n",
            "4960 val_loss: 0.6219922304153442, train_loss: 0.618691086769104\n",
            "4970 val_loss: 0.6217069029808044, train_loss: 0.6184965372085571\n",
            "4980 val_loss: 0.621595025062561, train_loss: 0.6181737184524536\n",
            "4990 val_loss: 0.6212254166603088, train_loss: 0.6178451180458069\n",
            "5000 val_loss: 0.6210075616836548, train_loss: 0.6176252961158752\n",
            "5010 val_loss: 0.6207515001296997, train_loss: 0.617555558681488\n",
            "5020 val_loss: 0.6205793023109436, train_loss: 0.6173198223114014\n",
            "5030 val_loss: 0.6201342344284058, train_loss: 0.6170400381088257\n",
            "5040 val_loss: 0.6199229955673218, train_loss: 0.6168795228004456\n",
            "5050 val_loss: 0.619640052318573, train_loss: 0.6167184710502625\n",
            "5060 val_loss: 0.6194262504577637, train_loss: 0.6164509057998657\n",
            "5070 val_loss: 0.6191872358322144, train_loss: 0.6162188053131104\n",
            "5080 val_loss: 0.6189080476760864, train_loss: 0.6160621047019958\n",
            "5090 val_loss: 0.6186785697937012, train_loss: 0.6157574653625488\n",
            "5100 val_loss: 0.6186650395393372, train_loss: 0.6156384944915771\n",
            "5110 val_loss: 0.6184016466140747, train_loss: 0.6153604388237\n",
            "5120 val_loss: 0.6180822253227234, train_loss: 0.6150919795036316\n",
            "5130 val_loss: 0.6177926063537598, train_loss: 0.6148768067359924\n",
            "5140 val_loss: 0.617326021194458, train_loss: 0.6145932078361511\n",
            "5150 val_loss: 0.6170796751976013, train_loss: 0.6144043207168579\n",
            "5160 val_loss: 0.6167057156562805, train_loss: 0.6140897870063782\n",
            "5170 val_loss: 0.616683840751648, train_loss: 0.6138383746147156\n",
            "5180 val_loss: 0.6164762377738953, train_loss: 0.6137143969535828\n",
            "5190 val_loss: 0.6161217093467712, train_loss: 0.6134845018386841\n",
            "5200 val_loss: 0.6158590912818909, train_loss: 0.6132616996765137\n",
            "5210 val_loss: 0.6155714988708496, train_loss: 0.6131247282028198\n",
            "5220 val_loss: 0.6153817772865295, train_loss: 0.6128955483436584\n",
            "5230 val_loss: 0.61515873670578, train_loss: 0.6126101613044739\n",
            "5240 val_loss: 0.6148282289505005, train_loss: 0.6123080849647522\n",
            "5250 val_loss: 0.6146048307418823, train_loss: 0.6121538877487183\n",
            "5260 val_loss: 0.6142889857292175, train_loss: 0.6118704080581665\n",
            "5270 val_loss: 0.6141049861907959, train_loss: 0.6117584705352783\n",
            "5280 val_loss: 0.6138856410980225, train_loss: 0.6115483045578003\n",
            "5290 val_loss: 0.6136164665222168, train_loss: 0.6112697124481201\n",
            "5300 val_loss: 0.6135351657867432, train_loss: 0.6111891865730286\n",
            "5310 val_loss: 0.6132023930549622, train_loss: 0.6109366416931152\n",
            "5320 val_loss: 0.6129323840141296, train_loss: 0.6108187437057495\n",
            "5330 val_loss: 0.6126596927642822, train_loss: 0.6105284690856934\n",
            "5340 val_loss: 0.6123594641685486, train_loss: 0.6102868914604187\n",
            "5350 val_loss: 0.6122328042984009, train_loss: 0.6102108359336853\n",
            "5360 val_loss: 0.6120303273200989, train_loss: 0.6100090742111206\n",
            "5370 val_loss: 0.6118640303611755, train_loss: 0.6097956895828247\n",
            "5380 val_loss: 0.6116310358047485, train_loss: 0.6095603704452515\n",
            "5390 val_loss: 0.611596941947937, train_loss: 0.6094198226928711\n",
            "5400 val_loss: 0.6112778782844543, train_loss: 0.6092462539672852\n",
            "5410 val_loss: 0.6110989451408386, train_loss: 0.6091181635856628\n",
            "5420 val_loss: 0.6109648942947388, train_loss: 0.6089174151420593\n",
            "5430 val_loss: 0.6106664538383484, train_loss: 0.6086849570274353\n",
            "5440 val_loss: 0.6107169389724731, train_loss: 0.6085200309753418\n",
            "5450 val_loss: 0.6106562614440918, train_loss: 0.6083159446716309\n",
            "5460 val_loss: 0.6099526286125183, train_loss: 0.6079156994819641\n",
            "5470 val_loss: 0.6095026135444641, train_loss: 0.607702374458313\n",
            "5480 val_loss: 0.6093249320983887, train_loss: 0.6074755787849426\n",
            "5490 val_loss: 0.6090704798698425, train_loss: 0.6073232889175415\n",
            "5500 val_loss: 0.6089819073677063, train_loss: 0.6071901321411133\n",
            "5510 val_loss: 0.6088482737541199, train_loss: 0.6069813370704651\n",
            "5520 val_loss: 0.6085224747657776, train_loss: 0.6067767143249512\n",
            "5530 val_loss: 0.6084267497062683, train_loss: 0.6066316366195679\n",
            "5540 val_loss: 0.608269989490509, train_loss: 0.6065497994422913\n",
            "5550 val_loss: 0.60798579454422, train_loss: 0.6063349843025208\n",
            "5560 val_loss: 0.6077651977539062, train_loss: 0.6060495376586914\n",
            "5570 val_loss: 0.6075045466423035, train_loss: 0.6058114171028137\n",
            "5580 val_loss: 0.6073903441429138, train_loss: 0.6056099534034729\n",
            "5590 val_loss: 0.6073805093765259, train_loss: 0.6055709719657898\n",
            "5600 val_loss: 0.607065737247467, train_loss: 0.6053698658943176\n",
            "5610 val_loss: 0.60675048828125, train_loss: 0.6050925254821777\n",
            "5620 val_loss: 0.6065550446510315, train_loss: 0.6048822402954102\n",
            "5630 val_loss: 0.6064745783805847, train_loss: 0.6047044396400452\n",
            "5640 val_loss: 0.606232762336731, train_loss: 0.6045019030570984\n",
            "5650 val_loss: 0.6060521602630615, train_loss: 0.6043470501899719\n",
            "5660 val_loss: 0.6058365106582642, train_loss: 0.6041691899299622\n",
            "5670 val_loss: 0.605744481086731, train_loss: 0.6040613055229187\n",
            "5680 val_loss: 0.6053629517555237, train_loss: 0.6038843989372253\n",
            "5690 val_loss: 0.6050889492034912, train_loss: 0.6037027835845947\n",
            "5700 val_loss: 0.6049992442131042, train_loss: 0.6036049127578735\n",
            "5710 val_loss: 0.604843258857727, train_loss: 0.6034488081932068\n",
            "5720 val_loss: 0.604900062084198, train_loss: 0.603394091129303\n",
            "5730 val_loss: 0.6045713424682617, train_loss: 0.6031875014305115\n",
            "5740 val_loss: 0.6042307615280151, train_loss: 0.6028753519058228\n",
            "5750 val_loss: 0.6041284203529358, train_loss: 0.6027476787567139\n",
            "5760 val_loss: 0.6040421724319458, train_loss: 0.6026946306228638\n",
            "5770 val_loss: 0.6040387153625488, train_loss: 0.6026108860969543\n",
            "5780 val_loss: 0.6037953495979309, train_loss: 0.6024249196052551\n",
            "5790 val_loss: 0.6036759614944458, train_loss: 0.6021373271942139\n",
            "5800 val_loss: 0.6035190224647522, train_loss: 0.6020331978797913\n",
            "5810 val_loss: 0.6035010814666748, train_loss: 0.6019415259361267\n",
            "5820 val_loss: 0.6032910346984863, train_loss: 0.6017228960990906\n",
            "5830 val_loss: 0.6030106544494629, train_loss: 0.6015422344207764\n",
            "5840 val_loss: 0.6027792096138, train_loss: 0.6014297008514404\n",
            "5850 val_loss: 0.6024783849716187, train_loss: 0.6012803912162781\n",
            "5860 val_loss: 0.6023648381233215, train_loss: 0.6012033224105835\n",
            "5870 val_loss: 0.6023375988006592, train_loss: 0.6010617613792419\n",
            "5880 val_loss: 0.6020467877388, train_loss: 0.6008987426757812\n",
            "5890 val_loss: 0.601929247379303, train_loss: 0.6006941795349121\n",
            "5900 val_loss: 0.6015846133232117, train_loss: 0.6004588007926941\n",
            "5910 val_loss: 0.6015149354934692, train_loss: 0.6003305912017822\n",
            "5920 val_loss: 0.6014649271965027, train_loss: 0.600196361541748\n",
            "5930 val_loss: 0.6013892292976379, train_loss: 0.6000475883483887\n",
            "5940 val_loss: 0.6011192798614502, train_loss: 0.5997437834739685\n",
            "5950 val_loss: 0.6009659767150879, train_loss: 0.5996199250221252\n",
            "5960 val_loss: 0.6009054183959961, train_loss: 0.5995221138000488\n",
            "5970 val_loss: 0.6007434129714966, train_loss: 0.5993924140930176\n",
            "5980 val_loss: 0.6005842089653015, train_loss: 0.5992499589920044\n",
            "5990 val_loss: 0.6003276705741882, train_loss: 0.5991142988204956\n",
            "6000 val_loss: 0.600208044052124, train_loss: 0.5989262461662292\n",
            "6010 val_loss: 0.6000854969024658, train_loss: 0.598728358745575\n",
            "6020 val_loss: 0.5999704599380493, train_loss: 0.598656177520752\n",
            "6030 val_loss: 0.5999541282653809, train_loss: 0.5985898971557617\n",
            "6040 val_loss: 0.5997214317321777, train_loss: 0.598395586013794\n",
            "6050 val_loss: 0.5996300578117371, train_loss: 0.5983209013938904\n",
            "6060 val_loss: 0.5995701551437378, train_loss: 0.5981916189193726\n",
            "6070 val_loss: 0.5993733406066895, train_loss: 0.5980604290962219\n",
            "6080 val_loss: 0.5993371605873108, train_loss: 0.5979012846946716\n",
            "6090 val_loss: 0.5993960499763489, train_loss: 0.5978944301605225\n",
            "6100 val_loss: 0.599578857421875, train_loss: 0.5977625846862793\n",
            "6110 val_loss: 0.5993452668190002, train_loss: 0.5976486802101135\n",
            "6120 val_loss: 0.5989727973937988, train_loss: 0.5974494218826294\n",
            "6130 val_loss: 0.5987763404846191, train_loss: 0.5972722172737122\n",
            "6140 val_loss: 0.5985929369926453, train_loss: 0.5970933437347412\n",
            "6150 val_loss: 0.5985044836997986, train_loss: 0.5969514846801758\n",
            "6160 val_loss: 0.598296582698822, train_loss: 0.5968993306159973\n",
            "6170 val_loss: 0.5981913805007935, train_loss: 0.5966874957084656\n",
            "6180 val_loss: 0.5979708433151245, train_loss: 0.5964647531509399\n",
            "6190 val_loss: 0.5979743003845215, train_loss: 0.5963904857635498\n",
            "6200 val_loss: 0.5980145931243896, train_loss: 0.5963696241378784\n",
            "6210 val_loss: 0.5978360176086426, train_loss: 0.5961849689483643\n",
            "6220 val_loss: 0.5977878570556641, train_loss: 0.596125066280365\n",
            "6230 val_loss: 0.5975288152694702, train_loss: 0.5958214402198792\n",
            "6240 val_loss: 0.597162127494812, train_loss: 0.5955208539962769\n",
            "6250 val_loss: 0.5969355702400208, train_loss: 0.5952834486961365\n",
            "6260 val_loss: 0.5968615412712097, train_loss: 0.595177412033081\n",
            "6270 val_loss: 0.5966493487358093, train_loss: 0.5951086282730103\n",
            "6280 val_loss: 0.5964145660400391, train_loss: 0.5948728322982788\n",
            "6290 val_loss: 0.5961707234382629, train_loss: 0.5947880744934082\n",
            "6300 val_loss: 0.5960663557052612, train_loss: 0.5946269035339355\n",
            "6310 val_loss: 0.5960155129432678, train_loss: 0.5944664478302002\n",
            "6320 val_loss: 0.5957666039466858, train_loss: 0.5942124724388123\n",
            "6330 val_loss: 0.5955605506896973, train_loss: 0.5941644906997681\n",
            "6340 val_loss: 0.5955415964126587, train_loss: 0.593980073928833\n",
            "6350 val_loss: 0.5954537391662598, train_loss: 0.5939257144927979\n",
            "6360 val_loss: 0.5954526662826538, train_loss: 0.5937824845314026\n",
            "6370 val_loss: 0.5951430201530457, train_loss: 0.5935414433479309\n",
            "6380 val_loss: 0.5951194763183594, train_loss: 0.5934413075447083\n",
            "6390 val_loss: 0.5949187278747559, train_loss: 0.593382716178894\n",
            "6400 val_loss: 0.5948052406311035, train_loss: 0.5931851267814636\n",
            "6410 val_loss: 0.5947247743606567, train_loss: 0.5930683016777039\n",
            "6420 val_loss: 0.5945467352867126, train_loss: 0.5930002927780151\n",
            "6430 val_loss: 0.5944783687591553, train_loss: 0.5927966237068176\n",
            "6440 val_loss: 0.5943464636802673, train_loss: 0.5926753878593445\n",
            "6450 val_loss: 0.5942171812057495, train_loss: 0.5924866795539856\n",
            "6460 val_loss: 0.5939517617225647, train_loss: 0.5921831727027893\n",
            "6470 val_loss: 0.5937823057174683, train_loss: 0.5920371413230896\n",
            "6480 val_loss: 0.5935521125793457, train_loss: 0.5918781161308289\n",
            "6490 val_loss: 0.5932043790817261, train_loss: 0.591671347618103\n",
            "6500 val_loss: 0.5929956436157227, train_loss: 0.5913388729095459\n",
            "6510 val_loss: 0.5929283499717712, train_loss: 0.5911129713058472\n",
            "6520 val_loss: 0.5925154089927673, train_loss: 0.5908923745155334\n",
            "6530 val_loss: 0.5920989513397217, train_loss: 0.5907931923866272\n",
            "6540 val_loss: 0.5918461084365845, train_loss: 0.5906315445899963\n",
            "6550 val_loss: 0.591620147228241, train_loss: 0.5903892517089844\n",
            "6560 val_loss: 0.5913252830505371, train_loss: 0.590121865272522\n",
            "6570 val_loss: 0.5912714004516602, train_loss: 0.5900763869285583\n",
            "6580 val_loss: 0.591206967830658, train_loss: 0.590053141117096\n",
            "6590 val_loss: 0.5909873247146606, train_loss: 0.5898708701133728\n",
            "6600 val_loss: 0.590899646282196, train_loss: 0.5896420478820801\n",
            "6610 val_loss: 0.5907363891601562, train_loss: 0.5894136428833008\n",
            "6620 val_loss: 0.5905468463897705, train_loss: 0.5891858339309692\n",
            "6630 val_loss: 0.5904349088668823, train_loss: 0.5889257192611694\n",
            "6640 val_loss: 0.5901507139205933, train_loss: 0.5887031555175781\n",
            "6650 val_loss: 0.5899556279182434, train_loss: 0.5885946750640869\n",
            "6660 val_loss: 0.5898865461349487, train_loss: 0.5884705185890198\n",
            "6670 val_loss: 0.5897417664527893, train_loss: 0.5882568955421448\n",
            "6680 val_loss: 0.589496910572052, train_loss: 0.5880842208862305\n",
            "6690 val_loss: 0.5893084406852722, train_loss: 0.5877335071563721\n",
            "6700 val_loss: 0.5891944169998169, train_loss: 0.5876137614250183\n",
            "6710 val_loss: 0.5890817046165466, train_loss: 0.5875838398933411\n",
            "6720 val_loss: 0.5891169905662537, train_loss: 0.5874756574630737\n",
            "6730 val_loss: 0.5888453722000122, train_loss: 0.5871429443359375\n",
            "6740 val_loss: 0.5886994004249573, train_loss: 0.5870695114135742\n",
            "6750 val_loss: 0.5886754989624023, train_loss: 0.586966872215271\n",
            "6760 val_loss: 0.5884522795677185, train_loss: 0.5867619514465332\n",
            "6770 val_loss: 0.5883587002754211, train_loss: 0.5865982174873352\n",
            "6780 val_loss: 0.5882752537727356, train_loss: 0.5864677429199219\n",
            "6790 val_loss: 0.5880154371261597, train_loss: 0.5863305330276489\n",
            "6800 val_loss: 0.5879020094871521, train_loss: 0.5862066149711609\n",
            "6810 val_loss: 0.5878845453262329, train_loss: 0.5860283374786377\n",
            "6820 val_loss: 0.5876609086990356, train_loss: 0.5858103632926941\n",
            "6830 val_loss: 0.5875027179718018, train_loss: 0.5856276750564575\n",
            "6840 val_loss: 0.5872710347175598, train_loss: 0.5853690505027771\n",
            "6850 val_loss: 0.5872184038162231, train_loss: 0.5853938460350037\n",
            "6860 val_loss: 0.5870450139045715, train_loss: 0.5852024555206299\n",
            "6870 val_loss: 0.586830198764801, train_loss: 0.5850120782852173\n",
            "6880 val_loss: 0.5868436098098755, train_loss: 0.5849135518074036\n",
            "6890 val_loss: 0.5865388512611389, train_loss: 0.5846502184867859\n",
            "6900 val_loss: 0.5863710045814514, train_loss: 0.5844728946685791\n",
            "6910 val_loss: 0.5864125490188599, train_loss: 0.5844960808753967\n",
            "6920 val_loss: 0.5862946510314941, train_loss: 0.5842442512512207\n",
            "6930 val_loss: 0.5860973596572876, train_loss: 0.5841142535209656\n",
            "6940 val_loss: 0.5858388543128967, train_loss: 0.5838505625724792\n",
            "6950 val_loss: 0.585403561592102, train_loss: 0.5834341645240784\n",
            "6960 val_loss: 0.5853302478790283, train_loss: 0.5832428932189941\n",
            "6970 val_loss: 0.5851969718933105, train_loss: 0.5830973386764526\n",
            "6980 val_loss: 0.5849803686141968, train_loss: 0.5828519463539124\n",
            "6990 val_loss: 0.5847895741462708, train_loss: 0.5825762748718262\n",
            "7000 val_loss: 0.5846497416496277, train_loss: 0.5823981761932373\n",
            "7010 val_loss: 0.5844171643257141, train_loss: 0.5820826888084412\n",
            "7020 val_loss: 0.5842544436454773, train_loss: 0.5819529891014099\n",
            "7030 val_loss: 0.5842107534408569, train_loss: 0.5819506645202637\n",
            "7040 val_loss: 0.5840730667114258, train_loss: 0.5817489624023438\n",
            "7050 val_loss: 0.5836725234985352, train_loss: 0.581501841545105\n",
            "7060 val_loss: 0.583409309387207, train_loss: 0.581253707408905\n",
            "7070 val_loss: 0.5833637118339539, train_loss: 0.5811095237731934\n",
            "7080 val_loss: 0.5833796858787537, train_loss: 0.5809354186058044\n",
            "7090 val_loss: 0.5831112265586853, train_loss: 0.5806763172149658\n",
            "7100 val_loss: 0.5828797221183777, train_loss: 0.580493152141571\n",
            "7110 val_loss: 0.5825932621955872, train_loss: 0.5800946950912476\n",
            "7120 val_loss: 0.5822425484657288, train_loss: 0.5797404646873474\n",
            "7130 val_loss: 0.5820352435112, train_loss: 0.5794268250465393\n",
            "7140 val_loss: 0.5817880630493164, train_loss: 0.5791506171226501\n",
            "7150 val_loss: 0.5814528465270996, train_loss: 0.5788182020187378\n",
            "7160 val_loss: 0.581249475479126, train_loss: 0.5785381197929382\n",
            "7170 val_loss: 0.5811821222305298, train_loss: 0.5783836841583252\n",
            "7180 val_loss: 0.5810460448265076, train_loss: 0.5783788561820984\n",
            "7190 val_loss: 0.5808491706848145, train_loss: 0.5781082510948181\n",
            "7200 val_loss: 0.5806424021720886, train_loss: 0.5778612494468689\n",
            "7210 val_loss: 0.580466628074646, train_loss: 0.5776969194412231\n",
            "7220 val_loss: 0.5804064869880676, train_loss: 0.5777533650398254\n",
            "7230 val_loss: 0.58024662733078, train_loss: 0.5775391459465027\n",
            "7240 val_loss: 0.5800732374191284, train_loss: 0.5773651599884033\n",
            "7250 val_loss: 0.5797969698905945, train_loss: 0.577093243598938\n",
            "7260 val_loss: 0.579651951789856, train_loss: 0.5768901109695435\n",
            "7270 val_loss: 0.57954341173172, train_loss: 0.5767716765403748\n",
            "7280 val_loss: 0.5793790221214294, train_loss: 0.5766290426254272\n",
            "7290 val_loss: 0.5790067911148071, train_loss: 0.5762138366699219\n",
            "7300 val_loss: 0.5786293745040894, train_loss: 0.57586669921875\n",
            "7310 val_loss: 0.5785170197486877, train_loss: 0.5756655931472778\n",
            "7320 val_loss: 0.5782747268676758, train_loss: 0.5753733515739441\n",
            "7330 val_loss: 0.5781086087226868, train_loss: 0.5752236247062683\n",
            "7340 val_loss: 0.5778098106384277, train_loss: 0.5749982595443726\n",
            "7350 val_loss: 0.5777788758277893, train_loss: 0.5748283863067627\n",
            "7360 val_loss: 0.5775614380836487, train_loss: 0.5744861960411072\n",
            "7370 val_loss: 0.5773817896842957, train_loss: 0.5743796229362488\n",
            "7380 val_loss: 0.57703697681427, train_loss: 0.5742637515068054\n",
            "7390 val_loss: 0.5767884850502014, train_loss: 0.5740092396736145\n",
            "7400 val_loss: 0.5766585469245911, train_loss: 0.573805570602417\n",
            "7410 val_loss: 0.576626181602478, train_loss: 0.5737647414207458\n",
            "7420 val_loss: 0.5765091180801392, train_loss: 0.5733996629714966\n",
            "7430 val_loss: 0.5762866139411926, train_loss: 0.573211669921875\n",
            "7440 val_loss: 0.5761645436286926, train_loss: 0.5729568600654602\n",
            "7450 val_loss: 0.5758307576179504, train_loss: 0.5726682543754578\n",
            "7460 val_loss: 0.5753799676895142, train_loss: 0.5721718668937683\n",
            "7470 val_loss: 0.5751636028289795, train_loss: 0.5719831585884094\n",
            "7480 val_loss: 0.575012743473053, train_loss: 0.5717102885246277\n",
            "7490 val_loss: 0.5750105977058411, train_loss: 0.5716181993484497\n",
            "7500 val_loss: 0.5748782753944397, train_loss: 0.5714132189750671\n",
            "7510 val_loss: 0.5746845006942749, train_loss: 0.5711724758148193\n",
            "7520 val_loss: 0.5743883848190308, train_loss: 0.570948600769043\n",
            "7530 val_loss: 0.5739699006080627, train_loss: 0.570649266242981\n",
            "7540 val_loss: 0.5735743641853333, train_loss: 0.5702528953552246\n",
            "7550 val_loss: 0.5733144879341125, train_loss: 0.5699028372764587\n",
            "7560 val_loss: 0.5729047060012817, train_loss: 0.5695506930351257\n",
            "7570 val_loss: 0.5728198289871216, train_loss: 0.5693797469139099\n",
            "7580 val_loss: 0.5728932619094849, train_loss: 0.5694553256034851\n",
            "7590 val_loss: 0.5726931095123291, train_loss: 0.5691934823989868\n",
            "7600 val_loss: 0.5725205540657043, train_loss: 0.5689281821250916\n",
            "7610 val_loss: 0.5723090171813965, train_loss: 0.5687228441238403\n",
            "7620 val_loss: 0.572010338306427, train_loss: 0.5684205889701843\n",
            "7630 val_loss: 0.5718810558319092, train_loss: 0.5683597922325134\n",
            "7640 val_loss: 0.5717076063156128, train_loss: 0.5679892897605896\n",
            "7650 val_loss: 0.5717645287513733, train_loss: 0.567909300327301\n",
            "7660 val_loss: 0.5714804530143738, train_loss: 0.5675434470176697\n",
            "7670 val_loss: 0.5714109539985657, train_loss: 0.5673034191131592\n",
            "7680 val_loss: 0.5713639259338379, train_loss: 0.5672661066055298\n",
            "7690 val_loss: 0.5711878538131714, train_loss: 0.567042887210846\n",
            "7700 val_loss: 0.5710556507110596, train_loss: 0.566884458065033\n",
            "7710 val_loss: 0.5706508755683899, train_loss: 0.5663999319076538\n",
            "7720 val_loss: 0.5704617500305176, train_loss: 0.5661910176277161\n",
            "7730 val_loss: 0.5702869892120361, train_loss: 0.5658934116363525\n",
            "7740 val_loss: 0.5701376795768738, train_loss: 0.5656042098999023\n",
            "7750 val_loss: 0.5699470639228821, train_loss: 0.5652551054954529\n",
            "7760 val_loss: 0.5696990489959717, train_loss: 0.5650309920310974\n",
            "7770 val_loss: 0.569421648979187, train_loss: 0.5646175742149353\n",
            "7780 val_loss: 0.5690521001815796, train_loss: 0.5642864108085632\n",
            "7790 val_loss: 0.5687607526779175, train_loss: 0.5639300346374512\n",
            "7800 val_loss: 0.5682696104049683, train_loss: 0.5635229349136353\n",
            "7810 val_loss: 0.5677329301834106, train_loss: 0.5631181597709656\n",
            "7820 val_loss: 0.5673706531524658, train_loss: 0.5627522468566895\n",
            "7830 val_loss: 0.5671873092651367, train_loss: 0.5626639723777771\n",
            "7840 val_loss: 0.5669032335281372, train_loss: 0.5623803734779358\n",
            "7850 val_loss: 0.5666739344596863, train_loss: 0.5620889663696289\n",
            "7860 val_loss: 0.566376805305481, train_loss: 0.5615974068641663\n",
            "7870 val_loss: 0.565888524055481, train_loss: 0.5610924959182739\n",
            "7880 val_loss: 0.5654603838920593, train_loss: 0.5607726573944092\n",
            "7890 val_loss: 0.5650501251220703, train_loss: 0.5604485273361206\n",
            "7900 val_loss: 0.5646350383758545, train_loss: 0.5601282119750977\n",
            "7910 val_loss: 0.5644465684890747, train_loss: 0.5597519874572754\n",
            "7920 val_loss: 0.5639232397079468, train_loss: 0.5593249797821045\n",
            "7930 val_loss: 0.5636332631111145, train_loss: 0.5588762164115906\n",
            "7940 val_loss: 0.5632765293121338, train_loss: 0.5585710406303406\n",
            "7950 val_loss: 0.5629240870475769, train_loss: 0.558153510093689\n",
            "7960 val_loss: 0.5627232193946838, train_loss: 0.5579164624214172\n",
            "7970 val_loss: 0.5625333786010742, train_loss: 0.5575849413871765\n",
            "7980 val_loss: 0.5620073676109314, train_loss: 0.5571478605270386\n",
            "7990 val_loss: 0.5617883205413818, train_loss: 0.5567725300788879\n",
            "8000 val_loss: 0.5614304542541504, train_loss: 0.5565335154533386\n",
            "8010 val_loss: 0.5611013174057007, train_loss: 0.5562012791633606\n",
            "8020 val_loss: 0.5608526468276978, train_loss: 0.5559330582618713\n",
            "8030 val_loss: 0.5605210065841675, train_loss: 0.5556265115737915\n",
            "8040 val_loss: 0.5604294538497925, train_loss: 0.5553622841835022\n",
            "8050 val_loss: 0.560167670249939, train_loss: 0.5551490187644958\n",
            "8060 val_loss: 0.5597142577171326, train_loss: 0.5546903610229492\n",
            "8070 val_loss: 0.5595243573188782, train_loss: 0.5545305609703064\n",
            "8080 val_loss: 0.5592896342277527, train_loss: 0.5542840361595154\n",
            "8090 val_loss: 0.5591465830802917, train_loss: 0.5540099740028381\n",
            "8100 val_loss: 0.5587674379348755, train_loss: 0.5535805225372314\n",
            "8110 val_loss: 0.5582177639007568, train_loss: 0.5532262325286865\n",
            "8120 val_loss: 0.5578073859214783, train_loss: 0.5528677701950073\n",
            "8130 val_loss: 0.5573303699493408, train_loss: 0.5524010062217712\n",
            "8140 val_loss: 0.5567674040794373, train_loss: 0.551896870136261\n",
            "8150 val_loss: 0.5565589070320129, train_loss: 0.5515360236167908\n",
            "8160 val_loss: 0.5561475157737732, train_loss: 0.5511977672576904\n",
            "8170 val_loss: 0.555834949016571, train_loss: 0.5508058667182922\n",
            "8180 val_loss: 0.5554825663566589, train_loss: 0.5504249930381775\n",
            "8190 val_loss: 0.5551462769508362, train_loss: 0.5500532388687134\n",
            "8200 val_loss: 0.5548253655433655, train_loss: 0.5496978759765625\n",
            "8210 val_loss: 0.554410457611084, train_loss: 0.5492962598800659\n",
            "8220 val_loss: 0.5539634227752686, train_loss: 0.5488864779472351\n",
            "8230 val_loss: 0.5537739992141724, train_loss: 0.5485882759094238\n",
            "8240 val_loss: 0.553443431854248, train_loss: 0.5481787919998169\n",
            "8250 val_loss: 0.5529163479804993, train_loss: 0.5476253032684326\n",
            "8260 val_loss: 0.5527075529098511, train_loss: 0.547154426574707\n",
            "8270 val_loss: 0.5525065064430237, train_loss: 0.5467795729637146\n",
            "8280 val_loss: 0.5521275401115417, train_loss: 0.5463750958442688\n",
            "8290 val_loss: 0.5517027974128723, train_loss: 0.5457976460456848\n",
            "8300 val_loss: 0.5513257384300232, train_loss: 0.545436441898346\n",
            "8310 val_loss: 0.5508297681808472, train_loss: 0.5449479222297668\n",
            "8320 val_loss: 0.5503941178321838, train_loss: 0.544459879398346\n",
            "8330 val_loss: 0.5499926805496216, train_loss: 0.5440173745155334\n",
            "8340 val_loss: 0.5496637225151062, train_loss: 0.5435672402381897\n",
            "8350 val_loss: 0.549109160900116, train_loss: 0.5429826378822327\n",
            "8360 val_loss: 0.54854416847229, train_loss: 0.5424605011940002\n",
            "8370 val_loss: 0.5477657914161682, train_loss: 0.5418106913566589\n",
            "8380 val_loss: 0.5472280383110046, train_loss: 0.541143536567688\n",
            "8390 val_loss: 0.5469743013381958, train_loss: 0.5407721996307373\n",
            "8400 val_loss: 0.5466605424880981, train_loss: 0.5403562188148499\n",
            "8410 val_loss: 0.5461710691452026, train_loss: 0.5398736000061035\n",
            "8420 val_loss: 0.5458720326423645, train_loss: 0.5394770503044128\n",
            "8430 val_loss: 0.5455580949783325, train_loss: 0.539108157157898\n",
            "8440 val_loss: 0.54534512758255, train_loss: 0.5386992692947388\n",
            "8450 val_loss: 0.5446189641952515, train_loss: 0.5381196737289429\n",
            "8460 val_loss: 0.5441148281097412, train_loss: 0.5375659465789795\n",
            "8470 val_loss: 0.5436003804206848, train_loss: 0.5371369123458862\n",
            "8480 val_loss: 0.5430785417556763, train_loss: 0.5366119146347046\n",
            "8490 val_loss: 0.542617917060852, train_loss: 0.5360537767410278\n",
            "8500 val_loss: 0.5420809984207153, train_loss: 0.5355983376502991\n",
            "8510 val_loss: 0.5417879819869995, train_loss: 0.5351405739784241\n",
            "8520 val_loss: 0.5413103103637695, train_loss: 0.5346017479896545\n",
            "8530 val_loss: 0.5409598350524902, train_loss: 0.5340763330459595\n",
            "8540 val_loss: 0.540299654006958, train_loss: 0.533435046672821\n",
            "8550 val_loss: 0.5398684144020081, train_loss: 0.532783031463623\n",
            "8560 val_loss: 0.5392844676971436, train_loss: 0.5322632193565369\n",
            "8570 val_loss: 0.5388007164001465, train_loss: 0.5318087339401245\n",
            "8580 val_loss: 0.538318932056427, train_loss: 0.5313739776611328\n",
            "8590 val_loss: 0.5379120707511902, train_loss: 0.5309796929359436\n",
            "8600 val_loss: 0.5374335050582886, train_loss: 0.5304574966430664\n",
            "8610 val_loss: 0.537079393863678, train_loss: 0.5299415588378906\n",
            "8620 val_loss: 0.5366864204406738, train_loss: 0.5293999314308167\n",
            "8630 val_loss: 0.5363551378250122, train_loss: 0.529071033000946\n",
            "8640 val_loss: 0.5358933210372925, train_loss: 0.5284744501113892\n",
            "8650 val_loss: 0.5354105234146118, train_loss: 0.5278579592704773\n",
            "8660 val_loss: 0.5348381996154785, train_loss: 0.5272831320762634\n",
            "8670 val_loss: 0.5343196392059326, train_loss: 0.5267336368560791\n",
            "8680 val_loss: 0.5339288115501404, train_loss: 0.5262889266014099\n",
            "8690 val_loss: 0.5334815979003906, train_loss: 0.5257048606872559\n",
            "8700 val_loss: 0.5330407023429871, train_loss: 0.5253046751022339\n",
            "8710 val_loss: 0.5328092575073242, train_loss: 0.5249836444854736\n",
            "8720 val_loss: 0.5326018333435059, train_loss: 0.524613618850708\n",
            "8730 val_loss: 0.5321468710899353, train_loss: 0.5241336226463318\n",
            "8740 val_loss: 0.5315921306610107, train_loss: 0.5235363841056824\n",
            "8750 val_loss: 0.531122088432312, train_loss: 0.5230820178985596\n",
            "8760 val_loss: 0.5307009816169739, train_loss: 0.5226199626922607\n",
            "8770 val_loss: 0.5300995111465454, train_loss: 0.522011399269104\n",
            "8780 val_loss: 0.5297623872756958, train_loss: 0.5215601921081543\n",
            "8790 val_loss: 0.529446542263031, train_loss: 0.5211448669433594\n",
            "8800 val_loss: 0.5287135243415833, train_loss: 0.520469069480896\n",
            "8810 val_loss: 0.5282305479049683, train_loss: 0.5200563669204712\n",
            "8820 val_loss: 0.527885913848877, train_loss: 0.5196972489356995\n",
            "8830 val_loss: 0.5276472568511963, train_loss: 0.519264817237854\n",
            "8840 val_loss: 0.5273787379264832, train_loss: 0.5187109708786011\n",
            "8850 val_loss: 0.5266891121864319, train_loss: 0.5181525349617004\n",
            "8860 val_loss: 0.526261031627655, train_loss: 0.517726480960846\n",
            "8870 val_loss: 0.5258479714393616, train_loss: 0.5172895193099976\n",
            "8880 val_loss: 0.5255264043807983, train_loss: 0.5166997313499451\n",
            "8890 val_loss: 0.5251085758209229, train_loss: 0.5162149667739868\n",
            "8900 val_loss: 0.5246822237968445, train_loss: 0.5159172415733337\n",
            "8910 val_loss: 0.5243549346923828, train_loss: 0.5153590440750122\n",
            "8920 val_loss: 0.5238640904426575, train_loss: 0.5149831771850586\n",
            "8930 val_loss: 0.5234436988830566, train_loss: 0.5144872069358826\n",
            "8940 val_loss: 0.5230861306190491, train_loss: 0.5140056610107422\n",
            "8950 val_loss: 0.522917628288269, train_loss: 0.5135141015052795\n",
            "8960 val_loss: 0.522233247756958, train_loss: 0.5131499767303467\n",
            "8970 val_loss: 0.521734356880188, train_loss: 0.5125732421875\n",
            "8980 val_loss: 0.5212441682815552, train_loss: 0.5121316313743591\n",
            "8990 val_loss: 0.5208483934402466, train_loss: 0.5114489197731018\n",
            "9000 val_loss: 0.5204617381095886, train_loss: 0.5109434127807617\n",
            "9010 val_loss: 0.5199378728866577, train_loss: 0.5103961825370789\n",
            "9020 val_loss: 0.5191864967346191, train_loss: 0.5097732543945312\n",
            "9030 val_loss: 0.5186929106712341, train_loss: 0.5091558694839478\n",
            "9040 val_loss: 0.5180478096008301, train_loss: 0.5088946223258972\n",
            "9050 val_loss: 0.518036961555481, train_loss: 0.5085203051567078\n",
            "9060 val_loss: 0.5176979303359985, train_loss: 0.5080800652503967\n",
            "9070 val_loss: 0.5172165632247925, train_loss: 0.5074266195297241\n",
            "9080 val_loss: 0.5165303349494934, train_loss: 0.5068426728248596\n",
            "9090 val_loss: 0.5159690380096436, train_loss: 0.5063444375991821\n",
            "9100 val_loss: 0.515515923500061, train_loss: 0.505864143371582\n",
            "9110 val_loss: 0.5150980949401855, train_loss: 0.5052523612976074\n",
            "9120 val_loss: 0.5144509077072144, train_loss: 0.5047997236251831\n",
            "9130 val_loss: 0.5139024257659912, train_loss: 0.5043970346450806\n",
            "9140 val_loss: 0.5134055614471436, train_loss: 0.5038014650344849\n",
            "9150 val_loss: 0.5131697654724121, train_loss: 0.5032415390014648\n",
            "9160 val_loss: 0.5127626657485962, train_loss: 0.5028061866760254\n",
            "9170 val_loss: 0.5125994682312012, train_loss: 0.5024680495262146\n",
            "9180 val_loss: 0.5120528340339661, train_loss: 0.5020313262939453\n",
            "9190 val_loss: 0.5115904808044434, train_loss: 0.5014722943305969\n",
            "9200 val_loss: 0.5109277367591858, train_loss: 0.5008756518363953\n",
            "9210 val_loss: 0.510588526725769, train_loss: 0.5004169344902039\n",
            "9220 val_loss: 0.5107250809669495, train_loss: 0.5001307725906372\n",
            "9230 val_loss: 0.5098315477371216, train_loss: 0.4993937611579895\n",
            "9240 val_loss: 0.5092482566833496, train_loss: 0.4988221228122711\n",
            "9250 val_loss: 0.5086683630943298, train_loss: 0.4982846677303314\n",
            "9260 val_loss: 0.508223831653595, train_loss: 0.4977451264858246\n",
            "9270 val_loss: 0.5077279210090637, train_loss: 0.4970256984233856\n",
            "9280 val_loss: 0.5073134303092957, train_loss: 0.4965766966342926\n",
            "9290 val_loss: 0.5066691040992737, train_loss: 0.4958629608154297\n",
            "9300 val_loss: 0.5067859888076782, train_loss: 0.4955465495586395\n",
            "9310 val_loss: 0.5063894987106323, train_loss: 0.49512407183647156\n",
            "9320 val_loss: 0.5058252811431885, train_loss: 0.4944416284561157\n",
            "9330 val_loss: 0.5050772428512573, train_loss: 0.49400651454925537\n",
            "9340 val_loss: 0.5047901272773743, train_loss: 0.4934662878513336\n",
            "9350 val_loss: 0.5040720701217651, train_loss: 0.49285888671875\n",
            "9360 val_loss: 0.5038490891456604, train_loss: 0.4923841953277588\n",
            "9370 val_loss: 0.5036454200744629, train_loss: 0.49200689792633057\n",
            "9380 val_loss: 0.5034397840499878, train_loss: 0.4914916753768921\n",
            "9390 val_loss: 0.5029911994934082, train_loss: 0.4909944236278534\n",
            "9400 val_loss: 0.5025681257247925, train_loss: 0.4905170798301697\n",
            "9410 val_loss: 0.5019734501838684, train_loss: 0.4899144470691681\n",
            "9420 val_loss: 0.501374363899231, train_loss: 0.48916736245155334\n",
            "9430 val_loss: 0.5009371638298035, train_loss: 0.488549143075943\n",
            "9440 val_loss: 0.5004382133483887, train_loss: 0.487964004278183\n",
            "9450 val_loss: 0.50029057264328, train_loss: 0.48752593994140625\n",
            "9460 val_loss: 0.5000388026237488, train_loss: 0.4869779944419861\n",
            "9470 val_loss: 0.49945908784866333, train_loss: 0.48631536960601807\n",
            "9480 val_loss: 0.4988836646080017, train_loss: 0.4856579899787903\n",
            "9490 val_loss: 0.49873873591423035, train_loss: 0.4852414131164551\n",
            "9500 val_loss: 0.49834245443344116, train_loss: 0.484792560338974\n",
            "9510 val_loss: 0.49820396304130554, train_loss: 0.4844092130661011\n",
            "9520 val_loss: 0.4978068172931671, train_loss: 0.4840277135372162\n",
            "9530 val_loss: 0.4974566102027893, train_loss: 0.4833705723285675\n",
            "9540 val_loss: 0.497414231300354, train_loss: 0.48312875628471375\n",
            "9550 val_loss: 0.4972444772720337, train_loss: 0.48270273208618164\n",
            "9560 val_loss: 0.4967101812362671, train_loss: 0.48229750990867615\n",
            "9570 val_loss: 0.49600425362586975, train_loss: 0.4817028343677521\n",
            "9580 val_loss: 0.4954422414302826, train_loss: 0.480947345495224\n",
            "9590 val_loss: 0.4953088164329529, train_loss: 0.4806203246116638\n",
            "9600 val_loss: 0.49477341771125793, train_loss: 0.48015889525413513\n",
            "9610 val_loss: 0.49457669258117676, train_loss: 0.47978779673576355\n",
            "9620 val_loss: 0.49386066198349, train_loss: 0.47911715507507324\n",
            "9630 val_loss: 0.49359720945358276, train_loss: 0.47862520813941956\n",
            "9640 val_loss: 0.4934767782688141, train_loss: 0.4780697226524353\n",
            "9650 val_loss: 0.4928745627403259, train_loss: 0.4776116609573364\n",
            "9660 val_loss: 0.4927624762058258, train_loss: 0.47704657912254333\n",
            "9670 val_loss: 0.49245181679725647, train_loss: 0.47646138072013855\n",
            "9680 val_loss: 0.49206823110580444, train_loss: 0.47601771354675293\n",
            "9690 val_loss: 0.4914833605289459, train_loss: 0.4754348695278168\n",
            "9700 val_loss: 0.4912189841270447, train_loss: 0.47510722279548645\n",
            "9710 val_loss: 0.4908675253391266, train_loss: 0.47466975450515747\n",
            "9720 val_loss: 0.49119308590888977, train_loss: 0.4743972420692444\n",
            "9730 val_loss: 0.4904181659221649, train_loss: 0.47372549772262573\n",
            "9740 val_loss: 0.49003487825393677, train_loss: 0.473123162984848\n",
            "9750 val_loss: 0.48994308710098267, train_loss: 0.4726105034351349\n",
            "9760 val_loss: 0.4890161156654358, train_loss: 0.47190070152282715\n",
            "9770 val_loss: 0.4894143044948578, train_loss: 0.47147440910339355\n",
            "9780 val_loss: 0.4886375069618225, train_loss: 0.47069889307022095\n",
            "9790 val_loss: 0.4878866970539093, train_loss: 0.4699607491493225\n",
            "9800 val_loss: 0.4877738058567047, train_loss: 0.46944597363471985\n",
            "9810 val_loss: 0.4873165786266327, train_loss: 0.4687703847885132\n",
            "9820 val_loss: 0.48735958337783813, train_loss: 0.46834439039230347\n",
            "9830 val_loss: 0.4870743453502655, train_loss: 0.4678662419319153\n",
            "9840 val_loss: 0.4869546890258789, train_loss: 0.4675847291946411\n",
            "9850 val_loss: 0.4867902398109436, train_loss: 0.4671799838542938\n",
            "9860 val_loss: 0.4864983856678009, train_loss: 0.4664364159107208\n",
            "9870 val_loss: 0.4860296845436096, train_loss: 0.4659642279148102\n",
            "9880 val_loss: 0.4855839014053345, train_loss: 0.465411514043808\n",
            "9890 val_loss: 0.4850926995277405, train_loss: 0.4648158550262451\n",
            "9900 val_loss: 0.48450061678886414, train_loss: 0.4640634059906006\n",
            "9910 val_loss: 0.4846254587173462, train_loss: 0.4636925756931305\n",
            "9920 val_loss: 0.4841328263282776, train_loss: 0.4630699157714844\n",
            "9930 val_loss: 0.48375770449638367, train_loss: 0.4626353085041046\n",
            "9940 val_loss: 0.4832770526409149, train_loss: 0.46198198199272156\n",
            "9950 val_loss: 0.4828766882419586, train_loss: 0.46143049001693726\n",
            "9960 val_loss: 0.4825892746448517, train_loss: 0.46086999773979187\n",
            "9970 val_loss: 0.4826201796531677, train_loss: 0.46038487553596497\n",
            "9980 val_loss: 0.4819955825805664, train_loss: 0.4595222771167755\n",
            "9990 val_loss: 0.48177406191825867, train_loss: 0.4589199423789978\n",
            "10000 val_loss: 0.48148655891418457, train_loss: 0.4582827687263489\n",
            "10010 val_loss: 0.4809999465942383, train_loss: 0.4575038552284241\n",
            "10020 val_loss: 0.48122379183769226, train_loss: 0.4574151337146759\n",
            "10030 val_loss: 0.4803129732608795, train_loss: 0.45651113986968994\n",
            "10040 val_loss: 0.4795856475830078, train_loss: 0.4555785655975342\n",
            "10050 val_loss: 0.4794028103351593, train_loss: 0.45493632555007935\n",
            "10060 val_loss: 0.4792907238006592, train_loss: 0.45457977056503296\n",
            "10070 val_loss: 0.47872334718704224, train_loss: 0.4537932872772217\n",
            "10080 val_loss: 0.4783419966697693, train_loss: 0.45321664214134216\n",
            "10090 val_loss: 0.47787681221961975, train_loss: 0.45237234234809875\n",
            "10100 val_loss: 0.4774121642112732, train_loss: 0.4516473114490509\n",
            "10110 val_loss: 0.4775559902191162, train_loss: 0.4512118101119995\n",
            "10120 val_loss: 0.47693315148353577, train_loss: 0.450338751077652\n",
            "10130 val_loss: 0.476776659488678, train_loss: 0.4498814046382904\n",
            "10140 val_loss: 0.47623926401138306, train_loss: 0.44909340143203735\n",
            "10150 val_loss: 0.47631022334098816, train_loss: 0.4487439692020416\n",
            "10160 val_loss: 0.47550511360168457, train_loss: 0.4477975070476532\n",
            "10170 val_loss: 0.4753131866455078, train_loss: 0.4471980631351471\n",
            "10180 val_loss: 0.47502073645591736, train_loss: 0.4464968740940094\n",
            "10190 val_loss: 0.4746330678462982, train_loss: 0.4457336664199829\n",
            "10200 val_loss: 0.4735904932022095, train_loss: 0.44465988874435425\n",
            "10210 val_loss: 0.4731824994087219, train_loss: 0.4440244436264038\n",
            "10220 val_loss: 0.4732377231121063, train_loss: 0.44367438554763794\n",
            "10230 val_loss: 0.4730481505393982, train_loss: 0.4431215524673462\n",
            "10240 val_loss: 0.47243717312812805, train_loss: 0.44232264161109924\n",
            "10250 val_loss: 0.4719623327255249, train_loss: 0.4415241479873657\n",
            "10260 val_loss: 0.47188040614128113, train_loss: 0.4410529136657715\n",
            "10270 val_loss: 0.4716194272041321, train_loss: 0.44047045707702637\n",
            "10280 val_loss: 0.47091493010520935, train_loss: 0.4393948018550873\n",
            "10290 val_loss: 0.4703739583492279, train_loss: 0.438611775636673\n",
            "10300 val_loss: 0.4699818193912506, train_loss: 0.4377719461917877\n",
            "10310 val_loss: 0.4697372019290924, train_loss: 0.4373723268508911\n",
            "10320 val_loss: 0.46988731622695923, train_loss: 0.4370933175086975\n",
            "10330 val_loss: 0.46934372186660767, train_loss: 0.43629440665245056\n",
            "10340 val_loss: 0.4690547287464142, train_loss: 0.43572360277175903\n",
            "10350 val_loss: 0.4684008061885834, train_loss: 0.434844970703125\n",
            "10360 val_loss: 0.4681066870689392, train_loss: 0.43426409363746643\n",
            "10370 val_loss: 0.4677903354167938, train_loss: 0.4336620271205902\n",
            "10380 val_loss: 0.46716761589050293, train_loss: 0.4327409267425537\n",
            "10390 val_loss: 0.4666055142879486, train_loss: 0.43173113465309143\n",
            "10400 val_loss: 0.4662087857723236, train_loss: 0.4311388432979584\n",
            "10410 val_loss: 0.4659012258052826, train_loss: 0.4305126667022705\n",
            "10420 val_loss: 0.46559393405914307, train_loss: 0.4297943115234375\n",
            "10430 val_loss: 0.4653145968914032, train_loss: 0.42902475595474243\n",
            "10440 val_loss: 0.46487554907798767, train_loss: 0.42824578285217285\n",
            "10450 val_loss: 0.46465858817100525, train_loss: 0.4276987910270691\n",
            "10460 val_loss: 0.4641827642917633, train_loss: 0.4267690181732178\n",
            "10470 val_loss: 0.46352705359458923, train_loss: 0.4257389008998871\n",
            "10480 val_loss: 0.4630195200443268, train_loss: 0.4247779846191406\n",
            "10490 val_loss: 0.46319717168807983, train_loss: 0.42468172311782837\n",
            "10500 val_loss: 0.46279776096343994, train_loss: 0.42377969622612\n",
            "10510 val_loss: 0.46226221323013306, train_loss: 0.42281848192214966\n",
            "10520 val_loss: 0.4619312286376953, train_loss: 0.4220605194568634\n",
            "10530 val_loss: 0.46195533871650696, train_loss: 0.4217066466808319\n",
            "10540 val_loss: 0.46157708764076233, train_loss: 0.4209837317466736\n",
            "10550 val_loss: 0.4612847864627838, train_loss: 0.42030590772628784\n",
            "10560 val_loss: 0.4605666697025299, train_loss: 0.4191214442253113\n",
            "10570 val_loss: 0.460430383682251, train_loss: 0.41872137784957886\n",
            "10580 val_loss: 0.4601356089115143, train_loss: 0.41814687848091125\n",
            "10590 val_loss: 0.46002137660980225, train_loss: 0.41767701506614685\n",
            "10600 val_loss: 0.459499716758728, train_loss: 0.41686302423477173\n",
            "10610 val_loss: 0.4585510790348053, train_loss: 0.4156017005443573\n",
            "10620 val_loss: 0.4580916464328766, train_loss: 0.41462796926498413\n",
            "10630 val_loss: 0.4575422406196594, train_loss: 0.4137800931930542\n",
            "10640 val_loss: 0.45771270990371704, train_loss: 0.4134332835674286\n",
            "10650 val_loss: 0.45706304907798767, train_loss: 0.41259121894836426\n",
            "10660 val_loss: 0.4563401937484741, train_loss: 0.4116199314594269\n",
            "10670 val_loss: 0.4557796120643616, train_loss: 0.4106506109237671\n",
            "10680 val_loss: 0.4556485712528229, train_loss: 0.410065621137619\n",
            "10690 val_loss: 0.4553941488265991, train_loss: 0.4095713198184967\n",
            "10700 val_loss: 0.4551149010658264, train_loss: 0.4089701175689697\n",
            "10710 val_loss: 0.4544667601585388, train_loss: 0.4081117808818817\n",
            "10720 val_loss: 0.45427295565605164, train_loss: 0.4076717793941498\n",
            "10730 val_loss: 0.45425114035606384, train_loss: 0.4071114957332611\n",
            "10740 val_loss: 0.4535001516342163, train_loss: 0.40620312094688416\n",
            "10750 val_loss: 0.4523027837276459, train_loss: 0.4047715961933136\n",
            "10760 val_loss: 0.45192310214042664, train_loss: 0.40402477979660034\n",
            "10770 val_loss: 0.4515877664089203, train_loss: 0.40320906043052673\n",
            "10780 val_loss: 0.4516056478023529, train_loss: 0.40277722477912903\n",
            "10790 val_loss: 0.45156314969062805, train_loss: 0.4025126099586487\n",
            "10800 val_loss: 0.45122578740119934, train_loss: 0.40188202261924744\n",
            "10810 val_loss: 0.4510415494441986, train_loss: 0.4013214111328125\n",
            "10820 val_loss: 0.451053261756897, train_loss: 0.40093061327934265\n",
            "10830 val_loss: 0.4507072865962982, train_loss: 0.4003596901893616\n",
            "10840 val_loss: 0.44939562678337097, train_loss: 0.3986983299255371\n",
            "10850 val_loss: 0.44920095801353455, train_loss: 0.39805006980895996\n",
            "10860 val_loss: 0.44874054193496704, train_loss: 0.3973565101623535\n",
            "10870 val_loss: 0.4487217962741852, train_loss: 0.39684781432151794\n",
            "10880 val_loss: 0.4484124779701233, train_loss: 0.3964194357395172\n",
            "10890 val_loss: 0.4475244879722595, train_loss: 0.39518025517463684\n",
            "10900 val_loss: 0.4475800693035126, train_loss: 0.3948631286621094\n",
            "10910 val_loss: 0.44713565707206726, train_loss: 0.39423292875289917\n",
            "10920 val_loss: 0.4468764364719391, train_loss: 0.39319688081741333\n",
            "10930 val_loss: 0.44638532400131226, train_loss: 0.3928476870059967\n",
            "10940 val_loss: 0.4455230236053467, train_loss: 0.39153531193733215\n",
            "10950 val_loss: 0.44546639919281006, train_loss: 0.3911722004413605\n",
            "10960 val_loss: 0.4450552463531494, train_loss: 0.3902333378791809\n",
            "10970 val_loss: 0.44475606083869934, train_loss: 0.3896922171115875\n",
            "10980 val_loss: 0.44444194436073303, train_loss: 0.3891347050666809\n",
            "10990 val_loss: 0.44438987970352173, train_loss: 0.3884715735912323\n",
            "11000 val_loss: 0.44444283843040466, train_loss: 0.38853782415390015\n",
            "11010 val_loss: 0.44389671087265015, train_loss: 0.3875483572483063\n",
            "11020 val_loss: 0.4433951675891876, train_loss: 0.3867247402667999\n",
            "11030 val_loss: 0.44285088777542114, train_loss: 0.38590097427368164\n",
            "11040 val_loss: 0.4428493082523346, train_loss: 0.38549867272377014\n",
            "11050 val_loss: 0.4428698718547821, train_loss: 0.3855905830860138\n",
            "11060 val_loss: 0.4424258768558502, train_loss: 0.3847931921482086\n",
            "11070 val_loss: 0.442177951335907, train_loss: 0.38426515460014343\n",
            "11080 val_loss: 0.44194358587265015, train_loss: 0.3833002746105194\n",
            "11090 val_loss: 0.44170325994491577, train_loss: 0.3829129934310913\n",
            "11100 val_loss: 0.44124749302864075, train_loss: 0.38216307759284973\n",
            "11110 val_loss: 0.4409222900867462, train_loss: 0.38179564476013184\n",
            "11120 val_loss: 0.4403811991214752, train_loss: 0.3808698058128357\n",
            "11130 val_loss: 0.44043949246406555, train_loss: 0.38055548071861267\n",
            "11140 val_loss: 0.4400310516357422, train_loss: 0.3800167143344879\n",
            "11150 val_loss: 0.4398175776004791, train_loss: 0.37946662306785583\n",
            "11160 val_loss: 0.43940284848213196, train_loss: 0.379031240940094\n",
            "11170 val_loss: 0.43899980187416077, train_loss: 0.37848353385925293\n",
            "11180 val_loss: 0.4387482702732086, train_loss: 0.37806597352027893\n",
            "11190 val_loss: 0.43865498900413513, train_loss: 0.37741631269454956\n",
            "11200 val_loss: 0.43819868564605713, train_loss: 0.37715211510658264\n",
            "11210 val_loss: 0.4378955364227295, train_loss: 0.376285582780838\n",
            "11220 val_loss: 0.43742576241493225, train_loss: 0.3757694363594055\n",
            "11230 val_loss: 0.43698763847351074, train_loss: 0.3753402829170227\n",
            "11240 val_loss: 0.43684664368629456, train_loss: 0.37528684735298157\n",
            "11250 val_loss: 0.4362860321998596, train_loss: 0.37455686926841736\n",
            "11260 val_loss: 0.4361670911312103, train_loss: 0.37427762150764465\n",
            "11270 val_loss: 0.43542933464050293, train_loss: 0.3736320734024048\n",
            "11280 val_loss: 0.4351537823677063, train_loss: 0.3732534646987915\n",
            "11290 val_loss: 0.43504422903060913, train_loss: 0.37268292903900146\n",
            "11300 val_loss: 0.4344334006309509, train_loss: 0.37235715985298157\n",
            "11310 val_loss: 0.43418774008750916, train_loss: 0.3717546761035919\n",
            "11320 val_loss: 0.4338325262069702, train_loss: 0.3716247081756592\n",
            "11330 val_loss: 0.4335687756538391, train_loss: 0.37116631865501404\n",
            "11340 val_loss: 0.43327394127845764, train_loss: 0.3707430958747864\n",
            "11350 val_loss: 0.4331215023994446, train_loss: 0.37094971537590027\n",
            "11360 val_loss: 0.43258386850357056, train_loss: 0.3703310191631317\n",
            "11370 val_loss: 0.4318076968193054, train_loss: 0.3691871166229248\n",
            "11380 val_loss: 0.43163639307022095, train_loss: 0.36836573481559753\n",
            "11390 val_loss: 0.43130093812942505, train_loss: 0.36795446276664734\n",
            "11400 val_loss: 0.43073973059654236, train_loss: 0.3673851490020752\n",
            "11410 val_loss: 0.4302777349948883, train_loss: 0.36660346388816833\n",
            "11420 val_loss: 0.4300953149795532, train_loss: 0.3662049174308777\n",
            "11430 val_loss: 0.4296289086341858, train_loss: 0.3653225004673004\n",
            "11440 val_loss: 0.4293609857559204, train_loss: 0.3647425174713135\n",
            "11450 val_loss: 0.42900916934013367, train_loss: 0.3644504249095917\n",
            "11460 val_loss: 0.4286351799964905, train_loss: 0.36399126052856445\n",
            "11470 val_loss: 0.42841702699661255, train_loss: 0.36358389258384705\n",
            "11480 val_loss: 0.4282263219356537, train_loss: 0.36344999074935913\n",
            "11490 val_loss: 0.4278545379638672, train_loss: 0.36287978291511536\n",
            "11500 val_loss: 0.4277168810367584, train_loss: 0.3627345561981201\n",
            "11510 val_loss: 0.4274123013019562, train_loss: 0.36226797103881836\n",
            "11520 val_loss: 0.42690509557724, train_loss: 0.3616940677165985\n",
            "11530 val_loss: 0.4262664020061493, train_loss: 0.36094439029693604\n",
            "11540 val_loss: 0.4256003201007843, train_loss: 0.3600136637687683\n",
            "11550 val_loss: 0.4252794682979584, train_loss: 0.3593892753124237\n",
            "11560 val_loss: 0.4249694347381592, train_loss: 0.3589618504047394\n",
            "11570 val_loss: 0.4247713088989258, train_loss: 0.35890913009643555\n",
            "11580 val_loss: 0.424638032913208, train_loss: 0.3585208058357239\n",
            "11590 val_loss: 0.4244438707828522, train_loss: 0.3579464256763458\n",
            "11600 val_loss: 0.4237917363643646, train_loss: 0.35734981298446655\n",
            "11610 val_loss: 0.42350637912750244, train_loss: 0.3566010594367981\n",
            "11620 val_loss: 0.42324262857437134, train_loss: 0.3568127155303955\n",
            "11630 val_loss: 0.42372262477874756, train_loss: 0.35728585720062256\n",
            "11640 val_loss: 0.422493577003479, train_loss: 0.3554280996322632\n",
            "11650 val_loss: 0.4218377470970154, train_loss: 0.35488685965538025\n",
            "11660 val_loss: 0.4217696487903595, train_loss: 0.35466626286506653\n",
            "11670 val_loss: 0.4215751886367798, train_loss: 0.35422539710998535\n",
            "11680 val_loss: 0.4209655523300171, train_loss: 0.3538654148578644\n",
            "11690 val_loss: 0.42077845335006714, train_loss: 0.3536194860935211\n",
            "11700 val_loss: 0.42025530338287354, train_loss: 0.3532699644565582\n",
            "11710 val_loss: 0.41998857259750366, train_loss: 0.35290002822875977\n",
            "11720 val_loss: 0.41937968134880066, train_loss: 0.35248029232025146\n",
            "11730 val_loss: 0.41913458704948425, train_loss: 0.35213059186935425\n",
            "11740 val_loss: 0.4187038540840149, train_loss: 0.3514496088027954\n",
            "11750 val_loss: 0.4185199737548828, train_loss: 0.3511122167110443\n",
            "11760 val_loss: 0.4178224205970764, train_loss: 0.35011613368988037\n",
            "11770 val_loss: 0.4178164303302765, train_loss: 0.35013824701309204\n",
            "11780 val_loss: 0.4174952805042267, train_loss: 0.34981074929237366\n",
            "11790 val_loss: 0.4172634780406952, train_loss: 0.3491847813129425\n",
            "11800 val_loss: 0.41685110330581665, train_loss: 0.349133163690567\n",
            "11810 val_loss: 0.4165888726711273, train_loss: 0.34882956743240356\n",
            "11820 val_loss: 0.41580432653427124, train_loss: 0.34818828105926514\n",
            "11830 val_loss: 0.41526007652282715, train_loss: 0.3477970361709595\n",
            "11840 val_loss: 0.41545459628105164, train_loss: 0.3477573096752167\n",
            "11850 val_loss: 0.4149375557899475, train_loss: 0.34721335768699646\n",
            "11860 val_loss: 0.41480833292007446, train_loss: 0.34698984026908875\n",
            "11870 val_loss: 0.4143558740615845, train_loss: 0.3463955819606781\n",
            "11880 val_loss: 0.41390615701675415, train_loss: 0.3459234833717346\n",
            "11890 val_loss: 0.4137309789657593, train_loss: 0.34563297033309937\n",
            "11900 val_loss: 0.4132474660873413, train_loss: 0.3448406159877777\n",
            "11910 val_loss: 0.4127953052520752, train_loss: 0.3445771634578705\n",
            "11920 val_loss: 0.41245752573013306, train_loss: 0.3439819812774658\n",
            "11930 val_loss: 0.4123479723930359, train_loss: 0.3440189063549042\n",
            "11940 val_loss: 0.4120277762413025, train_loss: 0.3436436057090759\n",
            "11950 val_loss: 0.4117847979068756, train_loss: 0.34300723671913147\n",
            "11960 val_loss: 0.4114006459712982, train_loss: 0.3426606357097626\n",
            "11970 val_loss: 0.4116816222667694, train_loss: 0.34260740876197815\n",
            "11980 val_loss: 0.41090455651283264, train_loss: 0.34204402565956116\n",
            "11990 val_loss: 0.41062846779823303, train_loss: 0.3416717052459717\n",
            "12000 val_loss: 0.41033148765563965, train_loss: 0.3412555456161499\n",
            "12010 val_loss: 0.41025665402412415, train_loss: 0.3411904275417328\n",
            "12020 val_loss: 0.40993762016296387, train_loss: 0.34080976247787476\n",
            "12030 val_loss: 0.4095838665962219, train_loss: 0.3404026925563812\n",
            "12040 val_loss: 0.4089435040950775, train_loss: 0.33948150277137756\n",
            "12050 val_loss: 0.40874943137168884, train_loss: 0.3392297029495239\n",
            "12060 val_loss: 0.4085501730442047, train_loss: 0.3388786017894745\n",
            "12070 val_loss: 0.40795162320137024, train_loss: 0.3382301330566406\n",
            "12080 val_loss: 0.40766406059265137, train_loss: 0.33797335624694824\n",
            "12090 val_loss: 0.4074694812297821, train_loss: 0.3375180959701538\n",
            "12100 val_loss: 0.40731358528137207, train_loss: 0.33730947971343994\n",
            "12110 val_loss: 0.4068542718887329, train_loss: 0.33705762028694153\n",
            "12120 val_loss: 0.4064609110355377, train_loss: 0.3366444706916809\n",
            "12130 val_loss: 0.4061850905418396, train_loss: 0.33627575635910034\n",
            "12140 val_loss: 0.40588900446891785, train_loss: 0.3357715904712677\n",
            "12150 val_loss: 0.40583574771881104, train_loss: 0.3356417715549469\n",
            "12160 val_loss: 0.40567994117736816, train_loss: 0.3354782164096832\n",
            "12170 val_loss: 0.40536925196647644, train_loss: 0.3352876901626587\n",
            "12180 val_loss: 0.4053085446357727, train_loss: 0.3351975679397583\n",
            "12190 val_loss: 0.40508583188056946, train_loss: 0.3347521424293518\n",
            "12200 val_loss: 0.40422454476356506, train_loss: 0.33424198627471924\n",
            "12210 val_loss: 0.4040427505970001, train_loss: 0.3339853882789612\n",
            "12220 val_loss: 0.404005765914917, train_loss: 0.33376383781433105\n",
            "12230 val_loss: 0.4037610590457916, train_loss: 0.3334144353866577\n",
            "12240 val_loss: 0.4036567211151123, train_loss: 0.3333526849746704\n",
            "12250 val_loss: 0.40332794189453125, train_loss: 0.3328405022621155\n",
            "12260 val_loss: 0.4028378427028656, train_loss: 0.3323792815208435\n",
            "12270 val_loss: 0.4024471938610077, train_loss: 0.3318566381931305\n",
            "12280 val_loss: 0.40262290835380554, train_loss: 0.33221930265426636\n",
            "12290 val_loss: 0.401913046836853, train_loss: 0.3317554295063019\n",
            "12300 val_loss: 0.40187281370162964, train_loss: 0.331579327583313\n",
            "12310 val_loss: 0.40169715881347656, train_loss: 0.33118098974227905\n",
            "12320 val_loss: 0.40137526392936707, train_loss: 0.33063140511512756\n",
            "12330 val_loss: 0.4015766680240631, train_loss: 0.3303776979446411\n",
            "12340 val_loss: 0.4009877145290375, train_loss: 0.3301945626735687\n",
            "12350 val_loss: 0.40084075927734375, train_loss: 0.3298339545726776\n",
            "12360 val_loss: 0.4006800353527069, train_loss: 0.32966241240501404\n",
            "12370 val_loss: 0.40022018551826477, train_loss: 0.3294895589351654\n",
            "12380 val_loss: 0.39980578422546387, train_loss: 0.3289993405342102\n",
            "12390 val_loss: 0.399460107088089, train_loss: 0.3287792503833771\n",
            "12400 val_loss: 0.3991880416870117, train_loss: 0.3286573588848114\n",
            "12410 val_loss: 0.3991536498069763, train_loss: 0.32844114303588867\n",
            "12420 val_loss: 0.3993440270423889, train_loss: 0.32836708426475525\n",
            "12430 val_loss: 0.3987422287464142, train_loss: 0.3277842402458191\n",
            "12440 val_loss: 0.39853450655937195, train_loss: 0.3273220956325531\n",
            "12450 val_loss: 0.3981889486312866, train_loss: 0.3270924687385559\n",
            "12460 val_loss: 0.3981632888317108, train_loss: 0.32706332206726074\n",
            "12470 val_loss: 0.39791879057884216, train_loss: 0.3265751004219055\n",
            "12480 val_loss: 0.39745965600013733, train_loss: 0.3262762427330017\n",
            "12490 val_loss: 0.39763641357421875, train_loss: 0.32599660754203796\n",
            "12500 val_loss: 0.39700427651405334, train_loss: 0.3255982995033264\n",
            "12510 val_loss: 0.3973897695541382, train_loss: 0.32555586099624634\n",
            "12520 val_loss: 0.3966665267944336, train_loss: 0.32496166229248047\n",
            "12530 val_loss: 0.39618009328842163, train_loss: 0.3246687352657318\n",
            "12540 val_loss: 0.3966900110244751, train_loss: 0.3247615694999695\n",
            "12550 val_loss: 0.3962439000606537, train_loss: 0.3246610462665558\n",
            "12560 val_loss: 0.3961460590362549, train_loss: 0.32404470443725586\n",
            "12570 val_loss: 0.3957330584526062, train_loss: 0.3237013518810272\n",
            "12580 val_loss: 0.39537715911865234, train_loss: 0.323348730802536\n",
            "12590 val_loss: 0.3952661156654358, train_loss: 0.32330045104026794\n",
            "12600 val_loss: 0.39503541588783264, train_loss: 0.3230847716331482\n",
            "12610 val_loss: 0.39432471990585327, train_loss: 0.3225325047969818\n",
            "12620 val_loss: 0.39432770013809204, train_loss: 0.3224509358406067\n",
            "12630 val_loss: 0.39399096369743347, train_loss: 0.32218605279922485\n",
            "12640 val_loss: 0.39377325773239136, train_loss: 0.32204651832580566\n",
            "12650 val_loss: 0.39376139640808105, train_loss: 0.32174786925315857\n",
            "12660 val_loss: 0.3935029208660126, train_loss: 0.3215450048446655\n",
            "12670 val_loss: 0.3933590352535248, train_loss: 0.3211081326007843\n",
            "12680 val_loss: 0.39317411184310913, train_loss: 0.3207157552242279\n",
            "12690 val_loss: 0.39266136288642883, train_loss: 0.3202696442604065\n",
            "12700 val_loss: 0.39238062500953674, train_loss: 0.31999388337135315\n",
            "12710 val_loss: 0.39235758781433105, train_loss: 0.3197166919708252\n",
            "12720 val_loss: 0.3917948007583618, train_loss: 0.3192850947380066\n",
            "12730 val_loss: 0.39139434695243835, train_loss: 0.3187488317489624\n",
            "12740 val_loss: 0.39142677187919617, train_loss: 0.3187611699104309\n",
            "12750 val_loss: 0.39134928584098816, train_loss: 0.3184865117073059\n",
            "12760 val_loss: 0.3913571536540985, train_loss: 0.31845369935035706\n",
            "12770 val_loss: 0.3915122449398041, train_loss: 0.3187638819217682\n",
            "12780 val_loss: 0.39019644260406494, train_loss: 0.31763505935668945\n",
            "12790 val_loss: 0.39004290103912354, train_loss: 0.3175099492073059\n",
            "12800 val_loss: 0.38973546028137207, train_loss: 0.31714826822280884\n",
            "12810 val_loss: 0.3895806670188904, train_loss: 0.31680363416671753\n",
            "12820 val_loss: 0.3895205855369568, train_loss: 0.31650012731552124\n",
            "12830 val_loss: 0.38894087076187134, train_loss: 0.3161632716655731\n",
            "12840 val_loss: 0.38872650265693665, train_loss: 0.31557315587997437\n",
            "12850 val_loss: 0.38825058937072754, train_loss: 0.31515663862228394\n",
            "12860 val_loss: 0.3883209824562073, train_loss: 0.3149058222770691\n",
            "12870 val_loss: 0.388200581073761, train_loss: 0.3149707019329071\n",
            "12880 val_loss: 0.3881700038909912, train_loss: 0.3150145709514618\n",
            "12890 val_loss: 0.3878048360347748, train_loss: 0.31467652320861816\n",
            "12900 val_loss: 0.3873959481716156, train_loss: 0.31391727924346924\n",
            "12910 val_loss: 0.38774314522743225, train_loss: 0.3140222728252411\n",
            "12920 val_loss: 0.3867862820625305, train_loss: 0.3132627010345459\n",
            "12930 val_loss: 0.3863476812839508, train_loss: 0.3129485845565796\n",
            "12940 val_loss: 0.3862346410751343, train_loss: 0.31276464462280273\n",
            "12950 val_loss: 0.38600584864616394, train_loss: 0.3129025399684906\n",
            "12960 val_loss: 0.38556352257728577, train_loss: 0.3121661841869354\n",
            "12970 val_loss: 0.3853060305118561, train_loss: 0.3118837773799896\n",
            "12980 val_loss: 0.3855692446231842, train_loss: 0.3118393123149872\n",
            "12990 val_loss: 0.3848353922367096, train_loss: 0.3111642003059387\n",
            "13000 val_loss: 0.3846852481365204, train_loss: 0.31105929613113403\n",
            "13010 val_loss: 0.38475632667541504, train_loss: 0.31079739332199097\n",
            "13020 val_loss: 0.3842770755290985, train_loss: 0.31006696820259094\n",
            "13030 val_loss: 0.3841034173965454, train_loss: 0.3099963068962097\n",
            "13040 val_loss: 0.38358306884765625, train_loss: 0.3096318244934082\n",
            "13050 val_loss: 0.38361304998397827, train_loss: 0.30956876277923584\n",
            "13060 val_loss: 0.38316646218299866, train_loss: 0.30913862586021423\n",
            "13070 val_loss: 0.3826812505722046, train_loss: 0.30864274501800537\n",
            "13080 val_loss: 0.38291820883750916, train_loss: 0.3086616098880768\n",
            "13090 val_loss: 0.3823578357696533, train_loss: 0.3082190155982971\n",
            "13100 val_loss: 0.3819451630115509, train_loss: 0.30796387791633606\n",
            "13110 val_loss: 0.38199344277381897, train_loss: 0.30783015489578247\n",
            "13120 val_loss: 0.3820773959159851, train_loss: 0.3076430857181549\n",
            "13130 val_loss: 0.38186705112457275, train_loss: 0.3076665997505188\n",
            "13140 val_loss: 0.38159099221229553, train_loss: 0.3072836995124817\n",
            "13150 val_loss: 0.3812224566936493, train_loss: 0.30677834153175354\n",
            "13160 val_loss: 0.38093918561935425, train_loss: 0.30642199516296387\n",
            "13170 val_loss: 0.3805510997772217, train_loss: 0.306247353553772\n",
            "13180 val_loss: 0.38035181164741516, train_loss: 0.3058455288410187\n",
            "13190 val_loss: 0.3802870810031891, train_loss: 0.3056165277957916\n",
            "13200 val_loss: 0.3798943758010864, train_loss: 0.3052508234977722\n",
            "13210 val_loss: 0.3796268105506897, train_loss: 0.30497780442237854\n",
            "13220 val_loss: 0.3795994222164154, train_loss: 0.30482345819473267\n",
            "13230 val_loss: 0.37910282611846924, train_loss: 0.3044273257255554\n",
            "13240 val_loss: 0.37879040837287903, train_loss: 0.30407360196113586\n",
            "13250 val_loss: 0.3787405490875244, train_loss: 0.3042418658733368\n",
            "13260 val_loss: 0.37836897373199463, train_loss: 0.30393216013908386\n",
            "13270 val_loss: 0.37781232595443726, train_loss: 0.30345413088798523\n",
            "13280 val_loss: 0.37789130210876465, train_loss: 0.30332228541374207\n",
            "13290 val_loss: 0.37739497423171997, train_loss: 0.30288612842559814\n",
            "13300 val_loss: 0.3775140345096588, train_loss: 0.3026960790157318\n",
            "13310 val_loss: 0.37703704833984375, train_loss: 0.30225253105163574\n",
            "13320 val_loss: 0.37691861391067505, train_loss: 0.3021221458911896\n",
            "13330 val_loss: 0.3768106698989868, train_loss: 0.30198657512664795\n",
            "13340 val_loss: 0.37655362486839294, train_loss: 0.30150067806243896\n",
            "13350 val_loss: 0.37633997201919556, train_loss: 0.3012646734714508\n",
            "13360 val_loss: 0.3760758340358734, train_loss: 0.3006998300552368\n",
            "13370 val_loss: 0.3762036859989166, train_loss: 0.3009229302406311\n",
            "13380 val_loss: 0.3761073052883148, train_loss: 0.30066752433776855\n",
            "13390 val_loss: 0.37570926547050476, train_loss: 0.3003770411014557\n",
            "13400 val_loss: 0.37580373883247375, train_loss: 0.30035829544067383\n",
            "13410 val_loss: 0.3749412000179291, train_loss: 0.2994851768016815\n",
            "13420 val_loss: 0.37450870871543884, train_loss: 0.29893365502357483\n",
            "13430 val_loss: 0.37456682324409485, train_loss: 0.2988475561141968\n",
            "13440 val_loss: 0.3744712471961975, train_loss: 0.29893237352371216\n",
            "13450 val_loss: 0.37431827187538147, train_loss: 0.2987765669822693\n",
            "13460 val_loss: 0.3738698363304138, train_loss: 0.2981179654598236\n",
            "13470 val_loss: 0.374003142118454, train_loss: 0.29826560616493225\n",
            "13480 val_loss: 0.373649537563324, train_loss: 0.2980203330516815\n",
            "13490 val_loss: 0.3730829358100891, train_loss: 0.29731515049934387\n",
            "13500 val_loss: 0.37291088700294495, train_loss: 0.29699385166168213\n",
            "13510 val_loss: 0.3727477788925171, train_loss: 0.2969817519187927\n",
            "13520 val_loss: 0.3726288974285126, train_loss: 0.2966127097606659\n",
            "13530 val_loss: 0.3725963234901428, train_loss: 0.2964216470718384\n",
            "13540 val_loss: 0.3726702332496643, train_loss: 0.2966534495353699\n",
            "13550 val_loss: 0.3720146119594574, train_loss: 0.29617395997047424\n",
            "13560 val_loss: 0.37173864245414734, train_loss: 0.2959798574447632\n",
            "13570 val_loss: 0.37158456444740295, train_loss: 0.2958561182022095\n",
            "13580 val_loss: 0.37174877524375916, train_loss: 0.2958150804042816\n",
            "13590 val_loss: 0.3710893988609314, train_loss: 0.295504093170166\n",
            "13600 val_loss: 0.3711879253387451, train_loss: 0.2950519323348999\n",
            "13610 val_loss: 0.3706914782524109, train_loss: 0.2947236895561218\n",
            "13620 val_loss: 0.3704964816570282, train_loss: 0.29449930787086487\n",
            "13630 val_loss: 0.37086012959480286, train_loss: 0.2947819232940674\n",
            "13640 val_loss: 0.3703739643096924, train_loss: 0.29453960061073303\n",
            "13650 val_loss: 0.3700280487537384, train_loss: 0.2941347360610962\n",
            "13660 val_loss: 0.3700040280818939, train_loss: 0.2940147817134857\n",
            "13670 val_loss: 0.36972928047180176, train_loss: 0.2936793863773346\n",
            "13680 val_loss: 0.3693566918373108, train_loss: 0.293419748544693\n",
            "13690 val_loss: 0.3693862557411194, train_loss: 0.2931838035583496\n",
            "13700 val_loss: 0.3694327771663666, train_loss: 0.2930735945701599\n",
            "13710 val_loss: 0.3690529465675354, train_loss: 0.2926797866821289\n",
            "13720 val_loss: 0.3688059449195862, train_loss: 0.29256653785705566\n",
            "13730 val_loss: 0.3686031699180603, train_loss: 0.29245468974113464\n",
            "13740 val_loss: 0.3683265149593353, train_loss: 0.29205355048179626\n",
            "13750 val_loss: 0.36825165152549744, train_loss: 0.2916692793369293\n",
            "13760 val_loss: 0.36813172698020935, train_loss: 0.2916615307331085\n",
            "13770 val_loss: 0.3678266108036041, train_loss: 0.29112133383750916\n",
            "13780 val_loss: 0.3676656484603882, train_loss: 0.29074615240097046\n",
            "13790 val_loss: 0.36758702993392944, train_loss: 0.29058337211608887\n",
            "13800 val_loss: 0.36747798323631287, train_loss: 0.29063680768013\n",
            "13810 val_loss: 0.3673965036869049, train_loss: 0.2905811369419098\n",
            "13820 val_loss: 0.36797499656677246, train_loss: 0.2911559045314789\n",
            "13830 val_loss: 0.36711418628692627, train_loss: 0.29000645875930786\n",
            "13840 val_loss: 0.3667193055152893, train_loss: 0.28962069749832153\n",
            "13850 val_loss: 0.3665132224559784, train_loss: 0.2894202470779419\n",
            "13860 val_loss: 0.3664408028125763, train_loss: 0.28930479288101196\n",
            "13870 val_loss: 0.36602070927619934, train_loss: 0.28878799080848694\n",
            "13880 val_loss: 0.3659732937812805, train_loss: 0.2885649502277374\n",
            "13890 val_loss: 0.3659615218639374, train_loss: 0.28884753584861755\n",
            "13900 val_loss: 0.3654918670654297, train_loss: 0.2882708013057709\n",
            "13910 val_loss: 0.3653338849544525, train_loss: 0.28808045387268066\n",
            "13920 val_loss: 0.3650593161582947, train_loss: 0.28790369629859924\n",
            "13930 val_loss: 0.3648408055305481, train_loss: 0.2879363000392914\n",
            "13940 val_loss: 0.36483103036880493, train_loss: 0.28809410333633423\n",
            "13950 val_loss: 0.3646467924118042, train_loss: 0.28721708059310913\n",
            "13960 val_loss: 0.36416125297546387, train_loss: 0.2869551181793213\n",
            "13970 val_loss: 0.36351943016052246, train_loss: 0.28629833459854126\n",
            "13980 val_loss: 0.3639516532421112, train_loss: 0.286532998085022\n",
            "13990 val_loss: 0.3636915981769562, train_loss: 0.28632834553718567\n",
            "14000 val_loss: 0.3638116419315338, train_loss: 0.28628024458885193\n",
            "14010 val_loss: 0.36322471499443054, train_loss: 0.285854309797287\n",
            "14020 val_loss: 0.3630894124507904, train_loss: 0.2858579158782959\n",
            "14030 val_loss: 0.36320120096206665, train_loss: 0.28588196635246277\n",
            "14040 val_loss: 0.36298316717147827, train_loss: 0.28569984436035156\n",
            "14050 val_loss: 0.3629908859729767, train_loss: 0.28531038761138916\n",
            "14060 val_loss: 0.36237677931785583, train_loss: 0.2849000096321106\n",
            "14070 val_loss: 0.36258751153945923, train_loss: 0.28491589426994324\n",
            "14080 val_loss: 0.36222919821739197, train_loss: 0.28466466069221497\n",
            "14090 val_loss: 0.36176684498786926, train_loss: 0.2841915488243103\n",
            "14100 val_loss: 0.36246976256370544, train_loss: 0.28504085540771484\n",
            "14110 val_loss: 0.3621450960636139, train_loss: 0.2844301462173462\n",
            "14120 val_loss: 0.3614795207977295, train_loss: 0.28362125158309937\n",
            "14130 val_loss: 0.36112961173057556, train_loss: 0.28311076760292053\n",
            "14140 val_loss: 0.36095818877220154, train_loss: 0.28310489654541016\n",
            "14150 val_loss: 0.3605373501777649, train_loss: 0.2829480469226837\n",
            "14160 val_loss: 0.3603518009185791, train_loss: 0.2825114130973816\n",
            "14170 val_loss: 0.3602610230445862, train_loss: 0.28228455781936646\n",
            "14180 val_loss: 0.36007124185562134, train_loss: 0.2819003760814667\n",
            "14190 val_loss: 0.3601069152355194, train_loss: 0.28204402327537537\n",
            "14200 val_loss: 0.3594379425048828, train_loss: 0.2812250852584839\n",
            "14210 val_loss: 0.3594709038734436, train_loss: 0.2813229560852051\n",
            "14220 val_loss: 0.3591955304145813, train_loss: 0.2807920277118683\n",
            "14230 val_loss: 0.3591412901878357, train_loss: 0.2809804677963257\n",
            "14240 val_loss: 0.35917308926582336, train_loss: 0.28072819113731384\n",
            "14250 val_loss: 0.3591887950897217, train_loss: 0.28064125776290894\n",
            "14260 val_loss: 0.3590991199016571, train_loss: 0.28068554401397705\n",
            "14270 val_loss: 0.3594776391983032, train_loss: 0.28075215220451355\n",
            "14280 val_loss: 0.35833150148391724, train_loss: 0.279979944229126\n",
            "14290 val_loss: 0.358925998210907, train_loss: 0.28021249175071716\n",
            "14300 val_loss: 0.3579300343990326, train_loss: 0.2796986997127533\n",
            "14310 val_loss: 0.3577452301979065, train_loss: 0.2795163094997406\n",
            "14320 val_loss: 0.35778507590293884, train_loss: 0.2796475291252136\n",
            "14330 val_loss: 0.357664555311203, train_loss: 0.2789827883243561\n",
            "14340 val_loss: 0.357734352350235, train_loss: 0.27865415811538696\n",
            "14350 val_loss: 0.35716956853866577, train_loss: 0.27820149064064026\n",
            "14360 val_loss: 0.3572176396846771, train_loss: 0.27785754203796387\n",
            "14370 val_loss: 0.3571876287460327, train_loss: 0.27736032009124756\n",
            "14380 val_loss: 0.3570774495601654, train_loss: 0.2773338556289673\n",
            "14390 val_loss: 0.3569429814815521, train_loss: 0.2770366668701172\n",
            "14400 val_loss: 0.35714060068130493, train_loss: 0.2774227261543274\n",
            "14410 val_loss: 0.3566247820854187, train_loss: 0.27693048119544983\n",
            "14420 val_loss: 0.35631388425827026, train_loss: 0.27664297819137573\n",
            "14430 val_loss: 0.35677266120910645, train_loss: 0.277151495218277\n",
            "14440 val_loss: 0.35667505860328674, train_loss: 0.27732619643211365\n",
            "14450 val_loss: 0.35638585686683655, train_loss: 0.2766420543193817\n",
            "14460 val_loss: 0.35624298453330994, train_loss: 0.27671805024147034\n",
            "14470 val_loss: 0.3558349609375, train_loss: 0.27610883116722107\n",
            "14480 val_loss: 0.35576966404914856, train_loss: 0.2761097848415375\n",
            "14490 val_loss: 0.3555428087711334, train_loss: 0.2755916118621826\n",
            "14500 val_loss: 0.35529714822769165, train_loss: 0.27554550766944885\n",
            "14510 val_loss: 0.3549468517303467, train_loss: 0.2749640941619873\n",
            "14520 val_loss: 0.3550105690956116, train_loss: 0.27497535943984985\n",
            "14530 val_loss: 0.3547036647796631, train_loss: 0.2746187150478363\n",
            "14540 val_loss: 0.3547935485839844, train_loss: 0.2740432918071747\n",
            "14550 val_loss: 0.35474640130996704, train_loss: 0.27422669529914856\n",
            "14560 val_loss: 0.35447296500205994, train_loss: 0.2739705741405487\n",
            "14570 val_loss: 0.35454991459846497, train_loss: 0.27332863211631775\n",
            "14580 val_loss: 0.3541933596134186, train_loss: 0.27307480573654175\n",
            "14590 val_loss: 0.35415634512901306, train_loss: 0.27291232347488403\n",
            "14600 val_loss: 0.35464224219322205, train_loss: 0.2729729115962982\n",
            "14610 val_loss: 0.35426095128059387, train_loss: 0.27243828773498535\n",
            "14620 val_loss: 0.35428524017333984, train_loss: 0.2723946273326874\n",
            "14630 val_loss: 0.35370078682899475, train_loss: 0.27223944664001465\n",
            "14640 val_loss: 0.3535480499267578, train_loss: 0.2718152105808258\n",
            "14650 val_loss: 0.35354119539260864, train_loss: 0.2719057500362396\n",
            "14660 val_loss: 0.3536175787448883, train_loss: 0.27126824855804443\n",
            "14670 val_loss: 0.3531605303287506, train_loss: 0.2707897424697876\n",
            "14680 val_loss: 0.35267508029937744, train_loss: 0.27058014273643494\n",
            "14690 val_loss: 0.3528361916542053, train_loss: 0.27028974890708923\n",
            "14700 val_loss: 0.3526380956172943, train_loss: 0.26978054642677307\n",
            "14710 val_loss: 0.3523596227169037, train_loss: 0.26953139901161194\n",
            "14720 val_loss: 0.3527032732963562, train_loss: 0.26923319697380066\n",
            "14730 val_loss: 0.3520461320877075, train_loss: 0.26897668838500977\n",
            "14740 val_loss: 0.35188189148902893, train_loss: 0.2691507041454315\n",
            "14750 val_loss: 0.3530559241771698, train_loss: 0.269042432308197\n",
            "14760 val_loss: 0.352429062128067, train_loss: 0.26833653450012207\n",
            "14770 val_loss: 0.3516046702861786, train_loss: 0.26810210943222046\n",
            "14780 val_loss: 0.351746141910553, train_loss: 0.2682027518749237\n",
            "14790 val_loss: 0.35148143768310547, train_loss: 0.2679957449436188\n",
            "14800 val_loss: 0.35194408893585205, train_loss: 0.26779818534851074\n",
            "14810 val_loss: 0.3513980507850647, train_loss: 0.26732829213142395\n",
            "14820 val_loss: 0.3513396084308624, train_loss: 0.266769140958786\n",
            "14830 val_loss: 0.351240873336792, train_loss: 0.2665514051914215\n",
            "14840 val_loss: 0.3508013188838959, train_loss: 0.26597949862480164\n",
            "14850 val_loss: 0.35100114345550537, train_loss: 0.2657617926597595\n",
            "14860 val_loss: 0.3508418798446655, train_loss: 0.2653861343860626\n",
            "14870 val_loss: 0.3502705991268158, train_loss: 0.26491761207580566\n",
            "14880 val_loss: 0.35009902715682983, train_loss: 0.26490259170532227\n",
            "14890 val_loss: 0.3500767648220062, train_loss: 0.26455748081207275\n",
            "14900 val_loss: 0.3509736657142639, train_loss: 0.26471030712127686\n",
            "14910 val_loss: 0.35038113594055176, train_loss: 0.26435714960098267\n",
            "14920 val_loss: 0.3503803610801697, train_loss: 0.2641559839248657\n",
            "14930 val_loss: 0.350051611661911, train_loss: 0.2633492350578308\n",
            "14940 val_loss: 0.3494414687156677, train_loss: 0.26324301958084106\n",
            "14950 val_loss: 0.3495030999183655, train_loss: 0.2633422613143921\n",
            "14960 val_loss: 0.34979838132858276, train_loss: 0.26294153928756714\n",
            "14970 val_loss: 0.34925705194473267, train_loss: 0.2625873386859894\n",
            "14980 val_loss: 0.348869651556015, train_loss: 0.2624734044075012\n",
            "14990 val_loss: 0.34923234581947327, train_loss: 0.26230549812316895\n",
            "15000 val_loss: 0.3495132625102997, train_loss: 0.2624810039997101\n",
            "15010 val_loss: 0.3486608564853668, train_loss: 0.26212531328201294\n",
            "15020 val_loss: 0.34886422753334045, train_loss: 0.2621665894985199\n",
            "15030 val_loss: 0.34893137216567993, train_loss: 0.2626665532588959\n",
            "15040 val_loss: 0.3482822775840759, train_loss: 0.26150962710380554\n",
            "15050 val_loss: 0.34906214475631714, train_loss: 0.2612532675266266\n",
            "15060 val_loss: 0.34799617528915405, train_loss: 0.26075848937034607\n",
            "15070 val_loss: 0.3485233783721924, train_loss: 0.26030537486076355\n",
            "15080 val_loss: 0.34820297360420227, train_loss: 0.2600148618221283\n",
            "15090 val_loss: 0.3485606610774994, train_loss: 0.2598820626735687\n",
            "15100 val_loss: 0.34815770387649536, train_loss: 0.2594395875930786\n",
            "15110 val_loss: 0.3474740982055664, train_loss: 0.25902625918388367\n",
            "15120 val_loss: 0.3472968637943268, train_loss: 0.2589072585105896\n",
            "15130 val_loss: 0.3468424379825592, train_loss: 0.2583588659763336\n",
            "15140 val_loss: 0.3471725881099701, train_loss: 0.2580249607563019\n",
            "15150 val_loss: 0.34703391790390015, train_loss: 0.25790104269981384\n",
            "15160 val_loss: 0.34730392694473267, train_loss: 0.25792396068573\n",
            "15170 val_loss: 0.346793532371521, train_loss: 0.2573428153991699\n",
            "15180 val_loss: 0.3465055823326111, train_loss: 0.25690826773643494\n",
            "15190 val_loss: 0.34623056650161743, train_loss: 0.25667059421539307\n",
            "15200 val_loss: 0.34638309478759766, train_loss: 0.2565322518348694\n",
            "15210 val_loss: 0.3461936414241791, train_loss: 0.2563168704509735\n",
            "15220 val_loss: 0.345704585313797, train_loss: 0.2560872733592987\n",
            "15230 val_loss: 0.34618088603019714, train_loss: 0.25608715415000916\n",
            "15240 val_loss: 0.34570708870887756, train_loss: 0.2558321952819824\n",
            "15250 val_loss: 0.3454858958721161, train_loss: 0.2555214762687683\n",
            "15260 val_loss: 0.3457963466644287, train_loss: 0.25542598962783813\n",
            "15270 val_loss: 0.3462474048137665, train_loss: 0.2552209198474884\n",
            "15280 val_loss: 0.3457132577896118, train_loss: 0.254818320274353\n",
            "15290 val_loss: 0.3455590307712555, train_loss: 0.2543346583843231\n",
            "15300 val_loss: 0.3468599021434784, train_loss: 0.25518351793289185\n",
            "15310 val_loss: 0.34552404284477234, train_loss: 0.25437983870506287\n",
            "15320 val_loss: 0.3456905484199524, train_loss: 0.2544012665748596\n",
            "15330 val_loss: 0.3447626531124115, train_loss: 0.2538800835609436\n",
            "15340 val_loss: 0.34492337703704834, train_loss: 0.2535597085952759\n",
            "15350 val_loss: 0.3458150625228882, train_loss: 0.25398313999176025\n",
            "15360 val_loss: 0.3442476689815521, train_loss: 0.2527237832546234\n",
            "15370 val_loss: 0.34400302171707153, train_loss: 0.2525028586387634\n",
            "15380 val_loss: 0.34470462799072266, train_loss: 0.2529850900173187\n",
            "15390 val_loss: 0.3442201614379883, train_loss: 0.2523537874221802\n",
            "15400 val_loss: 0.34562215209007263, train_loss: 0.2531098425388336\n",
            "15410 val_loss: 0.34461769461631775, train_loss: 0.25230294466018677\n",
            "15420 val_loss: 0.343975305557251, train_loss: 0.25142794847488403\n",
            "15430 val_loss: 0.34321653842926025, train_loss: 0.2510431408882141\n",
            "15440 val_loss: 0.3429275155067444, train_loss: 0.2509678304195404\n",
            "15450 val_loss: 0.3436695635318756, train_loss: 0.2504315674304962\n",
            "15460 val_loss: 0.3430965840816498, train_loss: 0.25032833218574524\n",
            "15470 val_loss: 0.3438807427883148, train_loss: 0.2500477731227875\n",
            "15480 val_loss: 0.3439328670501709, train_loss: 0.24995344877243042\n",
            "15490 val_loss: 0.3432922959327698, train_loss: 0.24943490326404572\n",
            "15500 val_loss: 0.34524625539779663, train_loss: 0.24991384148597717\n",
            "15510 val_loss: 0.34293103218078613, train_loss: 0.24880580604076385\n",
            "15520 val_loss: 0.3427765369415283, train_loss: 0.24867679178714752\n",
            "15530 val_loss: 0.343048095703125, train_loss: 0.24844714999198914\n",
            "15540 val_loss: 0.3432106673717499, train_loss: 0.2482830137014389\n",
            "15550 val_loss: 0.3457604944705963, train_loss: 0.24849459528923035\n",
            "15560 val_loss: 0.34334492683410645, train_loss: 0.24717627465724945\n",
            "15570 val_loss: 0.34277206659317017, train_loss: 0.24650542438030243\n",
            "15580 val_loss: 0.3426477015018463, train_loss: 0.24609029293060303\n",
            "15590 val_loss: 0.344093382358551, train_loss: 0.24606190621852875\n",
            "15600 val_loss: 0.3416663706302643, train_loss: 0.24546882510185242\n",
            "15610 val_loss: 0.34237396717071533, train_loss: 0.24474111199378967\n",
            "15620 val_loss: 0.34174108505249023, train_loss: 0.244546040892601\n",
            "15630 val_loss: 0.34348517656326294, train_loss: 0.24517421424388885\n",
            "15640 val_loss: 0.3442438840866089, train_loss: 0.24491029977798462\n",
            "15650 val_loss: 0.3409600257873535, train_loss: 0.24428264796733856\n",
            "15660 val_loss: 0.3407631814479828, train_loss: 0.24351011216640472\n",
            "15670 val_loss: 0.3408539891242981, train_loss: 0.24347802996635437\n",
            "15680 val_loss: 0.3410409390926361, train_loss: 0.2433309704065323\n",
            "15690 val_loss: 0.33997347950935364, train_loss: 0.24357974529266357\n",
            "15700 val_loss: 0.34079769253730774, train_loss: 0.24276995658874512\n",
            "15710 val_loss: 0.34190455079078674, train_loss: 0.2427966445684433\n",
            "15720 val_loss: 0.34056469798088074, train_loss: 0.24221248924732208\n",
            "15730 val_loss: 0.3403083086013794, train_loss: 0.2428121119737625\n",
            "15740 val_loss: 0.34290117025375366, train_loss: 0.24242253601551056\n",
            "15750 val_loss: 0.34152066707611084, train_loss: 0.2422083467245102\n",
            "15760 val_loss: 0.3405560255050659, train_loss: 0.2418670803308487\n",
            "15770 val_loss: 0.3408677875995636, train_loss: 0.2416154146194458\n",
            "15780 val_loss: 0.3406526446342468, train_loss: 0.24154065549373627\n",
            "15790 val_loss: 0.3405994176864624, train_loss: 0.2412431836128235\n",
            "15800 val_loss: 0.3411620557308197, train_loss: 0.2409811019897461\n",
            "15810 val_loss: 0.3397412896156311, train_loss: 0.24048390984535217\n",
            "15820 val_loss: 0.3416055142879486, train_loss: 0.2409224659204483\n",
            "15830 val_loss: 0.340228796005249, train_loss: 0.24011892080307007\n",
            "15840 val_loss: 0.34197062253952026, train_loss: 0.24032890796661377\n",
            "15850 val_loss: 0.33975839614868164, train_loss: 0.23958106338977814\n",
            "15860 val_loss: 0.34176504611968994, train_loss: 0.23987692594528198\n",
            "15870 val_loss: 0.34023162722587585, train_loss: 0.2393302470445633\n",
            "15880 val_loss: 0.34085702896118164, train_loss: 0.23925592005252838\n",
            "15890 val_loss: 0.3392306864261627, train_loss: 0.2386501431465149\n",
            "15900 val_loss: 0.3407898545265198, train_loss: 0.23874951899051666\n",
            "15910 val_loss: 0.3411997854709625, train_loss: 0.23834118247032166\n",
            "15920 val_loss: 0.3397138714790344, train_loss: 0.2378043681383133\n",
            "15930 val_loss: 0.34082019329071045, train_loss: 0.2377033233642578\n",
            "15940 val_loss: 0.3388894498348236, train_loss: 0.23737086355686188\n",
            "15950 val_loss: 0.339119017124176, train_loss: 0.23668359220027924\n",
            "15960 val_loss: 0.33887869119644165, train_loss: 0.23646417260169983\n",
            "15970 val_loss: 0.3385756015777588, train_loss: 0.23631253838539124\n",
            "15980 val_loss: 0.33909982442855835, train_loss: 0.23619523644447327\n",
            "15990 val_loss: 0.33774781227111816, train_loss: 0.23549069464206696\n",
            "16000 val_loss: 0.33720117807388306, train_loss: 0.2356995940208435\n",
            "16010 val_loss: 0.3376847803592682, train_loss: 0.23527461290359497\n",
            "16020 val_loss: 0.33692702651023865, train_loss: 0.2351440191268921\n",
            "16030 val_loss: 0.3376806378364563, train_loss: 0.2352510690689087\n",
            "16040 val_loss: 0.33855438232421875, train_loss: 0.2343287169933319\n",
            "16050 val_loss: 0.3377653956413269, train_loss: 0.2338840663433075\n",
            "16060 val_loss: 0.33963361382484436, train_loss: 0.23417213559150696\n",
            "16070 val_loss: 0.33853670954704285, train_loss: 0.23344549536705017\n",
            "16080 val_loss: 0.3405543863773346, train_loss: 0.2335011214017868\n",
            "16090 val_loss: 0.33956509828567505, train_loss: 0.2325337827205658\n",
            "16100 val_loss: 0.3397495746612549, train_loss: 0.23238003253936768\n",
            "16110 val_loss: 0.3404461443424225, train_loss: 0.23228347301483154\n",
            "16120 val_loss: 0.3392936587333679, train_loss: 0.23173904418945312\n",
            "16130 val_loss: 0.33876848220825195, train_loss: 0.23123538494110107\n",
            "16140 val_loss: 0.3408503234386444, train_loss: 0.23147928714752197\n",
            "16150 val_loss: 0.342557817697525, train_loss: 0.2315092235803604\n",
            "16160 val_loss: 0.34002694487571716, train_loss: 0.23030100762844086\n",
            "16170 val_loss: 0.3386729657649994, train_loss: 0.2299816608428955\n",
            "16180 val_loss: 0.34258368611335754, train_loss: 0.23001697659492493\n",
            "16190 val_loss: 0.3407417833805084, train_loss: 0.22960790991783142\n",
            "16200 val_loss: 0.33959490060806274, train_loss: 0.22946451604366302\n",
            "16210 val_loss: 0.34348705410957336, train_loss: 0.22986570000648499\n",
            "16220 val_loss: 0.34217560291290283, train_loss: 0.2291208952665329\n",
            "16230 val_loss: 0.33832067251205444, train_loss: 0.22820447385311127\n",
            "16240 val_loss: 0.33831849694252014, train_loss: 0.22794505953788757\n",
            "16250 val_loss: 0.33944210410118103, train_loss: 0.22687530517578125\n",
            "16260 val_loss: 0.34264469146728516, train_loss: 0.22688497602939606\n",
            "16270 val_loss: 0.33824706077575684, train_loss: 0.22587575018405914\n",
            "16280 val_loss: 0.3426620066165924, train_loss: 0.2265014499425888\n",
            "16290 val_loss: 0.3402811884880066, train_loss: 0.22593379020690918\n",
            "16300 val_loss: 0.3386448323726654, train_loss: 0.2256084382534027\n",
            "16310 val_loss: 0.3363400399684906, train_loss: 0.22560334205627441\n",
            "16320 val_loss: 0.35210853815078735, train_loss: 0.2286045104265213\n",
            "16330 val_loss: 0.34519830346107483, train_loss: 0.22533594071865082\n",
            "16340 val_loss: 0.34043657779693604, train_loss: 0.22418347001075745\n",
            "16350 val_loss: 0.34444954991340637, train_loss: 0.22477053105831146\n",
            "16360 val_loss: 0.34089428186416626, train_loss: 0.22333693504333496\n",
            "16370 val_loss: 0.3400743901729584, train_loss: 0.22363673150539398\n",
            "16380 val_loss: 0.33958739042282104, train_loss: 0.22247545421123505\n",
            "16390 val_loss: 0.34042105078697205, train_loss: 0.22221322357654572\n",
            "16400 val_loss: 0.34688490629196167, train_loss: 0.22400538623332977\n",
            "16410 val_loss: 0.33812573552131653, train_loss: 0.22159810364246368\n",
            "16420 val_loss: 0.3394755721092224, train_loss: 0.22157147526741028\n",
            "16430 val_loss: 0.33642783761024475, train_loss: 0.22102822363376617\n",
            "16440 val_loss: 0.3481837809085846, train_loss: 0.22308921813964844\n",
            "16450 val_loss: 0.33441078662872314, train_loss: 0.2209603637456894\n",
            "16460 val_loss: 0.33609136939048767, train_loss: 0.2202855944633484\n",
            "16470 val_loss: 0.33814963698387146, train_loss: 0.22006548941135406\n",
            "16480 val_loss: 0.3376200795173645, train_loss: 0.2194073349237442\n",
            "16490 val_loss: 0.3364201486110687, train_loss: 0.21936525404453278\n",
            "16500 val_loss: 0.3345222771167755, train_loss: 0.21908262372016907\n",
            "16510 val_loss: 0.3353947103023529, train_loss: 0.21884767711162567\n",
            "16520 val_loss: 0.34321972727775574, train_loss: 0.22008074820041656\n",
            "16530 val_loss: 0.33619606494903564, train_loss: 0.21807503700256348\n",
            "16540 val_loss: 0.3379020094871521, train_loss: 0.21754257380962372\n",
            "16550 val_loss: 0.3429882526397705, train_loss: 0.21855428814888\n",
            "16560 val_loss: 0.3345735967159271, train_loss: 0.21718503534793854\n",
            "16570 val_loss: 0.3342001140117645, train_loss: 0.21679815649986267\n",
            "16580 val_loss: 0.3372822403907776, train_loss: 0.21695518493652344\n",
            "16590 val_loss: 0.3410080373287201, train_loss: 0.21742717921733856\n",
            "16600 val_loss: 0.33166739344596863, train_loss: 0.21581387519836426\n",
            "16610 val_loss: 0.331369549036026, train_loss: 0.21576161682605743\n",
            "16620 val_loss: 0.33441072702407837, train_loss: 0.21537144482135773\n",
            "16630 val_loss: 0.3342735171318054, train_loss: 0.2155921310186386\n",
            "16640 val_loss: 0.33607885241508484, train_loss: 0.2160298079252243\n",
            "16650 val_loss: 0.3304431140422821, train_loss: 0.21521532535552979\n",
            "16660 val_loss: 0.33465561270713806, train_loss: 0.21510092914104462\n",
            "16670 val_loss: 0.3375820517539978, train_loss: 0.2151939421892166\n",
            "16680 val_loss: 0.33284682035446167, train_loss: 0.21429267525672913\n",
            "16690 val_loss: 0.3344205319881439, train_loss: 0.2140035480260849\n",
            "16700 val_loss: 0.3346656560897827, train_loss: 0.21370981633663177\n",
            "16710 val_loss: 0.3292117416858673, train_loss: 0.21354956924915314\n",
            "16720 val_loss: 0.3406265377998352, train_loss: 0.21440131962299347\n",
            "16730 val_loss: 0.3349032700061798, train_loss: 0.21309241652488708\n",
            "16740 val_loss: 0.33881548047065735, train_loss: 0.2135205715894699\n",
            "16750 val_loss: 0.32765647768974304, train_loss: 0.21312737464904785\n",
            "16760 val_loss: 0.3275969922542572, train_loss: 0.21282637119293213\n",
            "16770 val_loss: 0.33665692806243896, train_loss: 0.21212735772132874\n",
            "16780 val_loss: 0.32948580384254456, train_loss: 0.21109382808208466\n",
            "16790 val_loss: 0.33235275745391846, train_loss: 0.21070075035095215\n",
            "16800 val_loss: 0.3335231840610504, train_loss: 0.2107793241739273\n",
            "16810 val_loss: 0.3310456871986389, train_loss: 0.21047937870025635\n",
            "16820 val_loss: 0.3325107991695404, train_loss: 0.21008896827697754\n",
            "16830 val_loss: 0.3340311050415039, train_loss: 0.2103893756866455\n",
            "16840 val_loss: 0.3340849280357361, train_loss: 0.20987534523010254\n",
            "16850 val_loss: 0.33367154002189636, train_loss: 0.20998452603816986\n",
            "16860 val_loss: 0.32896915078163147, train_loss: 0.20925311744213104\n",
            "16870 val_loss: 0.3322720229625702, train_loss: 0.20927059650421143\n",
            "16880 val_loss: 0.33155012130737305, train_loss: 0.20898914337158203\n",
            "16890 val_loss: 0.3265203833580017, train_loss: 0.20906619727611542\n",
            "16900 val_loss: 0.33097898960113525, train_loss: 0.20842775702476501\n",
            "16910 val_loss: 0.32820233702659607, train_loss: 0.20798735320568085\n",
            "16920 val_loss: 0.3314034044742584, train_loss: 0.20825937390327454\n",
            "16930 val_loss: 0.32891812920570374, train_loss: 0.20735988020896912\n",
            "16940 val_loss: 0.3341016173362732, train_loss: 0.20813527703285217\n",
            "16950 val_loss: 0.33244970440864563, train_loss: 0.20761363208293915\n",
            "16960 val_loss: 0.33257144689559937, train_loss: 0.20717138051986694\n",
            "16970 val_loss: 0.33263975381851196, train_loss: 0.20699767768383026\n",
            "16980 val_loss: 0.32900622487068176, train_loss: 0.20584362745285034\n",
            "16990 val_loss: 0.3257743716239929, train_loss: 0.20607224106788635\n",
            "17000 val_loss: 0.3288288712501526, train_loss: 0.20591992139816284\n",
            "17010 val_loss: 0.32777705788612366, train_loss: 0.20630961656570435\n",
            "17020 val_loss: 0.3217819631099701, train_loss: 0.2076711654663086\n",
            "17030 val_loss: 0.32999882102012634, train_loss: 0.20559105277061462\n",
            "17040 val_loss: 0.32739824056625366, train_loss: 0.20568400621414185\n",
            "17050 val_loss: 0.3285598158836365, train_loss: 0.20496603846549988\n",
            "17060 val_loss: 0.33034786581993103, train_loss: 0.20489223301410675\n",
            "17070 val_loss: 0.3286709189414978, train_loss: 0.2043624222278595\n",
            "17080 val_loss: 0.3286300003528595, train_loss: 0.2041785567998886\n",
            "17090 val_loss: 0.3281552195549011, train_loss: 0.20371372997760773\n",
            "17100 val_loss: 0.32641923427581787, train_loss: 0.2035072147846222\n",
            "17110 val_loss: 0.3238190710544586, train_loss: 0.20352157950401306\n",
            "17120 val_loss: 0.3230442702770233, train_loss: 0.20339858531951904\n",
            "17130 val_loss: 0.32081541419029236, train_loss: 0.20356859266757965\n",
            "17140 val_loss: 0.32521072030067444, train_loss: 0.20304882526397705\n",
            "17150 val_loss: 0.33308061957359314, train_loss: 0.20363402366638184\n",
            "17160 val_loss: 0.3240991532802582, train_loss: 0.20216555893421173\n",
            "17170 val_loss: 0.32168206572532654, train_loss: 0.20201070606708527\n",
            "17180 val_loss: 0.31989261507987976, train_loss: 0.20204433798789978\n",
            "17190 val_loss: 0.3234226703643799, train_loss: 0.20148269832134247\n",
            "17200 val_loss: 0.32834702730178833, train_loss: 0.20123101770877838\n",
            "17210 val_loss: 0.3291740417480469, train_loss: 0.20136669278144836\n",
            "17220 val_loss: 0.32725682854652405, train_loss: 0.2010793834924698\n",
            "17230 val_loss: 0.3228440284729004, train_loss: 0.20068728923797607\n",
            "17240 val_loss: 0.3221651613712311, train_loss: 0.2003938853740692\n",
            "17250 val_loss: 0.3181050419807434, train_loss: 0.20211586356163025\n",
            "17260 val_loss: 0.3249795138835907, train_loss: 0.20027849078178406\n",
            "17270 val_loss: 0.32522156834602356, train_loss: 0.20013053715229034\n",
            "17280 val_loss: 0.32932496070861816, train_loss: 0.20006972551345825\n",
            "17290 val_loss: 0.3336334526538849, train_loss: 0.20096945762634277\n",
            "17300 val_loss: 0.3249679207801819, train_loss: 0.19895204901695251\n",
            "17310 val_loss: 0.3335900902748108, train_loss: 0.2008640170097351\n",
            "17320 val_loss: 0.31775227189064026, train_loss: 0.1990886777639389\n",
            "17330 val_loss: 0.3191300928592682, train_loss: 0.198490709066391\n",
            "17340 val_loss: 0.32142502069473267, train_loss: 0.19803112745285034\n",
            "17350 val_loss: 0.32420268654823303, train_loss: 0.1979498416185379\n",
            "17360 val_loss: 0.32670798897743225, train_loss: 0.19868355989456177\n",
            "17370 val_loss: 0.32894760370254517, train_loss: 0.19806046783924103\n",
            "17380 val_loss: 0.3227466642856598, train_loss: 0.19697676599025726\n",
            "17390 val_loss: 0.32128265500068665, train_loss: 0.19650334119796753\n",
            "17400 val_loss: 0.31892094016075134, train_loss: 0.19670501351356506\n",
            "17410 val_loss: 0.31834644079208374, train_loss: 0.1969589740037918\n",
            "17420 val_loss: 0.32021862268447876, train_loss: 0.19660289585590363\n",
            "17430 val_loss: 0.3269399106502533, train_loss: 0.1973322033882141\n",
            "17440 val_loss: 0.32137128710746765, train_loss: 0.19624507427215576\n",
            "17450 val_loss: 0.3154211938381195, train_loss: 0.19669800996780396\n",
            "17460 val_loss: 0.3191460967063904, train_loss: 0.195339635014534\n",
            "17470 val_loss: 0.322014719247818, train_loss: 0.19495734572410583\n",
            "17480 val_loss: 0.3226150870323181, train_loss: 0.1950654238462448\n",
            "17490 val_loss: 0.31691569089889526, train_loss: 0.1948380321264267\n",
            "17500 val_loss: 0.3269626200199127, train_loss: 0.19516512751579285\n",
            "17510 val_loss: 0.3198392391204834, train_loss: 0.1942642629146576\n",
            "17520 val_loss: 0.32243865728378296, train_loss: 0.19428080320358276\n",
            "17530 val_loss: 0.3182958662509918, train_loss: 0.1934283971786499\n",
            "17540 val_loss: 0.3279397487640381, train_loss: 0.19405913352966309\n",
            "17550 val_loss: 0.31537213921546936, train_loss: 0.19403930008411407\n",
            "17560 val_loss: 0.3194311857223511, train_loss: 0.19305622577667236\n",
            "17570 val_loss: 0.3178988993167877, train_loss: 0.19259026646614075\n",
            "17580 val_loss: 0.322612464427948, train_loss: 0.1927100569009781\n",
            "17590 val_loss: 0.32024693489074707, train_loss: 0.19232353568077087\n",
            "17600 val_loss: 0.32195645570755005, train_loss: 0.1929865926504135\n",
            "17610 val_loss: 0.31321609020233154, train_loss: 0.19211642444133759\n",
            "17620 val_loss: 0.3200173079967499, train_loss: 0.19230131804943085\n",
            "17630 val_loss: 0.3141983449459076, train_loss: 0.19125257432460785\n",
            "17640 val_loss: 0.3187089264392853, train_loss: 0.19142524898052216\n",
            "17650 val_loss: 0.321577250957489, train_loss: 0.19133400917053223\n",
            "17660 val_loss: 0.32044556736946106, train_loss: 0.190707266330719\n",
            "17670 val_loss: 0.31373342871665955, train_loss: 0.1902310848236084\n",
            "17680 val_loss: 0.3182253837585449, train_loss: 0.1900428831577301\n",
            "17690 val_loss: 0.3229549825191498, train_loss: 0.19073174893856049\n",
            "17700 val_loss: 0.313307523727417, train_loss: 0.189437597990036\n",
            "17710 val_loss: 0.3120103180408478, train_loss: 0.19010579586029053\n",
            "17720 val_loss: 0.3105252683162689, train_loss: 0.18948733806610107\n",
            "17730 val_loss: 0.3156436085700989, train_loss: 0.1887364238500595\n",
            "17740 val_loss: 0.3176804780960083, train_loss: 0.18876710534095764\n",
            "17750 val_loss: 0.31331148743629456, train_loss: 0.1888546198606491\n",
            "17760 val_loss: 0.3201654851436615, train_loss: 0.18889693915843964\n",
            "17770 val_loss: 0.31724679470062256, train_loss: 0.1881496012210846\n",
            "17780 val_loss: 0.3150869607925415, train_loss: 0.18759313225746155\n",
            "17790 val_loss: 0.3106928765773773, train_loss: 0.1874566376209259\n",
            "17800 val_loss: 0.3141895830631256, train_loss: 0.1868097484111786\n",
            "17810 val_loss: 0.322853147983551, train_loss: 0.18752531707286835\n",
            "17820 val_loss: 0.3160540461540222, train_loss: 0.1860148012638092\n",
            "17830 val_loss: 0.30693382024765015, train_loss: 0.18674810230731964\n",
            "17840 val_loss: 0.31745004653930664, train_loss: 0.18591047823429108\n",
            "17850 val_loss: 0.3186205327510834, train_loss: 0.1856372058391571\n",
            "17860 val_loss: 0.32286930084228516, train_loss: 0.18600061535835266\n",
            "17870 val_loss: 0.31927257776260376, train_loss: 0.18566444516181946\n",
            "17880 val_loss: 0.31543394923210144, train_loss: 0.185390904545784\n",
            "17890 val_loss: 0.3134027123451233, train_loss: 0.1851893961429596\n",
            "17900 val_loss: 0.3148919641971588, train_loss: 0.1846272051334381\n",
            "17910 val_loss: 0.3147411644458771, train_loss: 0.18481793999671936\n",
            "17920 val_loss: 0.31477805972099304, train_loss: 0.18455441296100616\n",
            "17930 val_loss: 0.31622278690338135, train_loss: 0.18421730399131775\n",
            "17940 val_loss: 0.31277379393577576, train_loss: 0.1836218386888504\n",
            "17950 val_loss: 0.31655269861221313, train_loss: 0.1837766170501709\n",
            "17960 val_loss: 0.32487738132476807, train_loss: 0.18623286485671997\n",
            "17970 val_loss: 0.3201060891151428, train_loss: 0.18469130992889404\n",
            "17980 val_loss: 0.3117446005344391, train_loss: 0.18285374343395233\n",
            "17990 val_loss: 0.31299954652786255, train_loss: 0.18266761302947998\n",
            "18000 val_loss: 0.31448978185653687, train_loss: 0.18265609443187714\n",
            "18010 val_loss: 0.31352344155311584, train_loss: 0.1823665201663971\n",
            "18020 val_loss: 0.30409836769104004, train_loss: 0.1821364164352417\n",
            "18030 val_loss: 0.31832772493362427, train_loss: 0.18300984799861908\n",
            "18040 val_loss: 0.3100571930408478, train_loss: 0.18136045336723328\n",
            "18050 val_loss: 0.3013920187950134, train_loss: 0.18223020434379578\n",
            "18060 val_loss: 0.30625399947166443, train_loss: 0.18075989186763763\n",
            "18070 val_loss: 0.3174923062324524, train_loss: 0.18121637403964996\n",
            "18080 val_loss: 0.3135535418987274, train_loss: 0.18006151914596558\n",
            "18090 val_loss: 0.30573076009750366, train_loss: 0.17990989983081818\n",
            "18100 val_loss: 0.3091648519039154, train_loss: 0.18022753298282623\n",
            "18110 val_loss: 0.3060797452926636, train_loss: 0.17955511808395386\n",
            "18120 val_loss: 0.3056504726409912, train_loss: 0.17932473123073578\n",
            "18130 val_loss: 0.30784231424331665, train_loss: 0.17844748497009277\n",
            "18140 val_loss: 0.3027176260948181, train_loss: 0.1791578233242035\n",
            "18150 val_loss: 0.3091734051704407, train_loss: 0.17826053500175476\n",
            "18160 val_loss: 0.31030189990997314, train_loss: 0.1779860109090805\n",
            "18170 val_loss: 0.3144966661930084, train_loss: 0.17869216203689575\n",
            "18180 val_loss: 0.3087451457977295, train_loss: 0.17850837111473083\n",
            "18190 val_loss: 0.30850285291671753, train_loss: 0.17740853130817413\n",
            "18200 val_loss: 0.31255456805229187, train_loss: 0.1768292635679245\n",
            "18210 val_loss: 0.3069165349006653, train_loss: 0.17685091495513916\n",
            "18220 val_loss: 0.3081359267234802, train_loss: 0.1767338365316391\n",
            "18230 val_loss: 0.2990967035293579, train_loss: 0.17741090059280396\n",
            "18240 val_loss: 0.314105749130249, train_loss: 0.17701008915901184\n",
            "18250 val_loss: 0.30765587091445923, train_loss: 0.17633947730064392\n",
            "18260 val_loss: 0.3185654282569885, train_loss: 0.17695190012454987\n",
            "18270 val_loss: 0.30307409167289734, train_loss: 0.17503632605075836\n",
            "18280 val_loss: 0.3046037256717682, train_loss: 0.17441052198410034\n",
            "18290 val_loss: 0.30758136510849, train_loss: 0.17423224449157715\n",
            "18300 val_loss: 0.3070882558822632, train_loss: 0.17474670708179474\n",
            "18310 val_loss: 0.2990424335002899, train_loss: 0.1746429204940796\n",
            "18320 val_loss: 0.306225061416626, train_loss: 0.17369675636291504\n",
            "18330 val_loss: 0.3051236867904663, train_loss: 0.17289143800735474\n",
            "18340 val_loss: 0.3037416934967041, train_loss: 0.17287981510162354\n",
            "18350 val_loss: 0.30325236916542053, train_loss: 0.172001451253891\n",
            "18360 val_loss: 0.30472081899642944, train_loss: 0.17226745188236237\n",
            "18370 val_loss: 0.30882543325424194, train_loss: 0.17277203500270844\n",
            "18380 val_loss: 0.30409932136535645, train_loss: 0.17246858775615692\n",
            "18390 val_loss: 0.3067343533039093, train_loss: 0.17183655500411987\n",
            "18400 val_loss: 0.2970823049545288, train_loss: 0.17076122760772705\n",
            "18410 val_loss: 0.29636988043785095, train_loss: 0.17042362689971924\n",
            "18420 val_loss: 0.29804494976997375, train_loss: 0.16972899436950684\n",
            "18430 val_loss: 0.311422735452652, train_loss: 0.1709645539522171\n",
            "18440 val_loss: 0.30029627680778503, train_loss: 0.16884401440620422\n",
            "18450 val_loss: 0.2943647503852844, train_loss: 0.1687449812889099\n",
            "18460 val_loss: 0.30553433299064636, train_loss: 0.1683337390422821\n",
            "18470 val_loss: 0.30870500206947327, train_loss: 0.16824162006378174\n",
            "18480 val_loss: 0.30674833059310913, train_loss: 0.16724415123462677\n",
            "18490 val_loss: 0.29815930128097534, train_loss: 0.16637183725833893\n",
            "18500 val_loss: 0.2961826026439667, train_loss: 0.1656779795885086\n",
            "18510 val_loss: 0.306386262178421, train_loss: 0.1664406657218933\n",
            "18520 val_loss: 0.298162579536438, train_loss: 0.16508355736732483\n",
            "18530 val_loss: 0.29216212034225464, train_loss: 0.16485804319381714\n",
            "18540 val_loss: 0.2983764410018921, train_loss: 0.1641092449426651\n",
            "18550 val_loss: 0.2909215986728668, train_loss: 0.16366508603096008\n",
            "18560 val_loss: 0.2949661910533905, train_loss: 0.1620441973209381\n",
            "18570 val_loss: 0.29122021794319153, train_loss: 0.1631622314453125\n",
            "18580 val_loss: 0.29434001445770264, train_loss: 0.1612911969423294\n",
            "18590 val_loss: 0.2984974980354309, train_loss: 0.16057159006595612\n",
            "18600 val_loss: 0.2970393896102905, train_loss: 0.15976379811763763\n",
            "18610 val_loss: 0.2890862822532654, train_loss: 0.15914732217788696\n",
            "18620 val_loss: 0.29105669260025024, train_loss: 0.15835966169834137\n",
            "18630 val_loss: 0.3021177649497986, train_loss: 0.1582389920949936\n",
            "18640 val_loss: 0.29616284370422363, train_loss: 0.15701034665107727\n",
            "18650 val_loss: 0.2993185520172119, train_loss: 0.15706290304660797\n",
            "18660 val_loss: 0.30286291241645813, train_loss: 0.15724971890449524\n",
            "18670 val_loss: 0.29437658190727234, train_loss: 0.15428751707077026\n",
            "18680 val_loss: 0.29094427824020386, train_loss: 0.15318915247917175\n",
            "18690 val_loss: 0.30050742626190186, train_loss: 0.15488961338996887\n",
            "18700 val_loss: 0.29350489377975464, train_loss: 0.15150855481624603\n",
            "18710 val_loss: 0.2905489206314087, train_loss: 0.1504884958267212\n",
            "18720 val_loss: 0.28567564487457275, train_loss: 0.14977392554283142\n",
            "18730 val_loss: 0.29458382725715637, train_loss: 0.1502791941165924\n",
            "18740 val_loss: 0.28906378149986267, train_loss: 0.14865469932556152\n",
            "18750 val_loss: 0.2855878174304962, train_loss: 0.1480596959590912\n",
            "18760 val_loss: 0.27787038683891296, train_loss: 0.14896397292613983\n",
            "18770 val_loss: 0.28383755683898926, train_loss: 0.14570319652557373\n",
            "18780 val_loss: 0.27611255645751953, train_loss: 0.14619134366512299\n",
            "18790 val_loss: 0.2828899621963501, train_loss: 0.14423084259033203\n",
            "18800 val_loss: 0.2797168791294098, train_loss: 0.14340387284755707\n",
            "18810 val_loss: 0.27668148279190063, train_loss: 0.14263765513896942\n",
            "18820 val_loss: 0.2734028100967407, train_loss: 0.14173997938632965\n",
            "18830 val_loss: 0.2754216492176056, train_loss: 0.1408957839012146\n",
            "18840 val_loss: 0.27503523230552673, train_loss: 0.1396917700767517\n",
            "18850 val_loss: 0.2787787914276123, train_loss: 0.13969579339027405\n",
            "18860 val_loss: 0.2701759934425354, train_loss: 0.13851650059223175\n",
            "18870 val_loss: 0.2754579186439514, train_loss: 0.13831984996795654\n",
            "18880 val_loss: 0.2785104811191559, train_loss: 0.13795962929725647\n",
            "18890 val_loss: 0.27458903193473816, train_loss: 0.13690225780010223\n",
            "18900 val_loss: 0.2696358263492584, train_loss: 0.13570423424243927\n",
            "18910 val_loss: 0.2658073604106903, train_loss: 0.1367424875497818\n",
            "18920 val_loss: 0.26722967624664307, train_loss: 0.1350080519914627\n",
            "18930 val_loss: 0.26753494143486023, train_loss: 0.1335560530424118\n",
            "18940 val_loss: 0.2660433351993561, train_loss: 0.13302958011627197\n",
            "18950 val_loss: 0.26758456230163574, train_loss: 0.1322910487651825\n",
            "18960 val_loss: 0.2730778157711029, train_loss: 0.13332010805606842\n",
            "18970 val_loss: 0.2653023600578308, train_loss: 0.13101615011692047\n",
            "18980 val_loss: 0.2626996338367462, train_loss: 0.13036106526851654\n",
            "18990 val_loss: 0.2647876739501953, train_loss: 0.12962606549263\n",
            "19000 val_loss: 0.25930488109588623, train_loss: 0.13017794489860535\n",
            "19010 val_loss: 0.2635580599308014, train_loss: 0.12806349992752075\n",
            "19020 val_loss: 0.25931066274642944, train_loss: 0.12800993025302887\n",
            "19030 val_loss: 0.26323431730270386, train_loss: 0.12714438140392303\n",
            "19040 val_loss: 0.26440688967704773, train_loss: 0.12580914795398712\n",
            "19050 val_loss: 0.2590400278568268, train_loss: 0.12512679398059845\n",
            "19060 val_loss: 0.25462451577186584, train_loss: 0.12617039680480957\n",
            "19070 val_loss: 0.26073965430259705, train_loss: 0.12385241687297821\n",
            "19080 val_loss: 0.26942428946495056, train_loss: 0.12445312738418579\n",
            "19090 val_loss: 0.26056209206581116, train_loss: 0.12195117026567459\n",
            "19100 val_loss: 0.2663288712501526, train_loss: 0.12269594520330429\n",
            "19110 val_loss: 0.26299598813056946, train_loss: 0.11987120658159256\n",
            "19120 val_loss: 0.2605743110179901, train_loss: 0.11876106262207031\n",
            "19130 val_loss: 0.26256152987480164, train_loss: 0.11841874569654465\n",
            "19140 val_loss: 0.26356086134910583, train_loss: 0.11816956102848053\n",
            "19150 val_loss: 0.2619294822216034, train_loss: 0.11698634177446365\n",
            "19160 val_loss: 0.2538215219974518, train_loss: 0.11673231422901154\n",
            "19170 val_loss: 0.2693294286727905, train_loss: 0.12034787237644196\n",
            "19180 val_loss: 0.25429967045783997, train_loss: 0.11527081578969955\n",
            "19190 val_loss: 0.25203365087509155, train_loss: 0.11797018349170685\n",
            "19200 val_loss: 0.25250640511512756, train_loss: 0.11600328981876373\n",
            "19210 val_loss: 0.2561737596988678, train_loss: 0.11364071071147919\n",
            "19220 val_loss: 0.25550925731658936, train_loss: 0.11375229060649872\n",
            "19230 val_loss: 0.25944870710372925, train_loss: 0.11337435245513916\n",
            "19240 val_loss: 0.24719732999801636, train_loss: 0.11322565376758575\n",
            "19250 val_loss: 0.2530291974544525, train_loss: 0.1108904480934143\n",
            "19260 val_loss: 0.24850508570671082, train_loss: 0.11070045828819275\n",
            "19270 val_loss: 0.25075870752334595, train_loss: 0.10891075432300568\n",
            "19280 val_loss: 0.24589736759662628, train_loss: 0.11058619618415833\n",
            "19290 val_loss: 0.2443419247865677, train_loss: 0.11546643078327179\n",
            "19300 val_loss: 0.24991782009601593, train_loss: 0.10895802825689316\n",
            "19310 val_loss: 0.2436516135931015, train_loss: 0.10836702585220337\n",
            "19320 val_loss: 0.2502126097679138, train_loss: 0.11092499643564224\n",
            "19330 val_loss: 0.24721179902553558, train_loss: 0.10805761814117432\n",
            "19340 val_loss: 0.24772889912128448, train_loss: 0.10582409799098969\n",
            "19350 val_loss: 0.24425315856933594, train_loss: 0.10830958932638168\n",
            "19360 val_loss: 0.2479497194290161, train_loss: 0.1072150319814682\n",
            "19370 val_loss: 0.2466178685426712, train_loss: 0.11725053936243057\n",
            "19380 val_loss: 0.23970282077789307, train_loss: 0.10767847299575806\n",
            "19390 val_loss: 0.24156853556632996, train_loss: 0.10409298539161682\n",
            "19400 val_loss: 0.24479635059833527, train_loss: 0.10345233231782913\n",
            "19410 val_loss: 0.25389817357063293, train_loss: 0.10564685612916946\n",
            "19420 val_loss: 0.24617235362529755, train_loss: 0.10473985970020294\n",
            "19430 val_loss: 0.2502296268939972, train_loss: 0.1045265793800354\n",
            "19440 val_loss: 0.2425304800271988, train_loss: 0.09986016899347305\n",
            "19450 val_loss: 0.2571720778942108, train_loss: 0.10806235671043396\n",
            "19460 val_loss: 0.25217270851135254, train_loss: 0.10014747828245163\n",
            "19470 val_loss: 0.23789189755916595, train_loss: 0.10076058655977249\n",
            "19480 val_loss: 0.2579948902130127, train_loss: 0.11380144953727722\n",
            "19490 val_loss: 0.2343732714653015, train_loss: 0.1031750962138176\n",
            "19500 val_loss: 0.2539145052433014, train_loss: 0.10731719434261322\n",
            "19510 val_loss: 0.24094386398792267, train_loss: 0.09865343570709229\n",
            "19520 val_loss: 0.24056771397590637, train_loss: 0.10819807648658752\n",
            "19530 val_loss: 0.24200598895549774, train_loss: 0.09693795442581177\n",
            "19540 val_loss: 0.23721247911453247, train_loss: 0.09677279740571976\n",
            "19550 val_loss: 0.23809216916561127, train_loss: 0.09418788552284241\n",
            "19560 val_loss: 0.23459625244140625, train_loss: 0.09531355649232864\n",
            "19570 val_loss: 0.23589055240154266, train_loss: 0.09355194866657257\n",
            "19580 val_loss: 0.2305845022201538, train_loss: 0.09349837899208069\n",
            "19590 val_loss: 0.2370859533548355, train_loss: 0.09106194227933884\n",
            "19600 val_loss: 0.23738926649093628, train_loss: 0.09520350396633148\n",
            "19610 val_loss: 0.23539288341999054, train_loss: 0.09450124204158783\n",
            "19620 val_loss: 0.23225325345993042, train_loss: 0.08970015496015549\n",
            "19630 val_loss: 0.2313067764043808, train_loss: 0.08946079760789871\n",
            "19640 val_loss: 0.2304472178220749, train_loss: 0.098495714366436\n",
            "19650 val_loss: 0.22454412281513214, train_loss: 0.08948357403278351\n",
            "19660 val_loss: 0.23888467252254486, train_loss: 0.09403765946626663\n",
            "19670 val_loss: 0.23050758242607117, train_loss: 0.09164413064718246\n",
            "19680 val_loss: 0.22843945026397705, train_loss: 0.0878538191318512\n",
            "19690 val_loss: 0.22497671842575073, train_loss: 0.08902803063392639\n",
            "19700 val_loss: 0.22564546763896942, train_loss: 0.08739300072193146\n",
            "19710 val_loss: 0.22609035670757294, train_loss: 0.08855314552783966\n",
            "19720 val_loss: 0.23226217925548553, train_loss: 0.08792150020599365\n",
            "19730 val_loss: 0.2287273108959198, train_loss: 0.08547881245613098\n",
            "19740 val_loss: 0.224183589220047, train_loss: 0.08771448582410812\n",
            "19750 val_loss: 0.22129449248313904, train_loss: 0.08609339594841003\n",
            "19760 val_loss: 0.22604301571846008, train_loss: 0.08900953829288483\n",
            "19770 val_loss: 0.22287091612815857, train_loss: 0.08667244017124176\n",
            "19780 val_loss: 0.22024838626384735, train_loss: 0.08494558185338974\n",
            "19790 val_loss: 0.22160373628139496, train_loss: 0.08450527489185333\n",
            "19800 val_loss: 0.2224971204996109, train_loss: 0.08265002816915512\n",
            "19810 val_loss: 0.2282238006591797, train_loss: 0.09156891703605652\n",
            "19820 val_loss: 0.2200239896774292, train_loss: 0.08384132385253906\n",
            "19830 val_loss: 0.2372765839099884, train_loss: 0.08762314170598984\n",
            "19840 val_loss: 0.22798842191696167, train_loss: 0.0811581090092659\n",
            "19850 val_loss: 0.22123324871063232, train_loss: 0.08153566718101501\n",
            "19860 val_loss: 0.23680534958839417, train_loss: 0.09764137119054794\n",
            "19870 val_loss: 0.22240330278873444, train_loss: 0.08227455615997314\n",
            "19880 val_loss: 0.22862279415130615, train_loss: 0.0864686369895935\n",
            "19890 val_loss: 0.21591512858867645, train_loss: 0.08124689012765884\n",
            "19900 val_loss: 0.22336676716804504, train_loss: 0.07937423139810562\n",
            "19910 val_loss: 0.23402824997901917, train_loss: 0.08575902879238129\n",
            "19920 val_loss: 0.2214546948671341, train_loss: 0.08218740671873093\n",
            "19930 val_loss: 0.23198756575584412, train_loss: 0.09077675640583038\n",
            "19940 val_loss: 0.21873946487903595, train_loss: 0.07782596349716187\n",
            "19950 val_loss: 0.2170652151107788, train_loss: 0.07854101806879044\n",
            "19960 val_loss: 0.2176017463207245, train_loss: 0.07916122674942017\n",
            "19970 val_loss: 0.21604196727275848, train_loss: 0.07752061635255814\n",
            "19980 val_loss: 0.22361057996749878, train_loss: 0.08263644576072693\n",
            "19990 val_loss: 0.21584470570087433, train_loss: 0.08149518072605133\n",
            "20000 val_loss: 0.21434065699577332, train_loss: 0.07754117250442505\n",
            "20010 val_loss: 0.22549422085285187, train_loss: 0.08538959175348282\n",
            "20020 val_loss: 0.21346209943294525, train_loss: 0.076416976749897\n",
            "20030 val_loss: 0.21533459424972534, train_loss: 0.07553953677415848\n",
            "20040 val_loss: 0.21917633712291718, train_loss: 0.0803142786026001\n",
            "20050 val_loss: 0.21830172836780548, train_loss: 0.07903910428285599\n",
            "20060 val_loss: 0.2111644446849823, train_loss: 0.07514383643865585\n",
            "20070 val_loss: 0.21377412974834442, train_loss: 0.07905072718858719\n",
            "20080 val_loss: 0.21330851316452026, train_loss: 0.07285898923873901\n",
            "20090 val_loss: 0.21918685734272003, train_loss: 0.08444315940141678\n",
            "20100 val_loss: 0.21366164088249207, train_loss: 0.07339034974575043\n",
            "20110 val_loss: 0.21615760028362274, train_loss: 0.07443764060735703\n",
            "20120 val_loss: 0.2123415172100067, train_loss: 0.07234890758991241\n",
            "20130 val_loss: 0.21128661930561066, train_loss: 0.07426192611455917\n",
            "20140 val_loss: 0.21120332181453705, train_loss: 0.07151050120592117\n",
            "20150 val_loss: 0.21002322435379028, train_loss: 0.0710606575012207\n",
            "20160 val_loss: 0.20613159239292145, train_loss: 0.0692688524723053\n",
            "20170 val_loss: 0.2062259167432785, train_loss: 0.07178384065628052\n",
            "20180 val_loss: 0.20684969425201416, train_loss: 0.07126211374998093\n",
            "20190 val_loss: 0.20905306935310364, train_loss: 0.07039915025234222\n",
            "20200 val_loss: 0.21059729158878326, train_loss: 0.06847014278173447\n",
            "20210 val_loss: 0.2110227644443512, train_loss: 0.06908565014600754\n",
            "20220 val_loss: 0.20739932358264923, train_loss: 0.06844934076070786\n",
            "20230 val_loss: 0.2057657241821289, train_loss: 0.06779198348522186\n",
            "20240 val_loss: 0.21277067065238953, train_loss: 0.06647531688213348\n",
            "20250 val_loss: 0.2098093032836914, train_loss: 0.066666379570961\n",
            "20260 val_loss: 0.22149279713630676, train_loss: 0.07326149940490723\n",
            "20270 val_loss: 0.2136143296957016, train_loss: 0.06905577331781387\n",
            "20280 val_loss: 0.2075391560792923, train_loss: 0.06724430620670319\n",
            "20290 val_loss: 0.2120700627565384, train_loss: 0.06856251507997513\n",
            "20300 val_loss: 0.20926502346992493, train_loss: 0.06651555001735687\n",
            "20310 val_loss: 0.21199476718902588, train_loss: 0.06493588536977768\n",
            "20320 val_loss: 0.20969942212104797, train_loss: 0.06421826779842377\n",
            "20330 val_loss: 0.20683567225933075, train_loss: 0.0673152506351471\n",
            "20340 val_loss: 0.2045128047466278, train_loss: 0.06613051891326904\n",
            "20350 val_loss: 0.2095523625612259, train_loss: 0.06944967061281204\n",
            "20360 val_loss: 0.2030855417251587, train_loss: 0.06808702647686005\n",
            "20370 val_loss: 0.20259380340576172, train_loss: 0.06568863242864609\n",
            "20380 val_loss: 0.2092626690864563, train_loss: 0.06840528547763824\n",
            "20390 val_loss: 0.2028636932373047, train_loss: 0.06427660584449768\n",
            "20400 val_loss: 0.22080810368061066, train_loss: 0.07193309813737869\n",
            "20410 val_loss: 0.20281219482421875, train_loss: 0.06434737145900726\n",
            "20420 val_loss: 0.21319687366485596, train_loss: 0.06638558208942413\n",
            "20430 val_loss: 0.20425085723400116, train_loss: 0.06331229954957962\n",
            "20440 val_loss: 0.2045663446187973, train_loss: 0.06494370102882385\n",
            "20450 val_loss: 0.20426928997039795, train_loss: 0.06478816270828247\n",
            "20460 val_loss: 0.20921087265014648, train_loss: 0.06584753096103668\n",
            "20470 val_loss: 0.20204418897628784, train_loss: 0.06361205130815506\n",
            "20480 val_loss: 0.19662587344646454, train_loss: 0.060972124338150024\n",
            "20490 val_loss: 0.20455247163772583, train_loss: 0.06545258313417435\n",
            "20500 val_loss: 0.1977812498807907, train_loss: 0.0609126091003418\n",
            "20510 val_loss: 0.19524939358234406, train_loss: 0.06499972939491272\n",
            "20520 val_loss: 0.1973358541727066, train_loss: 0.06368416547775269\n",
            "20530 val_loss: 0.2006416767835617, train_loss: 0.06171729043126106\n",
            "20540 val_loss: 0.21482345461845398, train_loss: 0.06626977026462555\n",
            "20550 val_loss: 0.19974200427532196, train_loss: 0.06162993609905243\n",
            "20560 val_loss: 0.1997864544391632, train_loss: 0.06425141543149948\n",
            "20570 val_loss: 0.22111918032169342, train_loss: 0.0736219510436058\n",
            "20580 val_loss: 0.19634941220283508, train_loss: 0.058568425476551056\n",
            "20590 val_loss: 0.1995108723640442, train_loss: 0.05749716982245445\n",
            "20600 val_loss: 0.2211606353521347, train_loss: 0.06751476228237152\n",
            "20610 val_loss: 0.21386346220970154, train_loss: 0.06837914139032364\n",
            "20620 val_loss: 0.20347334444522858, train_loss: 0.06277093291282654\n",
            "20630 val_loss: 0.19890807569026947, train_loss: 0.06076173484325409\n",
            "20640 val_loss: 0.19512467086315155, train_loss: 0.06013091281056404\n",
            "20650 val_loss: 0.1985960453748703, train_loss: 0.06344137340784073\n",
            "20660 val_loss: 0.18782170116901398, train_loss: 0.06060494855046272\n",
            "20670 val_loss: 0.19324277341365814, train_loss: 0.05806209146976471\n",
            "20680 val_loss: 0.21107174456119537, train_loss: 0.06321372836828232\n",
            "20690 val_loss: 0.19642198085784912, train_loss: 0.058112844824790955\n",
            "20700 val_loss: 0.1969623863697052, train_loss: 0.05608795955777168\n",
            "20710 val_loss: 0.2122383564710617, train_loss: 0.06409694254398346\n",
            "20720 val_loss: 0.20124861598014832, train_loss: 0.059708576649427414\n",
            "20730 val_loss: 0.1948990523815155, train_loss: 0.05645699426531792\n",
            "20740 val_loss: 0.1952521651983261, train_loss: 0.055040158331394196\n",
            "20750 val_loss: 0.18556635081768036, train_loss: 0.056412044912576675\n",
            "20760 val_loss: 0.2021864950656891, train_loss: 0.05740584060549736\n",
            "20770 val_loss: 0.1950913667678833, train_loss: 0.056455593556165695\n",
            "20780 val_loss: 0.19282735884189606, train_loss: 0.05427592620253563\n",
            "20790 val_loss: 0.19048979878425598, train_loss: 0.05483627691864967\n",
            "20800 val_loss: 0.19258753955364227, train_loss: 0.05499515309929848\n",
            "20810 val_loss: 0.18783415853977203, train_loss: 0.05391767993569374\n",
            "20820 val_loss: 0.18876127898693085, train_loss: 0.052625056356191635\n",
            "20830 val_loss: 0.1884581744670868, train_loss: 0.052834849804639816\n",
            "20840 val_loss: 0.1924940049648285, train_loss: 0.05428345873951912\n",
            "20850 val_loss: 0.19998975098133087, train_loss: 0.05456636846065521\n",
            "20860 val_loss: 0.20069339871406555, train_loss: 0.056069210171699524\n",
            "20870 val_loss: 0.1899997442960739, train_loss: 0.0519675612449646\n",
            "20880 val_loss: 0.20390932261943817, train_loss: 0.055370207875967026\n",
            "20890 val_loss: 0.200807124376297, train_loss: 0.06051856279373169\n",
            "20900 val_loss: 0.2049013376235962, train_loss: 0.06360895186662674\n",
            "20910 val_loss: 0.187630295753479, train_loss: 0.05199681594967842\n",
            "20920 val_loss: 0.2133575826883316, train_loss: 0.0575692318379879\n",
            "20930 val_loss: 0.19288384914398193, train_loss: 0.052221279591321945\n",
            "20940 val_loss: 0.19539842009544373, train_loss: 0.052260622382164\n",
            "20950 val_loss: 0.18960461020469666, train_loss: 0.05179430916905403\n",
            "20960 val_loss: 0.2172231376171112, train_loss: 0.06482984870672226\n",
            "20970 val_loss: 0.20185540616512299, train_loss: 0.05746012181043625\n",
            "20980 val_loss: 0.18386156857013702, train_loss: 0.05315729230642319\n",
            "20990 val_loss: 0.1893509179353714, train_loss: 0.0509493388235569\n",
            "21000 val_loss: 0.22316405177116394, train_loss: 0.0660029798746109\n",
            "21010 val_loss: 0.21159619092941284, train_loss: 0.05948749929666519\n",
            "21020 val_loss: 0.2020735740661621, train_loss: 0.05280332639813423\n",
            "21030 val_loss: 0.18277117609977722, train_loss: 0.05108664929866791\n",
            "21040 val_loss: 0.19254963099956512, train_loss: 0.05412742495536804\n",
            "21050 val_loss: 0.18638114631175995, train_loss: 0.052551981061697006\n",
            "21060 val_loss: 0.19284482300281525, train_loss: 0.050373807549476624\n",
            "21070 val_loss: 0.181676983833313, train_loss: 0.04987533763051033\n",
            "21080 val_loss: 0.19674760103225708, train_loss: 0.05002925917506218\n",
            "21090 val_loss: 0.20701220631599426, train_loss: 0.05453450232744217\n",
            "21100 val_loss: 0.1925431191921234, train_loss: 0.05075577273964882\n",
            "21110 val_loss: 0.18918512761592865, train_loss: 0.04791586846113205\n",
            "21120 val_loss: 0.20722177624702454, train_loss: 0.05413886159658432\n",
            "21130 val_loss: 0.18477246165275574, train_loss: 0.04822688549757004\n",
            "21140 val_loss: 0.2132953405380249, train_loss: 0.06103018671274185\n",
            "21150 val_loss: 0.18060603737831116, train_loss: 0.05108248442411423\n",
            "21160 val_loss: 0.18464641273021698, train_loss: 0.048030078411102295\n",
            "21170 val_loss: 0.18536274135112762, train_loss: 0.04783258214592934\n",
            "21180 val_loss: 0.1876462697982788, train_loss: 0.04730959236621857\n",
            "21190 val_loss: 0.18198560178279877, train_loss: 0.047324828803539276\n",
            "21200 val_loss: 0.1991845965385437, train_loss: 0.05150723457336426\n",
            "21210 val_loss: 0.18253342807292938, train_loss: 0.04663430526852608\n",
            "21220 val_loss: 0.18511512875556946, train_loss: 0.04884565994143486\n",
            "21230 val_loss: 0.1953805685043335, train_loss: 0.05245552211999893\n",
            "21240 val_loss: 0.1918012946844101, train_loss: 0.0466756671667099\n",
            "21250 val_loss: 0.19213004410266876, train_loss: 0.04754655808210373\n",
            "21260 val_loss: 0.19462335109710693, train_loss: 0.05079825967550278\n",
            "21270 val_loss: 0.18089231848716736, train_loss: 0.0472298339009285\n",
            "21280 val_loss: 0.1899031400680542, train_loss: 0.046769291162490845\n",
            "21290 val_loss: 0.18644511699676514, train_loss: 0.046465348452329636\n",
            "21300 val_loss: 0.18649999797344208, train_loss: 0.04679565504193306\n",
            "21310 val_loss: 0.19874992966651917, train_loss: 0.050451964139938354\n",
            "21320 val_loss: 0.19184289872646332, train_loss: 0.04932287335395813\n",
            "21330 val_loss: 0.1930725872516632, train_loss: 0.046252455562353134\n",
            "21340 val_loss: 0.19280345737934113, train_loss: 0.04898185282945633\n",
            "21350 val_loss: 0.1945563703775406, train_loss: 0.047400664538145065\n",
            "21360 val_loss: 0.1858828067779541, train_loss: 0.045013733208179474\n",
            "21370 val_loss: 0.19436679780483246, train_loss: 0.044803328812122345\n",
            "21380 val_loss: 0.19670622050762177, train_loss: 0.04567814990878105\n",
            "21390 val_loss: 0.184326633810997, train_loss: 0.04537555202841759\n",
            "21400 val_loss: 0.18070141971111298, train_loss: 0.04465252161026001\n",
            "21410 val_loss: 0.1877509206533432, train_loss: 0.04545155167579651\n",
            "21420 val_loss: 0.18026316165924072, train_loss: 0.04507694020867348\n",
            "21430 val_loss: 0.20512805879116058, train_loss: 0.047798193991184235\n",
            "21440 val_loss: 0.19615411758422852, train_loss: 0.04641096293926239\n",
            "21450 val_loss: 0.1826322376728058, train_loss: 0.04303356632590294\n",
            "21460 val_loss: 0.18165872991085052, train_loss: 0.04395727068185806\n",
            "21470 val_loss: 0.1847439557313919, train_loss: 0.04348723590373993\n",
            "21480 val_loss: 0.18865236639976501, train_loss: 0.04788019880652428\n",
            "21490 val_loss: 0.18415896594524384, train_loss: 0.04347461462020874\n",
            "21500 val_loss: 0.1826609969139099, train_loss: 0.0439329594373703\n",
            "21510 val_loss: 0.19600296020507812, train_loss: 0.04994929954409599\n",
            "21520 val_loss: 0.18583978712558746, train_loss: 0.04427778348326683\n",
            "21530 val_loss: 0.18221229314804077, train_loss: 0.042262762784957886\n",
            "21540 val_loss: 0.18152733147144318, train_loss: 0.0439598374068737\n",
            "21550 val_loss: 0.1798267364501953, train_loss: 0.041744545102119446\n",
            "21560 val_loss: 0.1862340122461319, train_loss: 0.04242246598005295\n",
            "21570 val_loss: 0.1979793757200241, train_loss: 0.044536080211400986\n",
            "21580 val_loss: 0.19616958498954773, train_loss: 0.04243754968047142\n",
            "21590 val_loss: 0.2132692039012909, train_loss: 0.050430674105882645\n",
            "21600 val_loss: 0.19195778667926788, train_loss: 0.04309587925672531\n",
            "21610 val_loss: 0.18550854921340942, train_loss: 0.04182896390557289\n",
            "21620 val_loss: 0.2005108892917633, train_loss: 0.045430880039930344\n",
            "21630 val_loss: 0.19833014905452728, train_loss: 0.044083040207624435\n",
            "21640 val_loss: 0.18752720952033997, train_loss: 0.041171059012413025\n",
            "21650 val_loss: 0.2061152458190918, train_loss: 0.04557254537940025\n",
            "21660 val_loss: 0.2083408534526825, train_loss: 0.047518208622932434\n",
            "21670 val_loss: 0.18433985114097595, train_loss: 0.041265808045864105\n",
            "21680 val_loss: 0.18572868406772614, train_loss: 0.04218888282775879\n",
            "21690 val_loss: 0.18366262316703796, train_loss: 0.04066072031855583\n",
            "21700 val_loss: 0.18036186695098877, train_loss: 0.0410861074924469\n",
            "21710 val_loss: 0.18370473384857178, train_loss: 0.04096115380525589\n",
            "21720 val_loss: 0.1822623759508133, train_loss: 0.040319446474313736\n",
            "21730 val_loss: 0.1889941543340683, train_loss: 0.039115916937589645\n",
            "21740 val_loss: 0.1982494592666626, train_loss: 0.044023603200912476\n",
            "21750 val_loss: 0.1858358085155487, train_loss: 0.039315417408943176\n",
            "21760 val_loss: 0.18043336272239685, train_loss: 0.039217881858348846\n",
            "21770 val_loss: 0.19140733778476715, train_loss: 0.03908027336001396\n",
            "21780 val_loss: 0.18226057291030884, train_loss: 0.039294250309467316\n",
            "21790 val_loss: 0.18366162478923798, train_loss: 0.04094249755144119\n",
            "21800 val_loss: 0.18560576438903809, train_loss: 0.0387469120323658\n",
            "21810 val_loss: 0.1814773827791214, train_loss: 0.04002108797430992\n",
            "21820 val_loss: 0.18607385456562042, train_loss: 0.03752344101667404\n",
            "21830 val_loss: 0.18145562708377838, train_loss: 0.03840845823287964\n",
            "21840 val_loss: 0.18875239789485931, train_loss: 0.04086540266871452\n",
            "21850 val_loss: 0.19633790850639343, train_loss: 0.04452493414282799\n",
            "21860 val_loss: 0.179624542593956, train_loss: 0.03991148993372917\n",
            "21870 val_loss: 0.19052337110042572, train_loss: 0.03821134567260742\n",
            "21880 val_loss: 0.1919422596693039, train_loss: 0.038180746138095856\n",
            "21890 val_loss: 0.18629439175128937, train_loss: 0.0381741002202034\n",
            "21900 val_loss: 0.18700766563415527, train_loss: 0.037011802196502686\n",
            "21910 val_loss: 0.18766647577285767, train_loss: 0.03803147003054619\n",
            "21920 val_loss: 0.18080876767635345, train_loss: 0.03777848184108734\n",
            "21930 val_loss: 0.18429939448833466, train_loss: 0.040034886449575424\n",
            "21940 val_loss: 0.19488121569156647, train_loss: 0.03732527419924736\n",
            "21950 val_loss: 0.18122628331184387, train_loss: 0.03763579577207565\n",
            "21960 val_loss: 0.18612639605998993, train_loss: 0.03805963322520256\n",
            "21970 val_loss: 0.1849122792482376, train_loss: 0.03672552481293678\n",
            "21980 val_loss: 0.20592144131660461, train_loss: 0.03989280015230179\n",
            "21990 val_loss: 0.18613207340240479, train_loss: 0.037016045302152634\n",
            "22000 val_loss: 0.19501502811908722, train_loss: 0.04214560613036156\n",
            "22010 val_loss: 0.20019423961639404, train_loss: 0.03919851407408714\n",
            "22020 val_loss: 0.19828376173973083, train_loss: 0.03832443803548813\n",
            "22030 val_loss: 0.1909790337085724, train_loss: 0.04435290768742561\n",
            "22040 val_loss: 0.1782190054655075, train_loss: 0.03704423829913139\n",
            "22050 val_loss: 0.18854384124279022, train_loss: 0.038220152258872986\n",
            "22060 val_loss: 0.18703116476535797, train_loss: 0.03883197531104088\n",
            "22070 val_loss: 0.1952141523361206, train_loss: 0.03882097080349922\n",
            "22080 val_loss: 0.19380773603916168, train_loss: 0.03688930347561836\n",
            "22090 val_loss: 0.18812195956707, train_loss: 0.03680805116891861\n",
            "22100 val_loss: 0.18962576985359192, train_loss: 0.03584716096520424\n",
            "22110 val_loss: 0.188815176486969, train_loss: 0.03566942736506462\n",
            "22120 val_loss: 0.17740985751152039, train_loss: 0.03628009930253029\n",
            "22130 val_loss: 0.17439360916614532, train_loss: 0.03901594132184982\n",
            "22140 val_loss: 0.18091170489788055, train_loss: 0.03582165390253067\n",
            "22150 val_loss: 0.1923021823167801, train_loss: 0.03612491860985756\n",
            "22160 val_loss: 0.19886653125286102, train_loss: 0.04381197318434715\n",
            "22170 val_loss: 0.18765521049499512, train_loss: 0.03401966392993927\n",
            "22180 val_loss: 0.202307790517807, train_loss: 0.03692248836159706\n",
            "22190 val_loss: 0.1884303092956543, train_loss: 0.03406836465001106\n",
            "22200 val_loss: 0.1994098424911499, train_loss: 0.037566885352134705\n",
            "22210 val_loss: 0.1991516500711441, train_loss: 0.035354454070329666\n",
            "22220 val_loss: 0.18872690200805664, train_loss: 0.03342794254422188\n",
            "22230 val_loss: 0.18514716625213623, train_loss: 0.03324338048696518\n",
            "22240 val_loss: 0.1862439662218094, train_loss: 0.035440731793642044\n",
            "22250 val_loss: 0.23522455990314484, train_loss: 0.04946222901344299\n",
            "22260 val_loss: 0.18248800933361053, train_loss: 0.03401554003357887\n",
            "22270 val_loss: 0.182708278298378, train_loss: 0.034595660865306854\n",
            "22280 val_loss: 0.1923152655363083, train_loss: 0.03392932936549187\n",
            "22290 val_loss: 0.20760414004325867, train_loss: 0.04095673933625221\n",
            "22300 val_loss: 0.21158191561698914, train_loss: 0.03917962312698364\n",
            "22310 val_loss: 0.19737474620342255, train_loss: 0.03655006363987923\n",
            "22320 val_loss: 0.19486233592033386, train_loss: 0.03478453680872917\n",
            "22330 val_loss: 0.19893911480903625, train_loss: 0.03639727830886841\n",
            "22340 val_loss: 0.18817806243896484, train_loss: 0.033254869282245636\n",
            "22350 val_loss: 0.17997685074806213, train_loss: 0.03341240435838699\n",
            "22360 val_loss: 0.19268183410167694, train_loss: 0.03302516043186188\n",
            "22370 val_loss: 0.18589547276496887, train_loss: 0.03254137560725212\n",
            "22380 val_loss: 0.20330138504505157, train_loss: 0.034103937447071075\n",
            "22390 val_loss: 0.20354925096035004, train_loss: 0.03900662809610367\n",
            "22400 val_loss: 0.1821780949831009, train_loss: 0.03384295850992203\n",
            "22410 val_loss: 0.1743873953819275, train_loss: 0.033852435648441315\n",
            "22420 val_loss: 0.19679364562034607, train_loss: 0.03507702797651291\n",
            "22430 val_loss: 0.1803872287273407, train_loss: 0.03316374495625496\n",
            "22440 val_loss: 0.17863202095031738, train_loss: 0.03365102410316467\n",
            "22450 val_loss: 0.1773805171251297, train_loss: 0.031872715801000595\n",
            "22460 val_loss: 0.2314945012331009, train_loss: 0.052135907113552094\n",
            "22470 val_loss: 0.18367506563663483, train_loss: 0.03227207064628601\n",
            "22480 val_loss: 0.1831730455160141, train_loss: 0.03318106755614281\n",
            "22490 val_loss: 0.17981532216072083, train_loss: 0.03280482813715935\n",
            "22500 val_loss: 0.20836807787418365, train_loss: 0.0370979979634285\n",
            "22510 val_loss: 0.18317106366157532, train_loss: 0.03165217116475105\n",
            "22520 val_loss: 0.17426666617393494, train_loss: 0.03259928151965141\n",
            "22530 val_loss: 0.18512818217277527, train_loss: 0.03223826363682747\n",
            "22540 val_loss: 0.2185884416103363, train_loss: 0.03907681629061699\n",
            "22550 val_loss: 0.18438850343227386, train_loss: 0.032024968415498734\n",
            "22560 val_loss: 0.18584273755550385, train_loss: 0.03174607828259468\n",
            "22570 val_loss: 0.18818414211273193, train_loss: 0.03255477547645569\n",
            "22580 val_loss: 0.18777325749397278, train_loss: 0.031235164031386375\n",
            "22590 val_loss: 0.18225711584091187, train_loss: 0.03134624660015106\n",
            "22600 val_loss: 0.194123312830925, train_loss: 0.03140372037887573\n",
            "22610 val_loss: 0.18302826583385468, train_loss: 0.03115469589829445\n",
            "22620 val_loss: 0.18788698315620422, train_loss: 0.031006326898932457\n",
            "22630 val_loss: 0.17806366086006165, train_loss: 0.03162790462374687\n",
            "22640 val_loss: 0.18133163452148438, train_loss: 0.030426479876041412\n",
            "22650 val_loss: 0.18869464099407196, train_loss: 0.031493112444877625\n",
            "22660 val_loss: 0.18174409866333008, train_loss: 0.03103557415306568\n",
            "22670 val_loss: 0.22000190615653992, train_loss: 0.03705395385622978\n",
            "22680 val_loss: 0.1801079362630844, train_loss: 0.030155375599861145\n",
            "22690 val_loss: 0.18990007042884827, train_loss: 0.03119332157075405\n",
            "22700 val_loss: 0.18759691715240479, train_loss: 0.02986975573003292\n",
            "22710 val_loss: 0.18642683327198029, train_loss: 0.029967498034238815\n",
            "22720 val_loss: 0.18664772808551788, train_loss: 0.029815953224897385\n",
            "22730 val_loss: 0.18512766063213348, train_loss: 0.029721610248088837\n",
            "22740 val_loss: 0.19167770445346832, train_loss: 0.030228430405259132\n",
            "22750 val_loss: 0.17987574636936188, train_loss: 0.029295530170202255\n",
            "22760 val_loss: 0.19318246841430664, train_loss: 0.030552616342902184\n",
            "22770 val_loss: 0.1891866773366928, train_loss: 0.028996886685490608\n",
            "22780 val_loss: 0.1999526470899582, train_loss: 0.02994556538760662\n",
            "22790 val_loss: 0.1779397875070572, train_loss: 0.029477559030056\n",
            "22800 val_loss: 0.18134291470050812, train_loss: 0.029604459181427956\n",
            "22810 val_loss: 0.1935964822769165, train_loss: 0.02916799485683441\n",
            "22820 val_loss: 0.18796893954277039, train_loss: 0.02865174598991871\n",
            "22830 val_loss: 0.19186201691627502, train_loss: 0.028956327587366104\n",
            "22840 val_loss: 0.1941610723733902, train_loss: 0.028712429106235504\n",
            "22850 val_loss: 0.1813744306564331, train_loss: 0.029044106602668762\n",
            "22860 val_loss: 0.21286378800868988, train_loss: 0.0331890694797039\n",
            "22870 val_loss: 0.1809721291065216, train_loss: 0.03044295869767666\n",
            "22880 val_loss: 0.18155881762504578, train_loss: 0.02818157523870468\n",
            "22890 val_loss: 0.2109726071357727, train_loss: 0.030713558197021484\n",
            "22900 val_loss: 0.21674087643623352, train_loss: 0.03482789173722267\n",
            "22910 val_loss: 0.18331323564052582, train_loss: 0.028364449739456177\n",
            "22920 val_loss: 0.18699561059474945, train_loss: 0.028473034501075745\n",
            "22930 val_loss: 0.1861775517463684, train_loss: 0.03190917149186134\n",
            "22940 val_loss: 0.1821606308221817, train_loss: 0.02857097238302231\n",
            "22950 val_loss: 0.19236110150814056, train_loss: 0.02858644537627697\n",
            "22960 val_loss: 0.18399129807949066, train_loss: 0.02815239690244198\n",
            "22970 val_loss: 0.197126567363739, train_loss: 0.02838958241045475\n",
            "22980 val_loss: 0.18204376101493835, train_loss: 0.029956229031085968\n",
            "22990 val_loss: 0.19270572066307068, train_loss: 0.027396878227591515\n",
            "23000 val_loss: 0.19178339838981628, train_loss: 0.02738194167613983\n",
            "23010 val_loss: 0.18246157467365265, train_loss: 0.027752961963415146\n",
            "23020 val_loss: 0.1915520429611206, train_loss: 0.028916142880916595\n",
            "23030 val_loss: 0.20284900069236755, train_loss: 0.027984315529465675\n",
            "23040 val_loss: 0.18520162999629974, train_loss: 0.02730381302535534\n",
            "23050 val_loss: 0.20575487613677979, train_loss: 0.029160181060433388\n",
            "23060 val_loss: 0.20078380405902863, train_loss: 0.027241786941885948\n",
            "23070 val_loss: 0.20239466428756714, train_loss: 0.035071324557065964\n",
            "23080 val_loss: 0.2129054069519043, train_loss: 0.029210608452558517\n",
            "23090 val_loss: 0.21001951396465302, train_loss: 0.02735717035830021\n",
            "23100 val_loss: 0.20265553891658783, train_loss: 0.028104957193136215\n",
            "23110 val_loss: 0.18239153921604156, train_loss: 0.026963846758008003\n",
            "23120 val_loss: 0.18580372631549835, train_loss: 0.026763606816530228\n",
            "23130 val_loss: 0.21592369675636292, train_loss: 0.029761631041765213\n",
            "23140 val_loss: 0.1930152177810669, train_loss: 0.028114041313529015\n",
            "23150 val_loss: 0.20528949797153473, train_loss: 0.028563227504491806\n",
            "23160 val_loss: 0.18653973937034607, train_loss: 0.026312531903386116\n",
            "23170 val_loss: 0.1771916002035141, train_loss: 0.02775871939957142\n",
            "23180 val_loss: 0.19312870502471924, train_loss: 0.02672530896961689\n",
            "23190 val_loss: 0.21720406413078308, train_loss: 0.029368465766310692\n",
            "23200 val_loss: 0.19698749482631683, train_loss: 0.026148509234189987\n",
            "23210 val_loss: 0.19891716539859772, train_loss: 0.02587199956178665\n",
            "23220 val_loss: 0.1902041733264923, train_loss: 0.026700954884290695\n",
            "23230 val_loss: 0.19750496745109558, train_loss: 0.026929251849651337\n",
            "23240 val_loss: 0.19143283367156982, train_loss: 0.026970483362674713\n",
            "23250 val_loss: 0.21022078394889832, train_loss: 0.02911349944770336\n",
            "23260 val_loss: 0.1856064796447754, train_loss: 0.026645328849554062\n",
            "23270 val_loss: 0.22195573151111603, train_loss: 0.03033449873328209\n",
            "23280 val_loss: 0.1884310245513916, train_loss: 0.02554972469806671\n",
            "23290 val_loss: 0.18397434055805206, train_loss: 0.035166338086128235\n",
            "23300 val_loss: 0.18444183468818665, train_loss: 0.025476625189185143\n",
            "23310 val_loss: 0.19284693896770477, train_loss: 0.02543397806584835\n",
            "23320 val_loss: 0.21438419818878174, train_loss: 0.029547857120633125\n",
            "23330 val_loss: 0.18610864877700806, train_loss: 0.02560686320066452\n",
            "23340 val_loss: 0.18273349106311798, train_loss: 0.029196476563811302\n",
            "23350 val_loss: 0.19853805005550385, train_loss: 0.02614392712712288\n",
            "23360 val_loss: 0.19869449734687805, train_loss: 0.025447791442275047\n",
            "23370 val_loss: 0.18788975477218628, train_loss: 0.026257703080773354\n",
            "23380 val_loss: 0.20669515430927277, train_loss: 0.03106100857257843\n",
            "23390 val_loss: 0.20426863431930542, train_loss: 0.02598053589463234\n",
            "23400 val_loss: 0.20769314467906952, train_loss: 0.02805912308394909\n",
            "23410 val_loss: 0.2025935798883438, train_loss: 0.02555769495666027\n",
            "23420 val_loss: 0.19324654340744019, train_loss: 0.02515198476612568\n",
            "23430 val_loss: 0.18479111790657043, train_loss: 0.02548823319375515\n",
            "23440 val_loss: 0.2224189192056656, train_loss: 0.02754043973982334\n",
            "23450 val_loss: 0.19399738311767578, train_loss: 0.024874426424503326\n",
            "23460 val_loss: 0.2038951814174652, train_loss: 0.025081012398004532\n",
            "23470 val_loss: 0.1891845464706421, train_loss: 0.024149522185325623\n",
            "23480 val_loss: 0.22436289489269257, train_loss: 0.02793407440185547\n",
            "23490 val_loss: 0.18376918137073517, train_loss: 0.02540268376469612\n",
            "23500 val_loss: 0.19447192549705505, train_loss: 0.031246569007635117\n",
            "23510 val_loss: 0.1810997575521469, train_loss: 0.025124408304691315\n",
            "23520 val_loss: 0.2027401477098465, train_loss: 0.02454918809235096\n",
            "23530 val_loss: 0.19911691546440125, train_loss: 0.024331528693437576\n",
            "23540 val_loss: 0.1906966269016266, train_loss: 0.02361350692808628\n",
            "23550 val_loss: 0.18752779066562653, train_loss: 0.02365093119442463\n",
            "23560 val_loss: 0.17852120101451874, train_loss: 0.023663200438022614\n",
            "23570 val_loss: 0.1887984573841095, train_loss: 0.023197149857878685\n",
            "23580 val_loss: 0.22688128054141998, train_loss: 0.026503020897507668\n",
            "23590 val_loss: 0.19545094668865204, train_loss: 0.02478819526731968\n",
            "23600 val_loss: 0.19711092114448547, train_loss: 0.024302620440721512\n",
            "23610 val_loss: 0.2000366598367691, train_loss: 0.024529213085770607\n",
            "23620 val_loss: 0.19231779873371124, train_loss: 0.02443629316985607\n",
            "23630 val_loss: 0.18545188009738922, train_loss: 0.024297310039401054\n",
            "23640 val_loss: 0.1780005246400833, train_loss: 0.024373486638069153\n",
            "23650 val_loss: 0.1906646490097046, train_loss: 0.023347439244389534\n",
            "23660 val_loss: 0.19295138120651245, train_loss: 0.023024505004286766\n",
            "23670 val_loss: 0.19165289402008057, train_loss: 0.023366909474134445\n",
            "23680 val_loss: 0.20076903700828552, train_loss: 0.022500524297356606\n",
            "23690 val_loss: 0.20817267894744873, train_loss: 0.023343052715063095\n",
            "23700 val_loss: 0.20514395833015442, train_loss: 0.0233388040214777\n",
            "23710 val_loss: 0.19265951216220856, train_loss: 0.02319209650158882\n",
            "23720 val_loss: 0.20541495084762573, train_loss: 0.02272001840174198\n",
            "23730 val_loss: 0.193340465426445, train_loss: 0.02285202592611313\n",
            "23740 val_loss: 0.1880332976579666, train_loss: 0.02290673553943634\n",
            "23750 val_loss: 0.19414737820625305, train_loss: 0.02208539843559265\n",
            "23760 val_loss: 0.1950347125530243, train_loss: 0.022074108943343163\n",
            "23770 val_loss: 0.22266925871372223, train_loss: 0.02387099899351597\n",
            "23780 val_loss: 0.1913050264120102, train_loss: 0.0221497043967247\n",
            "23790 val_loss: 0.18835236132144928, train_loss: 0.022288696840405464\n",
            "23800 val_loss: 0.20053508877754211, train_loss: 0.0320282056927681\n",
            "23810 val_loss: 0.20403502881526947, train_loss: 0.022861763834953308\n",
            "23820 val_loss: 0.20344698429107666, train_loss: 0.022906389087438583\n",
            "23830 val_loss: 0.21426977217197418, train_loss: 0.023515041917562485\n",
            "23840 val_loss: 0.1898077130317688, train_loss: 0.02252468466758728\n",
            "23850 val_loss: 0.22048495709896088, train_loss: 0.023216487839818\n",
            "23860 val_loss: 0.20558466017246246, train_loss: 0.02228282392024994\n",
            "23870 val_loss: 0.19231532514095306, train_loss: 0.02274344488978386\n",
            "23880 val_loss: 0.199855774641037, train_loss: 0.021739060059189796\n",
            "23890 val_loss: 0.19575512409210205, train_loss: 0.022784972563385963\n",
            "23900 val_loss: 0.19711215794086456, train_loss: 0.02185731567442417\n",
            "23910 val_loss: 0.19024157524108887, train_loss: 0.021485336124897003\n",
            "23920 val_loss: 0.19862088561058044, train_loss: 0.02166837640106678\n",
            "23930 val_loss: 0.18532390892505646, train_loss: 0.022394759580492973\n",
            "23940 val_loss: 0.20598731935024261, train_loss: 0.021641356870532036\n",
            "23950 val_loss: 0.20391984283924103, train_loss: 0.022385532036423683\n",
            "23960 val_loss: 0.20892584323883057, train_loss: 0.022087762132287025\n",
            "23970 val_loss: 0.20287135243415833, train_loss: 0.023538921028375626\n",
            "23980 val_loss: 0.1940065324306488, train_loss: 0.02137196995317936\n",
            "23990 val_loss: 0.18512579798698425, train_loss: 0.021928781643509865\n",
            "24000 val_loss: 0.1985912024974823, train_loss: 0.02254599705338478\n",
            "24010 val_loss: 0.18999925255775452, train_loss: 0.02109500579535961\n",
            "24020 val_loss: 0.24353724718093872, train_loss: 0.03299318626523018\n",
            "24030 val_loss: 0.21020594239234924, train_loss: 0.022115858271718025\n",
            "24040 val_loss: 0.19357725977897644, train_loss: 0.0213619451969862\n",
            "24050 val_loss: 0.20454996824264526, train_loss: 0.021771114319562912\n",
            "24060 val_loss: 0.19922873377799988, train_loss: 0.020664487034082413\n",
            "24070 val_loss: 0.2028501182794571, train_loss: 0.02074071392416954\n",
            "24080 val_loss: 0.21775886416435242, train_loss: 0.02323700673878193\n",
            "24090 val_loss: 0.19839493930339813, train_loss: 0.020885633304715157\n",
            "24100 val_loss: 0.19799913465976715, train_loss: 0.021483207121491432\n",
            "24110 val_loss: 0.20597882568836212, train_loss: 0.02146376110613346\n",
            "24120 val_loss: 0.1913115680217743, train_loss: 0.022077010944485664\n",
            "24130 val_loss: 0.20358414947986603, train_loss: 0.02072504162788391\n",
            "24140 val_loss: 0.21422915160655975, train_loss: 0.02087228372693062\n",
            "24150 val_loss: 0.22801563143730164, train_loss: 0.023181572556495667\n",
            "24160 val_loss: 0.23743420839309692, train_loss: 0.026076888665556908\n",
            "24170 val_loss: 0.24695026874542236, train_loss: 0.030409950762987137\n",
            "24180 val_loss: 0.20464618504047394, train_loss: 0.020736465230584145\n",
            "24190 val_loss: 0.19617223739624023, train_loss: 0.02088659442961216\n",
            "24200 val_loss: 0.19290806353092194, train_loss: 0.02015163004398346\n",
            "24210 val_loss: 0.19467635452747345, train_loss: 0.020399300381541252\n",
            "24220 val_loss: 0.21609289944171906, train_loss: 0.022943781688809395\n",
            "24230 val_loss: 0.20197950303554535, train_loss: 0.020354025065898895\n",
            "24240 val_loss: 0.18419387936592102, train_loss: 0.02153477817773819\n",
            "24250 val_loss: 0.19198954105377197, train_loss: 0.021992649883031845\n",
            "24260 val_loss: 0.19532449543476105, train_loss: 0.01985250972211361\n",
            "24270 val_loss: 0.19191451370716095, train_loss: 0.019951149821281433\n",
            "24280 val_loss: 0.18525120615959167, train_loss: 0.019825248047709465\n",
            "24290 val_loss: 0.21596740186214447, train_loss: 0.021320797502994537\n",
            "24300 val_loss: 0.1872815191745758, train_loss: 0.01962483488023281\n",
            "24310 val_loss: 0.19676296412944794, train_loss: 0.019934561103582382\n",
            "24320 val_loss: 0.19488491117954254, train_loss: 0.020238187164068222\n",
            "24330 val_loss: 0.2295694649219513, train_loss: 0.022953031584620476\n",
            "24340 val_loss: 0.2116342931985855, train_loss: 0.020715631544589996\n",
            "24350 val_loss: 0.22883813083171844, train_loss: 0.022048737853765488\n",
            "24360 val_loss: 0.20162954926490784, train_loss: 0.019582310691475868\n",
            "24370 val_loss: 0.2008298933506012, train_loss: 0.019646544009447098\n",
            "24380 val_loss: 0.23359878361225128, train_loss: 0.02247525006532669\n",
            "24390 val_loss: 0.21925465762615204, train_loss: 0.021213660016655922\n",
            "24400 val_loss: 0.19386841356754303, train_loss: 0.02034728415310383\n",
            "24410 val_loss: 0.24692592024803162, train_loss: 0.02476627565920353\n",
            "24420 val_loss: 0.20535287261009216, train_loss: 0.019959865137934685\n",
            "24430 val_loss: 0.19522163271903992, train_loss: 0.020119592547416687\n",
            "24440 val_loss: 0.1958564966917038, train_loss: 0.020505836233496666\n",
            "24450 val_loss: 0.227035790681839, train_loss: 0.021009132266044617\n",
            "24460 val_loss: 0.2353561669588089, train_loss: 0.024638419970870018\n",
            "24470 val_loss: 0.21715813875198364, train_loss: 0.020581001415848732\n",
            "24480 val_loss: 0.19327683746814728, train_loss: 0.019184237346053123\n",
            "24490 val_loss: 0.2130660116672516, train_loss: 0.02024262025952339\n",
            "24500 val_loss: 0.26979193091392517, train_loss: 0.03244541957974434\n",
            "24510 val_loss: 0.2137647122144699, train_loss: 0.019823763519525528\n",
            "24520 val_loss: 0.2093515843153, train_loss: 0.019104503095149994\n",
            "24530 val_loss: 0.19344159960746765, train_loss: 0.01885870471596718\n",
            "24540 val_loss: 0.18502582609653473, train_loss: 0.019142242148518562\n",
            "24550 val_loss: 0.20339661836624146, train_loss: 0.019793637096881866\n",
            "24560 val_loss: 0.1837877482175827, train_loss: 0.0191830862313509\n",
            "24570 val_loss: 0.2181275188922882, train_loss: 0.020296789705753326\n",
            "24580 val_loss: 0.21871086955070496, train_loss: 0.020780635997653008\n",
            "24590 val_loss: 0.20957434177398682, train_loss: 0.019181786105036736\n",
            "24600 val_loss: 0.2237086296081543, train_loss: 0.020657101646065712\n",
            "24610 val_loss: 0.20396718382835388, train_loss: 0.01888338103890419\n",
            "24620 val_loss: 0.2085682600736618, train_loss: 0.032070863991975784\n",
            "24630 val_loss: 0.2250158190727234, train_loss: 0.020289193838834763\n",
            "24640 val_loss: 0.1968526393175125, train_loss: 0.018652938306331635\n",
            "24650 val_loss: 0.21132555603981018, train_loss: 0.01937440037727356\n",
            "24660 val_loss: 0.20498448610305786, train_loss: 0.01849544607102871\n",
            "24670 val_loss: 0.21828272938728333, train_loss: 0.019284764304757118\n",
            "24680 val_loss: 0.2074611335992813, train_loss: 0.01829509809613228\n",
            "24690 val_loss: 0.18343821167945862, train_loss: 0.020915230736136436\n",
            "24700 val_loss: 0.21221792697906494, train_loss: 0.018606241792440414\n",
            "24710 val_loss: 0.192098930478096, train_loss: 0.01951008290052414\n",
            "24720 val_loss: 0.19980517029762268, train_loss: 0.01891189254820347\n",
            "24730 val_loss: 0.23234279453754425, train_loss: 0.022133253514766693\n",
            "24740 val_loss: 0.2229534089565277, train_loss: 0.021789902821183205\n",
            "24750 val_loss: 0.2083873301744461, train_loss: 0.01872892864048481\n",
            "24760 val_loss: 0.2422836571931839, train_loss: 0.022851994261145592\n",
            "24770 val_loss: 0.2326785922050476, train_loss: 0.022438619285821915\n",
            "24780 val_loss: 0.19615736603736877, train_loss: 0.01911870203912258\n",
            "24790 val_loss: 0.21052291989326477, train_loss: 0.01899607852101326\n",
            "24800 val_loss: 0.20919479429721832, train_loss: 0.018392164260149002\n",
            "24810 val_loss: 0.2011069357395172, train_loss: 0.017998257651925087\n",
            "24820 val_loss: 0.2049284279346466, train_loss: 0.01768919825553894\n",
            "24830 val_loss: 0.2045707404613495, train_loss: 0.01829051412642002\n",
            "24840 val_loss: 0.21792446076869965, train_loss: 0.01853562332689762\n",
            "24850 val_loss: 0.18982309103012085, train_loss: 0.018361296504735947\n",
            "24860 val_loss: 0.2186787873506546, train_loss: 0.017850646749138832\n",
            "24870 val_loss: 0.2108866572380066, train_loss: 0.021068403497338295\n",
            "24880 val_loss: 0.1934298574924469, train_loss: 0.01861703209578991\n",
            "24890 val_loss: 0.21377189457416534, train_loss: 0.017773007974028587\n",
            "24900 val_loss: 0.21604010462760925, train_loss: 0.018360963091254234\n",
            "24910 val_loss: 0.20803606510162354, train_loss: 0.01955624669790268\n",
            "24920 val_loss: 0.2117656022310257, train_loss: 0.01776672713458538\n",
            "24930 val_loss: 0.214706152677536, train_loss: 0.017888527363538742\n",
            "24940 val_loss: 0.2352050393819809, train_loss: 0.022056609392166138\n",
            "24950 val_loss: 0.20912626385688782, train_loss: 0.018305057659745216\n",
            "24960 val_loss: 0.20007769763469696, train_loss: 0.017481304705142975\n",
            "24970 val_loss: 0.19144414365291595, train_loss: 0.01786264404654503\n",
            "24980 val_loss: 0.17771433293819427, train_loss: 0.018834508955478668\n",
            "24990 val_loss: 0.20771585404872894, train_loss: 0.018336080014705658\n",
            "25000 val_loss: 0.2234286069869995, train_loss: 0.01899208500981331\n",
            "25010 val_loss: 0.22320279479026794, train_loss: 0.01818733476102352\n",
            "25020 val_loss: 0.2172987312078476, train_loss: 0.01800457015633583\n",
            "25030 val_loss: 0.19938728213310242, train_loss: 0.01876569166779518\n",
            "25040 val_loss: 0.20091615617275238, train_loss: 0.018521197140216827\n",
            "25050 val_loss: 0.2029704600572586, train_loss: 0.020561112090945244\n",
            "25060 val_loss: 0.2058786153793335, train_loss: 0.018974334001541138\n",
            "25070 val_loss: 0.19945167005062103, train_loss: 0.017772680148482323\n",
            "25080 val_loss: 0.1942586600780487, train_loss: 0.017947131767868996\n",
            "25090 val_loss: 0.21820363402366638, train_loss: 0.017851460725069046\n",
            "25100 val_loss: 0.21258896589279175, train_loss: 0.017366459593176842\n",
            "25110 val_loss: 0.23944343626499176, train_loss: 0.019083550199866295\n",
            "25120 val_loss: 0.2085014283657074, train_loss: 0.017487289384007454\n",
            "25130 val_loss: 0.2581605315208435, train_loss: 0.027317116037011147\n",
            "25140 val_loss: 0.18861958384513855, train_loss: 0.018917664885520935\n",
            "25150 val_loss: 0.19606097042560577, train_loss: 0.018267612904310226\n",
            "25160 val_loss: 0.20901501178741455, train_loss: 0.018615195527672768\n",
            "25170 val_loss: 0.20633216202259064, train_loss: 0.017874816432595253\n",
            "25180 val_loss: 0.20895016193389893, train_loss: 0.017256511375308037\n",
            "25190 val_loss: 0.2042345553636551, train_loss: 0.018086571246385574\n",
            "25200 val_loss: 0.25003787875175476, train_loss: 0.022283846512436867\n",
            "25210 val_loss: 0.2052285522222519, train_loss: 0.017116330564022064\n",
            "25220 val_loss: 0.24732987582683563, train_loss: 0.01849556714296341\n",
            "25230 val_loss: 0.20633848011493683, train_loss: 0.017563190311193466\n",
            "25240 val_loss: 0.22488950192928314, train_loss: 0.017151767387986183\n",
            "25250 val_loss: 0.21827715635299683, train_loss: 0.01669793389737606\n",
            "25260 val_loss: 0.19987833499908447, train_loss: 0.016723375767469406\n",
            "25270 val_loss: 0.2041042000055313, train_loss: 0.019070236012339592\n",
            "25280 val_loss: 0.2371957153081894, train_loss: 0.0203020628541708\n",
            "25290 val_loss: 0.2176525890827179, train_loss: 0.01694398559629917\n",
            "25300 val_loss: 0.22373294830322266, train_loss: 0.017426511272788048\n",
            "25310 val_loss: 0.25388839840888977, train_loss: 0.020825902000069618\n",
            "25320 val_loss: 0.22218649089336395, train_loss: 0.017214570194482803\n",
            "25330 val_loss: 0.2069995105266571, train_loss: 0.01652958244085312\n",
            "25340 val_loss: 0.20478586852550507, train_loss: 0.017014155164361\n",
            "25350 val_loss: 0.25079217553138733, train_loss: 0.02147095836699009\n",
            "25360 val_loss: 0.2129664123058319, train_loss: 0.01685119979083538\n",
            "25370 val_loss: 0.19120332598686218, train_loss: 0.018783435225486755\n",
            "25380 val_loss: 0.22056443989276886, train_loss: 0.017774401232600212\n",
            "25390 val_loss: 0.20759040117263794, train_loss: 0.01665259338915348\n",
            "25400 val_loss: 0.21433696150779724, train_loss: 0.016653070226311684\n",
            "25410 val_loss: 0.20449288189411163, train_loss: 0.016977563500404358\n",
            "25420 val_loss: 0.22591274976730347, train_loss: 0.016270631924271584\n",
            "25430 val_loss: 0.2051020860671997, train_loss: 0.016272852197289467\n",
            "25440 val_loss: 0.22749683260917664, train_loss: 0.01796436496078968\n",
            "25450 val_loss: 0.19071553647518158, train_loss: 0.018516823649406433\n",
            "25460 val_loss: 0.20008373260498047, train_loss: 0.01732330210506916\n",
            "25470 val_loss: 0.20900024473667145, train_loss: 0.016958191990852356\n",
            "25480 val_loss: 0.20557153224945068, train_loss: 0.018232043832540512\n",
            "25490 val_loss: 0.2332584261894226, train_loss: 0.01754048652946949\n",
            "25500 val_loss: 0.20327690243721008, train_loss: 0.0173711646348238\n",
            "25510 val_loss: 0.1990727186203003, train_loss: 0.016575494781136513\n",
            "25520 val_loss: 0.19881117343902588, train_loss: 0.017230750992894173\n",
            "25530 val_loss: 0.2325829565525055, train_loss: 0.01767203025519848\n",
            "25540 val_loss: 0.20489943027496338, train_loss: 0.01649315655231476\n",
            "25550 val_loss: 0.22509527206420898, train_loss: 0.01794726774096489\n",
            "25560 val_loss: 0.24845139682292938, train_loss: 0.01930641382932663\n",
            "25570 val_loss: 0.21465803682804108, train_loss: 0.01622900925576687\n",
            "25580 val_loss: 0.22155587375164032, train_loss: 0.016040101647377014\n",
            "25590 val_loss: 0.2136031538248062, train_loss: 0.015704145655035973\n",
            "25600 val_loss: 0.2057766616344452, train_loss: 0.015820683911442757\n",
            "25610 val_loss: 0.20825517177581787, train_loss: 0.017785174772143364\n",
            "25620 val_loss: 0.23253539204597473, train_loss: 0.018655654042959213\n",
            "25630 val_loss: 0.2042139768600464, train_loss: 0.01638571359217167\n",
            "25640 val_loss: 0.2152266800403595, train_loss: 0.01552942581474781\n",
            "25650 val_loss: 0.21722981333732605, train_loss: 0.016102055087685585\n",
            "25660 val_loss: 0.20769217610359192, train_loss: 0.015287252143025398\n",
            "25670 val_loss: 0.21674439311027527, train_loss: 0.015553884208202362\n",
            "25680 val_loss: 0.2006235420703888, train_loss: 0.016625307500362396\n",
            "25690 val_loss: 0.2131255865097046, train_loss: 0.015410816296935081\n",
            "25700 val_loss: 0.2655968964099884, train_loss: 0.025084009394049644\n",
            "25710 val_loss: 0.2294004112482071, train_loss: 0.016272742301225662\n",
            "25720 val_loss: 0.23962320387363434, train_loss: 0.016637608408927917\n",
            "25730 val_loss: 0.2096891850233078, train_loss: 0.015518554486334324\n",
            "25740 val_loss: 0.19451801478862762, train_loss: 0.01573730632662773\n",
            "25750 val_loss: 0.19517169892787933, train_loss: 0.01575559936463833\n",
            "25760 val_loss: 0.2244562804698944, train_loss: 0.017591293901205063\n",
            "25770 val_loss: 0.2028973400592804, train_loss: 0.01569214276969433\n",
            "25780 val_loss: 0.207626074552536, train_loss: 0.015939559787511826\n",
            "25790 val_loss: 0.24652478098869324, train_loss: 0.017815712839365005\n",
            "25800 val_loss: 0.207109272480011, train_loss: 0.015721049159765244\n",
            "25810 val_loss: 0.22606311738491058, train_loss: 0.016128629446029663\n",
            "25820 val_loss: 0.21448907256126404, train_loss: 0.015461288392543793\n",
            "25830 val_loss: 0.20729082822799683, train_loss: 0.01572556421160698\n",
            "25840 val_loss: 0.24062585830688477, train_loss: 0.01803274266421795\n",
            "25850 val_loss: 0.21604090929031372, train_loss: 0.015822358429431915\n",
            "25860 val_loss: 0.20236830413341522, train_loss: 0.017001131549477577\n",
            "25870 val_loss: 0.22477133572101593, train_loss: 0.015718290582299232\n",
            "25880 val_loss: 0.2414194792509079, train_loss: 0.017749818041920662\n",
            "25890 val_loss: 0.2549942433834076, train_loss: 0.019086232408881187\n",
            "25900 val_loss: 0.1968681961297989, train_loss: 0.01624341867864132\n",
            "25910 val_loss: 0.218857079744339, train_loss: 0.015247663483023643\n",
            "25920 val_loss: 0.2318272590637207, train_loss: 0.015687985345721245\n",
            "25930 val_loss: 0.23945601284503937, train_loss: 0.015063338913023472\n",
            "25940 val_loss: 0.25423166155815125, train_loss: 0.01757095754146576\n",
            "25950 val_loss: 0.234533429145813, train_loss: 0.015170194208621979\n",
            "25960 val_loss: 0.2249765694141388, train_loss: 0.014671710319817066\n",
            "25970 val_loss: 0.2148333489894867, train_loss: 0.014834892004728317\n",
            "25980 val_loss: 0.2354600727558136, train_loss: 0.015690261498093605\n",
            "25990 val_loss: 0.2365921288728714, train_loss: 0.017438527196645737\n",
            "26000 val_loss: 0.21126465499401093, train_loss: 0.015503786504268646\n",
            "26010 val_loss: 0.21981999278068542, train_loss: 0.015134653076529503\n",
            "26020 val_loss: 0.21348822116851807, train_loss: 0.015014313161373138\n",
            "26030 val_loss: 0.22078227996826172, train_loss: 0.015042129904031754\n",
            "26040 val_loss: 0.20304614305496216, train_loss: 0.015375331044197083\n",
            "26050 val_loss: 0.22471588850021362, train_loss: 0.015033074654638767\n",
            "26060 val_loss: 0.2246149331331253, train_loss: 0.015120928175747395\n",
            "26070 val_loss: 0.20353589951992035, train_loss: 0.015480384230613708\n",
            "26080 val_loss: 0.22422204911708832, train_loss: 0.015238022431731224\n",
            "26090 val_loss: 0.2111169695854187, train_loss: 0.014752915129065514\n",
            "26100 val_loss: 0.20542274415493011, train_loss: 0.015130401588976383\n",
            "26110 val_loss: 0.20545804500579834, train_loss: 0.014815660193562508\n",
            "26120 val_loss: 0.24753250181674957, train_loss: 0.01662662997841835\n",
            "26130 val_loss: 0.23373685777187347, train_loss: 0.015161904506385326\n",
            "26140 val_loss: 0.2016807347536087, train_loss: 0.015477549284696579\n",
            "26150 val_loss: 0.2206253707408905, train_loss: 0.014589202590286732\n",
            "26160 val_loss: 0.20758694410324097, train_loss: 0.016496609896421432\n",
            "26170 val_loss: 0.21344956755638123, train_loss: 0.014674775302410126\n",
            "26180 val_loss: 0.18800003826618195, train_loss: 0.01651007868349552\n",
            "26190 val_loss: 0.21376140415668488, train_loss: 0.014375163242220879\n",
            "26200 val_loss: 0.22423402965068817, train_loss: 0.014790816232562065\n",
            "26210 val_loss: 0.22221378982067108, train_loss: 0.014867229387164116\n",
            "26220 val_loss: 0.22949659824371338, train_loss: 0.015168706886470318\n",
            "26230 val_loss: 0.24519291520118713, train_loss: 0.01669059507548809\n",
            "26240 val_loss: 0.23281952738761902, train_loss: 0.015499100089073181\n",
            "26250 val_loss: 0.19189339876174927, train_loss: 0.015376020222902298\n",
            "26260 val_loss: 0.2423112988471985, train_loss: 0.015935899689793587\n",
            "26270 val_loss: 0.24091482162475586, train_loss: 0.01680024527013302\n",
            "26280 val_loss: 0.22534573078155518, train_loss: 0.015335362404584885\n",
            "26290 val_loss: 0.23085005581378937, train_loss: 0.014933819882571697\n",
            "26300 val_loss: 0.2661648392677307, train_loss: 0.02136230282485485\n",
            "26310 val_loss: 0.195560485124588, train_loss: 0.014833291992545128\n",
            "26320 val_loss: 0.21278585493564606, train_loss: 0.014633825980126858\n",
            "26330 val_loss: 0.20296934247016907, train_loss: 0.01447451114654541\n",
            "26340 val_loss: 0.21540820598602295, train_loss: 0.014570445753633976\n",
            "26350 val_loss: 0.20587357878684998, train_loss: 0.01509111188352108\n",
            "26360 val_loss: 0.22879846394062042, train_loss: 0.014919396489858627\n",
            "26370 val_loss: 0.21998578310012817, train_loss: 0.014319142326712608\n",
            "26380 val_loss: 0.19767475128173828, train_loss: 0.01489208173006773\n",
            "26390 val_loss: 0.21462872624397278, train_loss: 0.01384403370320797\n",
            "26400 val_loss: 0.22485177218914032, train_loss: 0.013945014216005802\n",
            "26410 val_loss: 0.2068643867969513, train_loss: 0.013818089850246906\n",
            "26420 val_loss: 0.2512882649898529, train_loss: 0.016301609575748444\n",
            "26430 val_loss: 0.23525917530059814, train_loss: 0.014131477102637291\n",
            "26440 val_loss: 0.20607039332389832, train_loss: 0.014405199326574802\n",
            "26450 val_loss: 0.22200915217399597, train_loss: 0.013668750412762165\n",
            "26460 val_loss: 0.2830128073692322, train_loss: 0.021023638546466827\n",
            "26470 val_loss: 0.2207244485616684, train_loss: 0.01356577966362238\n",
            "26480 val_loss: 0.21908991038799286, train_loss: 0.013635169714689255\n",
            "26490 val_loss: 0.22821871936321259, train_loss: 0.013657698407769203\n",
            "26500 val_loss: 0.24896882474422455, train_loss: 0.01513419859111309\n",
            "26510 val_loss: 0.20908872783184052, train_loss: 0.014846989884972572\n",
            "26520 val_loss: 0.23885029554367065, train_loss: 0.01479687262326479\n",
            "26530 val_loss: 0.21431052684783936, train_loss: 0.013713797554373741\n",
            "26540 val_loss: 0.20720040798187256, train_loss: 0.014640552923083305\n",
            "26550 val_loss: 0.23269926011562347, train_loss: 0.014061077497899532\n",
            "26560 val_loss: 0.24716559052467346, train_loss: 0.015692515298724174\n",
            "26570 val_loss: 0.22379957139492035, train_loss: 0.01414124108850956\n",
            "26580 val_loss: 0.20059043169021606, train_loss: 0.015209272503852844\n",
            "26590 val_loss: 0.2143147587776184, train_loss: 0.01533434260636568\n",
            "26600 val_loss: 0.19802606105804443, train_loss: 0.01628250628709793\n",
            "26610 val_loss: 0.25490880012512207, train_loss: 0.016395701095461845\n",
            "26620 val_loss: 0.24443067610263824, train_loss: 0.014004434458911419\n",
            "26630 val_loss: 0.26768261194229126, train_loss: 0.017527073621749878\n",
            "26640 val_loss: 0.22537024319171906, train_loss: 0.017991265282034874\n",
            "26650 val_loss: 0.25822117924690247, train_loss: 0.019246723502874374\n",
            "26660 val_loss: 0.2178703248500824, train_loss: 0.014816231094300747\n",
            "26670 val_loss: 0.21452631056308746, train_loss: 0.014242371544241905\n",
            "26680 val_loss: 0.22533035278320312, train_loss: 0.014644583687186241\n",
            "26690 val_loss: 0.22756056487560272, train_loss: 0.014629492536187172\n",
            "26700 val_loss: 0.19705817103385925, train_loss: 0.01489249151200056\n",
            "26710 val_loss: 0.22486479580402374, train_loss: 0.014044670388102531\n",
            "26720 val_loss: 0.21291419863700867, train_loss: 0.013854114338755608\n",
            "26730 val_loss: 0.2357116937637329, train_loss: 0.0235251747071743\n",
            "26740 val_loss: 0.2068251669406891, train_loss: 0.014559436589479446\n",
            "26750 val_loss: 0.2053116112947464, train_loss: 0.014742258004844189\n",
            "26760 val_loss: 0.24431630969047546, train_loss: 0.01527919340878725\n",
            "26770 val_loss: 0.2810182571411133, train_loss: 0.019961943849921227\n",
            "26780 val_loss: 0.22217604517936707, train_loss: 0.013951819390058517\n",
            "26790 val_loss: 0.21504461765289307, train_loss: 0.013758647255599499\n",
            "26800 val_loss: 0.2290685921907425, train_loss: 0.013573400676250458\n",
            "26810 val_loss: 0.216394305229187, train_loss: 0.013634772039949894\n",
            "26820 val_loss: 0.19998393952846527, train_loss: 0.01613556407392025\n",
            "26830 val_loss: 0.21309150755405426, train_loss: 0.01325096283107996\n",
            "26840 val_loss: 0.21835334599018097, train_loss: 0.013638632372021675\n",
            "26850 val_loss: 0.20294758677482605, train_loss: 0.015368858352303505\n",
            "26860 val_loss: 0.2001534402370453, train_loss: 0.013780799694359303\n",
            "26870 val_loss: 0.21155183017253876, train_loss: 0.012838904745876789\n",
            "26880 val_loss: 0.20140984654426575, train_loss: 0.014898281544446945\n",
            "26890 val_loss: 0.2438042014837265, train_loss: 0.013460285030305386\n",
            "26900 val_loss: 0.19527959823608398, train_loss: 0.015908757224678993\n",
            "26910 val_loss: 0.23708438873291016, train_loss: 0.014822916127741337\n",
            "26920 val_loss: 0.22098563611507416, train_loss: 0.013221261091530323\n",
            "26930 val_loss: 0.22180506587028503, train_loss: 0.013308685272932053\n",
            "26940 val_loss: 0.24370667338371277, train_loss: 0.014302575960755348\n",
            "26950 val_loss: 0.2552540600299835, train_loss: 0.015567195601761341\n",
            "26960 val_loss: 0.238150954246521, train_loss: 0.014230294153094292\n",
            "26970 val_loss: 0.2475614994764328, train_loss: 0.014082073234021664\n",
            "26980 val_loss: 0.21390074491500854, train_loss: 0.013605646789073944\n",
            "26990 val_loss: 0.21923920512199402, train_loss: 0.013804973103106022\n",
            "27000 val_loss: 0.21812695264816284, train_loss: 0.013625799678266048\n",
            "27010 val_loss: 0.24292699992656708, train_loss: 0.014322399161756039\n",
            "27020 val_loss: 0.2943881154060364, train_loss: 0.023075716570019722\n",
            "27030 val_loss: 0.22109867632389069, train_loss: 0.013183614239096642\n",
            "27040 val_loss: 0.21909673511981964, train_loss: 0.013187212869524956\n",
            "27050 val_loss: 0.2276913970708847, train_loss: 0.013087664730846882\n",
            "27060 val_loss: 0.2113809883594513, train_loss: 0.013028048910200596\n",
            "27070 val_loss: 0.23551850020885468, train_loss: 0.013397853821516037\n",
            "27080 val_loss: 0.23632074892520905, train_loss: 0.013263149186968803\n",
            "27090 val_loss: 0.20406582951545715, train_loss: 0.014437500387430191\n",
            "27100 val_loss: 0.20871396362781525, train_loss: 0.013637117110192776\n",
            "27110 val_loss: 0.23980286717414856, train_loss: 0.013459502719342709\n",
            "27120 val_loss: 0.24725419282913208, train_loss: 0.014764107763767242\n",
            "27130 val_loss: 0.21865281462669373, train_loss: 0.013640510849654675\n",
            "27140 val_loss: 0.21363292634487152, train_loss: 0.01392298098653555\n",
            "27150 val_loss: 0.2276618778705597, train_loss: 0.013353821821510792\n",
            "27160 val_loss: 0.23670387268066406, train_loss: 0.013572598807513714\n",
            "27170 val_loss: 0.24910706281661987, train_loss: 0.015489736571907997\n",
            "27180 val_loss: 0.23458853363990784, train_loss: 0.014042723923921585\n",
            "27190 val_loss: 0.25879228115081787, train_loss: 0.016232235357165337\n",
            "27200 val_loss: 0.22598087787628174, train_loss: 0.013522651977837086\n",
            "27210 val_loss: 0.22409868240356445, train_loss: 0.013268987648189068\n",
            "27220 val_loss: 0.21397912502288818, train_loss: 0.014110625721514225\n",
            "27230 val_loss: 0.2194979041814804, train_loss: 0.013244506902992725\n",
            "27240 val_loss: 0.23434443771839142, train_loss: 0.013325974345207214\n",
            "27250 val_loss: 0.20508329570293427, train_loss: 0.014811941422522068\n",
            "27260 val_loss: 0.23006005585193634, train_loss: 0.013773608021438122\n",
            "27270 val_loss: 0.2707919776439667, train_loss: 0.017459064722061157\n",
            "27280 val_loss: 0.24116122722625732, train_loss: 0.014068656601011753\n",
            "27290 val_loss: 0.2154790759086609, train_loss: 0.013889133930206299\n",
            "27300 val_loss: 0.21359717845916748, train_loss: 0.013533934950828552\n",
            "27310 val_loss: 0.20894114673137665, train_loss: 0.013423671945929527\n",
            "27320 val_loss: 0.2502664029598236, train_loss: 0.014559503644704819\n",
            "27330 val_loss: 0.24035687744617462, train_loss: 0.013532928191125393\n",
            "27340 val_loss: 0.21360571682453156, train_loss: 0.013993702828884125\n",
            "27350 val_loss: 0.29967567324638367, train_loss: 0.023258551955223083\n",
            "27360 val_loss: 0.22346730530261993, train_loss: 0.013306908309459686\n",
            "27370 val_loss: 0.24736322462558746, train_loss: 0.014282755553722382\n",
            "27380 val_loss: 0.21827475726604462, train_loss: 0.013194347731769085\n",
            "27390 val_loss: 0.2538740038871765, train_loss: 0.014393397606909275\n",
            "27400 val_loss: 0.25925183296203613, train_loss: 0.01480195578187704\n",
            "27410 val_loss: 0.23893192410469055, train_loss: 0.013158220797777176\n",
            "27420 val_loss: 0.2118278443813324, train_loss: 0.012632979080080986\n",
            "27430 val_loss: 0.278463751077652, train_loss: 0.016462188214063644\n",
            "27440 val_loss: 0.24995562434196472, train_loss: 0.014411724172532558\n",
            "27450 val_loss: 0.2235933095216751, train_loss: 0.012272462248802185\n",
            "27460 val_loss: 0.24751442670822144, train_loss: 0.013028009794652462\n",
            "27470 val_loss: 0.2169904261827469, train_loss: 0.013176667504012585\n",
            "27480 val_loss: 0.20939186215400696, train_loss: 0.013859089463949203\n",
            "27490 val_loss: 0.22414831817150116, train_loss: 0.0199686661362648\n",
            "27500 val_loss: 0.24170441925525665, train_loss: 0.012856915593147278\n",
            "27510 val_loss: 0.21113517880439758, train_loss: 0.014554916881024837\n",
            "27520 val_loss: 0.21813227236270905, train_loss: 0.012636491097509861\n",
            "27530 val_loss: 0.21344569325447083, train_loss: 0.015118174254894257\n",
            "27540 val_loss: 0.22219201922416687, train_loss: 0.013718981295824051\n",
            "27550 val_loss: 0.2197597622871399, train_loss: 0.012447685934603214\n",
            "27560 val_loss: 0.2375105619430542, train_loss: 0.012741274200379848\n",
            "27570 val_loss: 0.21329548954963684, train_loss: 0.012344122864305973\n",
            "27580 val_loss: 0.2226364016532898, train_loss: 0.012251428328454494\n",
            "27590 val_loss: 0.29298776388168335, train_loss: 0.02259468287229538\n",
            "27600 val_loss: 0.223471999168396, train_loss: 0.01278144121170044\n",
            "27610 val_loss: 0.23052194714546204, train_loss: 0.013146590441465378\n",
            "27620 val_loss: 0.21243517100811005, train_loss: 0.01373143307864666\n",
            "27630 val_loss: 0.23587796092033386, train_loss: 0.012519455514848232\n",
            "27640 val_loss: 0.2859785258769989, train_loss: 0.018876932561397552\n",
            "27650 val_loss: 0.25016844272613525, train_loss: 0.014329686760902405\n",
            "27660 val_loss: 0.2080739140510559, train_loss: 0.013866974040865898\n",
            "27670 val_loss: 0.22158782184123993, train_loss: 0.012156586162745953\n",
            "27680 val_loss: 0.23783667385578156, train_loss: 0.012063932605087757\n",
            "27690 val_loss: 0.24816058576107025, train_loss: 0.01299230195581913\n",
            "27700 val_loss: 0.2407592386007309, train_loss: 0.012867449782788754\n",
            "27710 val_loss: 0.2465449720621109, train_loss: 0.01312220934778452\n",
            "27720 val_loss: 0.21788138151168823, train_loss: 0.012721509672701359\n",
            "27730 val_loss: 0.23043294250965118, train_loss: 0.012451893649995327\n",
            "27740 val_loss: 0.2537705898284912, train_loss: 0.013712501153349876\n",
            "27750 val_loss: 0.2337428778409958, train_loss: 0.012200374156236649\n",
            "27760 val_loss: 0.2302638441324234, train_loss: 0.012519718147814274\n",
            "27770 val_loss: 0.21084143221378326, train_loss: 0.013225558213889599\n",
            "27780 val_loss: 0.22436723113059998, train_loss: 0.012559172697365284\n",
            "27790 val_loss: 0.2183440923690796, train_loss: 0.012592076323926449\n",
            "27800 val_loss: 0.21269281208515167, train_loss: 0.013392689637839794\n",
            "27810 val_loss: 0.26558011770248413, train_loss: 0.03513071686029434\n",
            "27820 val_loss: 0.21051618456840515, train_loss: 0.013293664902448654\n",
            "27830 val_loss: 0.24510374665260315, train_loss: 0.013477945700287819\n",
            "27840 val_loss: 0.23898783326148987, train_loss: 0.012859996408224106\n",
            "27850 val_loss: 0.21824459731578827, train_loss: 0.012815750204026699\n",
            "27860 val_loss: 0.22282512485980988, train_loss: 0.012454588897526264\n",
            "27870 val_loss: 0.2425643354654312, train_loss: 0.012381299398839474\n",
            "27880 val_loss: 0.225981205701828, train_loss: 0.012319551780819893\n",
            "27890 val_loss: 0.22064195573329926, train_loss: 0.012445383705198765\n",
            "27900 val_loss: 0.2150038778781891, train_loss: 0.014019639231264591\n",
            "27910 val_loss: 0.2250925451517105, train_loss: 0.012659684754908085\n",
            "27920 val_loss: 0.23803052306175232, train_loss: 0.012510388158261776\n",
            "27930 val_loss: 0.23497937619686127, train_loss: 0.012762144207954407\n",
            "27940 val_loss: 0.23133723437786102, train_loss: 0.012192904949188232\n",
            "27950 val_loss: 0.22559583187103271, train_loss: 0.013044898398220539\n",
            "27960 val_loss: 0.22288577258586884, train_loss: 0.01238718070089817\n",
            "27970 val_loss: 0.25206103920936584, train_loss: 0.012986655347049236\n",
            "27980 val_loss: 0.31555020809173584, train_loss: 0.024179378524422646\n",
            "27990 val_loss: 0.23264732956886292, train_loss: 0.012137483805418015\n",
            "28000 val_loss: 0.22814281284809113, train_loss: 0.012039225548505783\n",
            "28010 val_loss: 0.2498319000005722, train_loss: 0.01203135121613741\n",
            "28020 val_loss: 0.2406889796257019, train_loss: 0.011697950772941113\n",
            "28030 val_loss: 0.23102881014347076, train_loss: 0.01177133247256279\n",
            "28040 val_loss: 0.23141878843307495, train_loss: 0.01143797766417265\n",
            "28050 val_loss: 0.23792873322963715, train_loss: 0.012352562509477139\n",
            "28060 val_loss: 0.2315365970134735, train_loss: 0.011959913186728954\n",
            "28070 val_loss: 0.2691308856010437, train_loss: 0.01470732782036066\n",
            "28080 val_loss: 0.21696966886520386, train_loss: 0.012149992398917675\n",
            "28090 val_loss: 0.22240452468395233, train_loss: 0.012104627676308155\n",
            "28100 val_loss: 0.23492561280727386, train_loss: 0.01231774128973484\n",
            "28110 val_loss: 0.23786185681819916, train_loss: 0.01184060052037239\n",
            "28120 val_loss: 0.2290363609790802, train_loss: 0.01165003888309002\n",
            "28130 val_loss: 0.22595006227493286, train_loss: 0.011774358339607716\n",
            "28140 val_loss: 0.2295549511909485, train_loss: 0.011453955434262753\n",
            "28150 val_loss: 0.2424173653125763, train_loss: 0.01138395071029663\n",
            "28160 val_loss: 0.2312314659357071, train_loss: 0.010915450751781464\n",
            "28170 val_loss: 0.21300871670246124, train_loss: 0.012124991044402122\n",
            "28180 val_loss: 0.2330217808485031, train_loss: 0.011681471951305866\n",
            "28190 val_loss: 0.272929847240448, train_loss: 0.014866403304040432\n",
            "28200 val_loss: 0.22918687760829926, train_loss: 0.012341836467385292\n",
            "28210 val_loss: 0.24516171216964722, train_loss: 0.012032616883516312\n",
            "28220 val_loss: 0.21782003343105316, train_loss: 0.012494302354753017\n",
            "28230 val_loss: 0.22182834148406982, train_loss: 0.011694403365254402\n",
            "28240 val_loss: 0.2209324836730957, train_loss: 0.011412183754146099\n",
            "28250 val_loss: 0.2474326640367508, train_loss: 0.013325178064405918\n",
            "28260 val_loss: 0.2848801910877228, train_loss: 0.01726456731557846\n",
            "28270 val_loss: 0.23452556133270264, train_loss: 0.011291095986962318\n",
            "28280 val_loss: 0.2388860136270523, train_loss: 0.011202426627278328\n",
            "28290 val_loss: 0.2367415875196457, train_loss: 0.011927890591323376\n",
            "28300 val_loss: 0.2726128399372101, train_loss: 0.014803217723965645\n",
            "28310 val_loss: 0.22657477855682373, train_loss: 0.011541665531694889\n",
            "28320 val_loss: 0.22378171980381012, train_loss: 0.0111411577090621\n",
            "28330 val_loss: 0.21839193999767303, train_loss: 0.012112092226743698\n",
            "28340 val_loss: 0.2125789076089859, train_loss: 0.011767427437007427\n",
            "28350 val_loss: 0.22886522114276886, train_loss: 0.011242922395467758\n",
            "28360 val_loss: 0.2575176954269409, train_loss: 0.012097405269742012\n",
            "28370 val_loss: 0.277621328830719, train_loss: 0.013901308178901672\n",
            "28380 val_loss: 0.2566981315612793, train_loss: 0.012245137244462967\n",
            "28390 val_loss: 0.22793669998645782, train_loss: 0.011430731043219566\n",
            "28400 val_loss: 0.2435939908027649, train_loss: 0.01107021514326334\n",
            "28410 val_loss: 0.21703092753887177, train_loss: 0.011700182221829891\n",
            "28420 val_loss: 0.23861998319625854, train_loss: 0.011068522930145264\n",
            "28430 val_loss: 0.2271949052810669, train_loss: 0.012904591858386993\n",
            "28440 val_loss: 0.23527638614177704, train_loss: 0.010847143828868866\n",
            "28450 val_loss: 0.24905672669410706, train_loss: 0.011049481108784676\n",
            "28460 val_loss: 0.23256492614746094, train_loss: 0.01100879069417715\n",
            "28470 val_loss: 0.2267041951417923, train_loss: 0.01257546991109848\n",
            "28480 val_loss: 0.20821787416934967, train_loss: 0.012243661098182201\n",
            "28490 val_loss: 0.22707822918891907, train_loss: 0.011933032423257828\n",
            "28500 val_loss: 0.24803873896598816, train_loss: 0.0200728140771389\n",
            "28510 val_loss: 0.2306261956691742, train_loss: 0.010965016670525074\n",
            "28520 val_loss: 0.2387680560350418, train_loss: 0.010608358308672905\n",
            "28530 val_loss: 0.24822062253952026, train_loss: 0.010873934254050255\n",
            "28540 val_loss: 0.22816337645053864, train_loss: 0.010935704223811626\n",
            "28550 val_loss: 0.2524563670158386, train_loss: 0.01140599139034748\n",
            "28560 val_loss: 0.24221697449684143, train_loss: 0.010582350194454193\n",
            "28570 val_loss: 0.24582229554653168, train_loss: 0.010797142051160336\n",
            "28580 val_loss: 0.2685289680957794, train_loss: 0.01301092840731144\n",
            "28590 val_loss: 0.21307232975959778, train_loss: 0.013056445866823196\n",
            "28600 val_loss: 0.2292402982711792, train_loss: 0.01052796095609665\n",
            "28610 val_loss: 0.20724643766880035, train_loss: 0.012877099215984344\n",
            "28620 val_loss: 0.227020263671875, train_loss: 0.010702773928642273\n",
            "28630 val_loss: 0.23429657518863678, train_loss: 0.010918895713984966\n",
            "28640 val_loss: 0.24679119884967804, train_loss: 0.011051674373447895\n",
            "28650 val_loss: 0.24747908115386963, train_loss: 0.015527307987213135\n",
            "28660 val_loss: 0.2399703711271286, train_loss: 0.010139618068933487\n",
            "28670 val_loss: 0.21640102565288544, train_loss: 0.011845664121210575\n",
            "28680 val_loss: 0.29266512393951416, train_loss: 0.018545014783740044\n",
            "28690 val_loss: 0.2492104470729828, train_loss: 0.013259805738925934\n",
            "28700 val_loss: 0.23290082812309265, train_loss: 0.010785330086946487\n",
            "28710 val_loss: 0.23037150502204895, train_loss: 0.011426329612731934\n",
            "28720 val_loss: 0.23164212703704834, train_loss: 0.010622023604810238\n",
            "28730 val_loss: 0.2685673236846924, train_loss: 0.01276068389415741\n",
            "28740 val_loss: 0.25902819633483887, train_loss: 0.010716363787651062\n",
            "28750 val_loss: 0.23123450577259064, train_loss: 0.010973824188113213\n",
            "28760 val_loss: 0.23426668345928192, train_loss: 0.010498417541384697\n",
            "28770 val_loss: 0.2102053314447403, train_loss: 0.01255760621279478\n",
            "28780 val_loss: 0.22855360805988312, train_loss: 0.010884121060371399\n",
            "28790 val_loss: 0.23294119536876678, train_loss: 0.010900513269007206\n",
            "28800 val_loss: 0.23764941096305847, train_loss: 0.014363733120262623\n",
            "28810 val_loss: 0.22227434813976288, train_loss: 0.011459589935839176\n",
            "28820 val_loss: 0.2557850778102875, train_loss: 0.011330756358802319\n",
            "28830 val_loss: 0.22514434158802032, train_loss: 0.01056901179254055\n",
            "28840 val_loss: 0.22087067365646362, train_loss: 0.01077637542039156\n",
            "28850 val_loss: 0.2339569330215454, train_loss: 0.011034933850169182\n",
            "28860 val_loss: 0.2304719239473343, train_loss: 0.01066894456744194\n",
            "28870 val_loss: 0.25980430841445923, train_loss: 0.01073646079748869\n",
            "28880 val_loss: 0.2600862979888916, train_loss: 0.018275389447808266\n",
            "28890 val_loss: 0.24491332471370697, train_loss: 0.010519037023186684\n",
            "28900 val_loss: 0.21605482697486877, train_loss: 0.014731104485690594\n",
            "28910 val_loss: 0.22139489650726318, train_loss: 0.01082500908523798\n",
            "28920 val_loss: 0.2242399901151657, train_loss: 0.01020327303558588\n",
            "28930 val_loss: 0.23701061308383942, train_loss: 0.009792853146791458\n",
            "28940 val_loss: 0.24000249803066254, train_loss: 0.010445889085531235\n",
            "28950 val_loss: 0.2194693386554718, train_loss: 0.010566020384430885\n",
            "28960 val_loss: 0.2397557944059372, train_loss: 0.010238151997327805\n",
            "28970 val_loss: 0.21875599026679993, train_loss: 0.010842787101864815\n",
            "28980 val_loss: 0.24003002047538757, train_loss: 0.010225275531411171\n",
            "28990 val_loss: 0.22164347767829895, train_loss: 0.010994039475917816\n",
            "29000 val_loss: 0.27049964666366577, train_loss: 0.010731065645813942\n",
            "29010 val_loss: 0.23902460932731628, train_loss: 0.010852408595383167\n",
            "29020 val_loss: 0.22817246615886688, train_loss: 0.010829528793692589\n",
            "29030 val_loss: 0.22877785563468933, train_loss: 0.012430730275809765\n",
            "29040 val_loss: 0.22335679829120636, train_loss: 0.011489832773804665\n",
            "29050 val_loss: 0.24498093128204346, train_loss: 0.010526315309107304\n",
            "29060 val_loss: 0.22686295211315155, train_loss: 0.010847628116607666\n",
            "29070 val_loss: 0.2340368926525116, train_loss: 0.010894023813307285\n",
            "29080 val_loss: 0.22030313313007355, train_loss: 0.010863988660275936\n",
            "29090 val_loss: 0.2224200963973999, train_loss: 0.011448542587459087\n",
            "29100 val_loss: 0.2871672213077545, train_loss: 0.01462002843618393\n",
            "29110 val_loss: 0.24426975846290588, train_loss: 0.009971551597118378\n",
            "29120 val_loss: 0.24960145354270935, train_loss: 0.010603642091155052\n",
            "29130 val_loss: 0.23949700593948364, train_loss: 0.010318471118807793\n",
            "29140 val_loss: 0.24646517634391785, train_loss: 0.010202134028077126\n",
            "29150 val_loss: 0.25185561180114746, train_loss: 0.010046129114925861\n",
            "29160 val_loss: 0.24781906604766846, train_loss: 0.010341929271817207\n",
            "29170 val_loss: 0.22291772067546844, train_loss: 0.010496547445654869\n",
            "29180 val_loss: 0.23655271530151367, train_loss: 0.010517517104744911\n",
            "29190 val_loss: 0.24451997876167297, train_loss: 0.010123729705810547\n",
            "29200 val_loss: 0.2232198417186737, train_loss: 0.01133076474070549\n",
            "29210 val_loss: 0.23306266963481903, train_loss: 0.009900638833642006\n",
            "29220 val_loss: 0.21526458859443665, train_loss: 0.017117295414209366\n",
            "29230 val_loss: 0.2273484617471695, train_loss: 0.00972025841474533\n",
            "29240 val_loss: 0.24199816584587097, train_loss: 0.009658939205110073\n",
            "29250 val_loss: 0.24564611911773682, train_loss: 0.009608482010662556\n",
            "29260 val_loss: 0.2276746928691864, train_loss: 0.009767199866473675\n",
            "29270 val_loss: 0.2423621565103531, train_loss: 0.010096294805407524\n",
            "29280 val_loss: 0.23419959843158722, train_loss: 0.010399388149380684\n",
            "29290 val_loss: 0.2302493304014206, train_loss: 0.009922133758664131\n",
            "29300 val_loss: 0.22067010402679443, train_loss: 0.010523024946451187\n",
            "29310 val_loss: 0.2311485856771469, train_loss: 0.009927643463015556\n",
            "29320 val_loss: 0.24771711230278015, train_loss: 0.009546620771288872\n",
            "29330 val_loss: 0.24540381133556366, train_loss: 0.00969813484698534\n",
            "29340 val_loss: 0.23282583057880402, train_loss: 0.009728056378662586\n",
            "29350 val_loss: 0.23193620145320892, train_loss: 0.01069997251033783\n",
            "29360 val_loss: 0.2037467062473297, train_loss: 0.011890820227563381\n",
            "29370 val_loss: 0.267899751663208, train_loss: 0.010884587652981281\n",
            "29380 val_loss: 0.24794553220272064, train_loss: 0.00957249104976654\n",
            "29390 val_loss: 0.22214005887508392, train_loss: 0.010240701027214527\n",
            "29400 val_loss: 0.27213048934936523, train_loss: 0.011379700154066086\n",
            "29410 val_loss: 0.30094894766807556, train_loss: 0.014958533458411694\n",
            "29420 val_loss: 0.23176920413970947, train_loss: 0.009862948209047318\n",
            "29430 val_loss: 0.255874902009964, train_loss: 0.010572354309260845\n",
            "29440 val_loss: 0.19787223637104034, train_loss: 0.017229415476322174\n",
            "29450 val_loss: 0.22432944178581238, train_loss: 0.010500877164304256\n",
            "29460 val_loss: 0.22026236355304718, train_loss: 0.012782974168658257\n",
            "29470 val_loss: 0.2557641565799713, train_loss: 0.009746313095092773\n",
            "29480 val_loss: 0.24229969084262848, train_loss: 0.00977511890232563\n",
            "29490 val_loss: 0.24524956941604614, train_loss: 0.012785717844963074\n",
            "29500 val_loss: 0.24008780717849731, train_loss: 0.009774303995072842\n",
            "29510 val_loss: 0.24683141708374023, train_loss: 0.009677295573055744\n",
            "29520 val_loss: 0.2296401411294937, train_loss: 0.0097264489158988\n",
            "29530 val_loss: 0.23095101118087769, train_loss: 0.010743411257863045\n",
            "29540 val_loss: 0.24773654341697693, train_loss: 0.010171451605856419\n",
            "29550 val_loss: 0.22578957676887512, train_loss: 0.010776519775390625\n",
            "29560 val_loss: 0.23683500289916992, train_loss: 0.009318542666733265\n",
            "29570 val_loss: 0.24369503557682037, train_loss: 0.009082329459488392\n",
            "29580 val_loss: 0.2758638560771942, train_loss: 0.0110629228875041\n",
            "29590 val_loss: 0.2533920407295227, train_loss: 0.009264301508665085\n",
            "29600 val_loss: 0.24476473033428192, train_loss: 0.008876758627593517\n",
            "29610 val_loss: 0.2888515889644623, train_loss: 0.011814668774604797\n",
            "29620 val_loss: 0.23187005519866943, train_loss: 0.009142397902905941\n",
            "29630 val_loss: 0.2378050535917282, train_loss: 0.008989879861474037\n",
            "29640 val_loss: 0.2582130432128906, train_loss: 0.011039922013878822\n",
            "29650 val_loss: 0.22413994371891022, train_loss: 0.011124709621071815\n",
            "29660 val_loss: 0.25136759877204895, train_loss: 0.008857486769557\n",
            "29670 val_loss: 0.21605932712554932, train_loss: 0.015387927182018757\n",
            "29680 val_loss: 0.21743175387382507, train_loss: 0.011670288629829884\n",
            "29690 val_loss: 0.25092798471450806, train_loss: 0.009303693659603596\n",
            "29700 val_loss: 0.23484274744987488, train_loss: 0.010216963477432728\n",
            "29710 val_loss: 0.27450740337371826, train_loss: 0.010921485722064972\n",
            "29720 val_loss: 0.24531494081020355, train_loss: 0.009355311281979084\n",
            "29730 val_loss: 0.24134951829910278, train_loss: 0.011443959549069405\n",
            "29740 val_loss: 0.23255109786987305, train_loss: 0.00961670558899641\n",
            "29750 val_loss: 0.2518327832221985, train_loss: 0.010923895053565502\n",
            "29760 val_loss: 0.22228999435901642, train_loss: 0.011743378825485706\n",
            "29770 val_loss: 0.23606325685977936, train_loss: 0.008858852088451385\n",
            "29780 val_loss: 0.2758174538612366, train_loss: 0.010553386993706226\n",
            "29790 val_loss: 0.2524035573005676, train_loss: 0.009293178096413612\n",
            "29800 val_loss: 0.22279274463653564, train_loss: 0.009684927761554718\n",
            "29810 val_loss: 0.3088316321372986, train_loss: 0.015762044116854668\n",
            "29820 val_loss: 0.2520998418331146, train_loss: 0.009766693226993084\n",
            "29830 val_loss: 0.24014294147491455, train_loss: 0.009336805902421474\n",
            "29840 val_loss: 0.24977275729179382, train_loss: 0.009179157204926014\n",
            "29850 val_loss: 0.23321016132831573, train_loss: 0.009191461838781834\n",
            "29860 val_loss: 0.24748174846172333, train_loss: 0.009481276385486126\n",
            "29870 val_loss: 0.24013306200504303, train_loss: 0.009304395876824856\n",
            "29880 val_loss: 0.23138944804668427, train_loss: 0.012389901094138622\n",
            "29890 val_loss: 0.29898056387901306, train_loss: 0.016582269221544266\n",
            "29900 val_loss: 0.2532714307308197, train_loss: 0.010500321164727211\n",
            "29910 val_loss: 0.2679082453250885, train_loss: 0.009162526577711105\n",
            "29920 val_loss: 0.2416381537914276, train_loss: 0.008771353401243687\n",
            "29930 val_loss: 0.25057750940322876, train_loss: 0.008856570348143578\n",
            "29940 val_loss: 0.24346381425857544, train_loss: 0.00928608886897564\n",
            "29950 val_loss: 0.24591697752475739, train_loss: 0.009419267065823078\n",
            "29960 val_loss: 0.238388791680336, train_loss: 0.009492265060544014\n",
            "29970 val_loss: 0.24518544971942902, train_loss: 0.009407139383256435\n",
            "29980 val_loss: 0.2347259521484375, train_loss: 0.00936158373951912\n",
            "29990 val_loss: 0.27214446663856506, train_loss: 0.011414576321840286\n",
            "30000 val_loss: 0.2510608434677124, train_loss: 0.010066637769341469\n",
            "30010 val_loss: 0.21806158125400543, train_loss: 0.011764425784349442\n",
            "30020 val_loss: 0.2461165189743042, train_loss: 0.00962187722325325\n",
            "30030 val_loss: 0.22238394618034363, train_loss: 0.013180973939597607\n",
            "30040 val_loss: 0.30455803871154785, train_loss: 0.02730504423379898\n",
            "30050 val_loss: 0.24326397478580475, train_loss: 0.009748775511980057\n",
            "30060 val_loss: 0.21806730329990387, train_loss: 0.011129569262266159\n",
            "30070 val_loss: 0.2409258633852005, train_loss: 0.009289015084505081\n",
            "30080 val_loss: 0.2426150143146515, train_loss: 0.009251128882169724\n",
            "30090 val_loss: 0.23382915556430817, train_loss: 0.009911647066473961\n",
            "30100 val_loss: 0.28033727407455444, train_loss: 0.011344516649842262\n",
            "30110 val_loss: 0.28473201394081116, train_loss: 0.01168469712138176\n",
            "30120 val_loss: 0.2355005145072937, train_loss: 0.009208885952830315\n",
            "30130 val_loss: 0.23381328582763672, train_loss: 0.009127458557486534\n",
            "30140 val_loss: 0.25648239254951477, train_loss: 0.008839567191898823\n",
            "30150 val_loss: 0.27010616660118103, train_loss: 0.00983313750475645\n",
            "30160 val_loss: 0.24783915281295776, train_loss: 0.00870163831859827\n",
            "30170 val_loss: 0.27959924936294556, train_loss: 0.010362508706748486\n",
            "30180 val_loss: 0.23994702100753784, train_loss: 0.00884298700839281\n",
            "30190 val_loss: 0.2600554823875427, train_loss: 0.008657367900013924\n",
            "30200 val_loss: 0.23795145750045776, train_loss: 0.008809714578092098\n",
            "30210 val_loss: 0.2478816658258438, train_loss: 0.008560770191252232\n",
            "30220 val_loss: 0.24231764674186707, train_loss: 0.008562484756112099\n",
            "30230 val_loss: 0.23291327059268951, train_loss: 0.008840617723762989\n",
            "30240 val_loss: 0.23203346133232117, train_loss: 0.009110520593822002\n",
            "30250 val_loss: 0.25689181685447693, train_loss: 0.009011720307171345\n",
            "30260 val_loss: 0.2595231533050537, train_loss: 0.009101909585297108\n",
            "30270 val_loss: 0.2562388777732849, train_loss: 0.009761380031704903\n",
            "30280 val_loss: 0.23796240985393524, train_loss: 0.008833665400743484\n",
            "30290 val_loss: 0.22536148130893707, train_loss: 0.010576469823718071\n",
            "30300 val_loss: 0.22561128437519073, train_loss: 0.009896391071379185\n",
            "30310 val_loss: 0.2310410439968109, train_loss: 0.010250194929540157\n",
            "30320 val_loss: 0.26134321093559265, train_loss: 0.009169629774987698\n",
            "30330 val_loss: 0.25031787157058716, train_loss: 0.00894994754344225\n",
            "30340 val_loss: 0.26006054878234863, train_loss: 0.008710441179573536\n",
            "30350 val_loss: 0.27316948771476746, train_loss: 0.00860760547220707\n",
            "30360 val_loss: 0.24235175549983978, train_loss: 0.011111446656286716\n",
            "30370 val_loss: 0.25821489095687866, train_loss: 0.008803154341876507\n",
            "30380 val_loss: 0.25736549496650696, train_loss: 0.008506924845278263\n",
            "30390 val_loss: 0.2608080506324768, train_loss: 0.008445925079286098\n",
            "30400 val_loss: 0.2553929090499878, train_loss: 0.008416838012635708\n",
            "30410 val_loss: 0.2539188265800476, train_loss: 0.008166324347257614\n",
            "30420 val_loss: 0.26774317026138306, train_loss: 0.007988556288182735\n",
            "30430 val_loss: 0.261547327041626, train_loss: 0.007968849502503872\n",
            "30440 val_loss: 0.24772284924983978, train_loss: 0.008327211253345013\n",
            "30450 val_loss: 0.23255547881126404, train_loss: 0.00889659021049738\n",
            "30460 val_loss: 0.25092044472694397, train_loss: 0.008516773581504822\n",
            "30470 val_loss: 0.25080618262290955, train_loss: 0.00854737963527441\n",
            "30480 val_loss: 0.22150377929210663, train_loss: 0.011563470587134361\n",
            "30490 val_loss: 0.2324761152267456, train_loss: 0.010652830824255943\n",
            "30500 val_loss: 0.2488739788532257, train_loss: 0.008462873287498951\n",
            "30510 val_loss: 0.2697417736053467, train_loss: 0.012116099707782269\n",
            "30520 val_loss: 0.2604775130748749, train_loss: 0.014279329217970371\n",
            "30530 val_loss: 0.2523542642593384, train_loss: 0.00826401636004448\n",
            "30540 val_loss: 0.3166120946407318, train_loss: 0.013358003459870815\n",
            "30550 val_loss: 0.2785983681678772, train_loss: 0.01009629387408495\n",
            "30560 val_loss: 0.238692969083786, train_loss: 0.008259083144366741\n",
            "30570 val_loss: 0.2547359764575958, train_loss: 0.008169776760041714\n",
            "30580 val_loss: 0.24638618528842926, train_loss: 0.010667048394680023\n",
            "30590 val_loss: 0.2537093460559845, train_loss: 0.008210540749132633\n",
            "30600 val_loss: 0.2566460967063904, train_loss: 0.008101353421807289\n",
            "30610 val_loss: 0.25471732020378113, train_loss: 0.008171341381967068\n",
            "30620 val_loss: 0.2528061866760254, train_loss: 0.008482949808239937\n",
            "30630 val_loss: 0.2682363986968994, train_loss: 0.008274310268461704\n",
            "30640 val_loss: 0.25288155674934387, train_loss: 0.008222207427024841\n",
            "30650 val_loss: 0.30077680945396423, train_loss: 0.010538562200963497\n",
            "30660 val_loss: 0.2583305239677429, train_loss: 0.008004918694496155\n",
            "30670 val_loss: 0.25490206480026245, train_loss: 0.00814972072839737\n",
            "30680 val_loss: 0.24037525057792664, train_loss: 0.00963215809315443\n",
            "30690 val_loss: 0.7018212080001831, train_loss: 0.2762119472026825\n",
            "30700 val_loss: 0.2232339233160019, train_loss: 0.02423989027738571\n",
            "30710 val_loss: 0.22448471188545227, train_loss: 0.017784830182790756\n",
            "30720 val_loss: 0.23018348217010498, train_loss: 0.014787749387323856\n",
            "30730 val_loss: 0.2529013156890869, train_loss: 0.013260889798402786\n",
            "30740 val_loss: 0.2931622266769409, train_loss: 0.017988331615924835\n",
            "30750 val_loss: 0.23787017166614532, train_loss: 0.01131187379360199\n",
            "30760 val_loss: 0.2288559228181839, train_loss: 0.011263357475399971\n",
            "30770 val_loss: 0.24548925459384918, train_loss: 0.010285585187375546\n",
            "30780 val_loss: 0.22677256166934967, train_loss: 0.011403611861169338\n",
            "30790 val_loss: 0.2321101576089859, train_loss: 0.010414189659059048\n",
            "30800 val_loss: 0.24033528566360474, train_loss: 0.009433843195438385\n",
            "30810 val_loss: 0.26284459233283997, train_loss: 0.009430890902876854\n",
            "30820 val_loss: 0.2650756239891052, train_loss: 0.009265431202948093\n",
            "30830 val_loss: 0.2495153695344925, train_loss: 0.008830944076180458\n",
            "30840 val_loss: 0.226283997297287, train_loss: 0.009925884194672108\n",
            "30850 val_loss: 0.2650454044342041, train_loss: 0.008767466992139816\n",
            "30860 val_loss: 0.26708704233169556, train_loss: 0.009502640925347805\n",
            "30870 val_loss: 0.27512016892433167, train_loss: 0.009829983115196228\n",
            "30880 val_loss: 0.24149495363235474, train_loss: 0.008507389575242996\n",
            "30890 val_loss: 0.22955390810966492, train_loss: 0.009907018393278122\n",
            "30900 val_loss: 0.2521820664405823, train_loss: 0.008195659145712852\n",
            "30910 val_loss: 0.3366684317588806, train_loss: 0.018553495407104492\n",
            "30920 val_loss: 0.2413671314716339, train_loss: 0.009352297522127628\n",
            "30930 val_loss: 0.27578550577163696, train_loss: 0.009132028557360172\n",
            "30940 val_loss: 0.24081920087337494, train_loss: 0.008807332254946232\n",
            "30950 val_loss: 0.27438509464263916, train_loss: 0.00854264385998249\n",
            "30960 val_loss: 0.2607818841934204, train_loss: 0.008024202659726143\n",
            "30970 val_loss: 0.27054905891418457, train_loss: 0.009029317647218704\n",
            "30980 val_loss: 0.25636887550354004, train_loss: 0.008388670161366463\n",
            "30990 val_loss: 0.25498390197753906, train_loss: 0.00793798640370369\n",
            "31000 val_loss: 0.1857825368642807, train_loss: 0.0167851485311985\n",
            "31010 val_loss: 0.2548149526119232, train_loss: 0.008274792693555355\n",
            "31020 val_loss: 0.22956807911396027, train_loss: 0.010044724680483341\n",
            "31030 val_loss: 0.27540209889411926, train_loss: 0.009384212084114552\n",
            "31040 val_loss: 0.25231051445007324, train_loss: 0.008248716592788696\n",
            "31050 val_loss: 0.24907882511615753, train_loss: 0.008679240942001343\n",
            "31060 val_loss: 0.2613019347190857, train_loss: 0.008904808200895786\n",
            "31070 val_loss: 0.2434067279100418, train_loss: 0.012330731377005577\n",
            "31080 val_loss: 0.2770443856716156, train_loss: 0.009124331176280975\n",
            "31090 val_loss: 0.2633213400840759, train_loss: 0.008142601698637009\n",
            "31100 val_loss: 0.25437408685684204, train_loss: 0.008841302245855331\n",
            "31110 val_loss: 0.23907332122325897, train_loss: 0.009043593890964985\n",
            "31120 val_loss: 0.25069350004196167, train_loss: 0.008420707657933235\n",
            "31130 val_loss: 0.26218828558921814, train_loss: 0.008513872511684895\n",
            "31140 val_loss: 0.23607929050922394, train_loss: 0.010711376555263996\n",
            "31150 val_loss: 0.3098161816596985, train_loss: 0.011684266850352287\n",
            "31160 val_loss: 0.2776695489883423, train_loss: 0.008779737167060375\n",
            "31170 val_loss: 0.24413681030273438, train_loss: 0.01003129594027996\n",
            "31180 val_loss: 0.2507445514202118, train_loss: 0.008253267034888268\n",
            "31190 val_loss: 0.2748676836490631, train_loss: 0.00855624582618475\n",
            "31200 val_loss: 0.25530296564102173, train_loss: 0.010545896366238594\n",
            "31210 val_loss: 0.25194448232650757, train_loss: 0.007866514846682549\n",
            "31220 val_loss: 0.26857563853263855, train_loss: 0.010412024334073067\n",
            "31230 val_loss: 0.25527510046958923, train_loss: 0.008609835989773273\n",
            "31240 val_loss: 0.2808510661125183, train_loss: 0.008677463978528976\n",
            "31250 val_loss: 0.25864139199256897, train_loss: 0.012724430300295353\n",
            "31260 val_loss: 0.26616576313972473, train_loss: 0.008353677578270435\n",
            "31270 val_loss: 0.23371751606464386, train_loss: 0.009549480862915516\n",
            "31280 val_loss: 0.223049595952034, train_loss: 0.010268875397741795\n",
            "31290 val_loss: 0.2892884314060211, train_loss: 0.009397446177899837\n",
            "31300 val_loss: 0.24363282322883606, train_loss: 0.008683541789650917\n",
            "31310 val_loss: 0.259095162153244, train_loss: 0.010206986218690872\n",
            "31320 val_loss: 0.2688145339488983, train_loss: 0.008041173219680786\n",
            "31330 val_loss: 0.2668517827987671, train_loss: 0.007811549585312605\n",
            "31340 val_loss: 0.2586411237716675, train_loss: 0.007466559298336506\n",
            "31350 val_loss: 0.26256003975868225, train_loss: 0.007591500412672758\n",
            "31360 val_loss: 0.3095398545265198, train_loss: 0.01203180942684412\n",
            "31370 val_loss: 0.2597624659538269, train_loss: 0.00801168754696846\n",
            "31380 val_loss: 0.30173078179359436, train_loss: 0.010161550715565681\n",
            "31390 val_loss: 0.2722710072994232, train_loss: 0.007753569167107344\n",
            "31400 val_loss: 0.25945302844047546, train_loss: 0.00728938914835453\n",
            "31410 val_loss: 0.25562161207199097, train_loss: 0.007340054959058762\n",
            "31420 val_loss: 0.2554900050163269, train_loss: 0.019273249432444572\n",
            "31430 val_loss: 0.26048532128334045, train_loss: 0.007986634038388729\n",
            "31440 val_loss: 0.23298379778862, train_loss: 0.009453088976442814\n",
            "31450 val_loss: 0.24555669724941254, train_loss: 0.008172838017344475\n",
            "31460 val_loss: 0.327345609664917, train_loss: 0.01374431699514389\n",
            "31470 val_loss: 0.23604826629161835, train_loss: 0.009331602603197098\n",
            "31480 val_loss: 0.254650741815567, train_loss: 0.007577530108392239\n",
            "31490 val_loss: 0.2358606904745102, train_loss: 0.009100408293306828\n",
            "31500 val_loss: 0.23937200009822845, train_loss: 0.010103308595716953\n",
            "31510 val_loss: 0.24599698185920715, train_loss: 0.007738852873444557\n",
            "31520 val_loss: 0.290484756231308, train_loss: 0.00852498970925808\n",
            "31530 val_loss: 0.23501865565776825, train_loss: 0.009363695979118347\n",
            "31540 val_loss: 0.2659006714820862, train_loss: 0.007221375126391649\n",
            "31550 val_loss: 0.23008008301258087, train_loss: 0.009699128568172455\n",
            "31560 val_loss: 0.321510374546051, train_loss: 0.011713636107742786\n",
            "31570 val_loss: 0.2542053759098053, train_loss: 0.0073544615879654884\n",
            "31580 val_loss: 0.27385640144348145, train_loss: 0.006989184767007828\n",
            "31590 val_loss: 0.27067163586616516, train_loss: 0.007047416642308235\n",
            "31600 val_loss: 0.25347205996513367, train_loss: 0.007917627692222595\n",
            "31610 val_loss: 0.33990713953971863, train_loss: 0.012910863384604454\n",
            "31620 val_loss: 0.25681060552597046, train_loss: 0.015866270288825035\n",
            "31630 val_loss: 0.20728826522827148, train_loss: 0.014793317764997482\n",
            "31640 val_loss: 0.26419028639793396, train_loss: 0.011886294931173325\n",
            "31650 val_loss: 0.23295919597148895, train_loss: 0.009814254939556122\n",
            "31660 val_loss: 0.25803977251052856, train_loss: 0.009247374720871449\n",
            "31670 val_loss: 0.23980596661567688, train_loss: 0.008612770587205887\n",
            "31680 val_loss: 0.25850406289100647, train_loss: 0.00796081218868494\n",
            "31690 val_loss: 0.2652260661125183, train_loss: 0.007914558053016663\n",
            "31700 val_loss: 0.25437355041503906, train_loss: 0.0076017738319933414\n",
            "31710 val_loss: 0.26359984278678894, train_loss: 0.012399486266076565\n",
            "31720 val_loss: 0.23166261613368988, train_loss: 0.010512673296034336\n",
            "31730 val_loss: 0.2611370086669922, train_loss: 0.007159504573792219\n",
            "31740 val_loss: 0.31897881627082825, train_loss: 0.01090668048709631\n",
            "31750 val_loss: 0.25539684295654297, train_loss: 0.016000239178538322\n",
            "31760 val_loss: 0.25117284059524536, train_loss: 0.007373610977083445\n",
            "31770 val_loss: 0.24845202267169952, train_loss: 0.007477476727217436\n",
            "31780 val_loss: 0.2601344883441925, train_loss: 0.009213864803314209\n",
            "31790 val_loss: 0.253974974155426, train_loss: 0.008683930151164532\n",
            "31800 val_loss: 0.26551535725593567, train_loss: 0.007106487639248371\n",
            "31810 val_loss: 0.2707594335079193, train_loss: 0.00736708240583539\n",
            "31820 val_loss: 0.2745923697948456, train_loss: 0.007216249592602253\n",
            "31830 val_loss: 0.3181055188179016, train_loss: 0.045557256788015366\n",
            "31840 val_loss: 0.27340763807296753, train_loss: 0.007832461968064308\n",
            "31850 val_loss: 0.3487394452095032, train_loss: 0.016956400126218796\n",
            "31860 val_loss: 0.23295895755290985, train_loss: 0.008929808624088764\n",
            "31870 val_loss: 0.2764190137386322, train_loss: 0.007564082276076078\n",
            "31880 val_loss: 0.2793702483177185, train_loss: 0.007823394611477852\n",
            "31890 val_loss: 0.25424447655677795, train_loss: 0.008176039904356003\n",
            "31900 val_loss: 0.27422139048576355, train_loss: 0.007196800317615271\n",
            "31910 val_loss: 0.2965850234031677, train_loss: 0.007908286526799202\n",
            "31920 val_loss: 0.2754940986633301, train_loss: 0.006970697082579136\n",
            "31930 val_loss: 0.24856220185756683, train_loss: 0.007367229554802179\n",
            "31940 val_loss: 0.23896469175815582, train_loss: 0.011441226117312908\n",
            "31950 val_loss: 0.3089165985584259, train_loss: 0.010166430845856667\n",
            "31960 val_loss: 0.25341320037841797, train_loss: 0.007281965110450983\n",
            "31970 val_loss: 0.2804822325706482, train_loss: 0.007053489796817303\n",
            "31980 val_loss: 0.23974072933197021, train_loss: 0.007900483906269073\n",
            "31990 val_loss: 0.3025040924549103, train_loss: 0.009433770552277565\n",
            "32000 val_loss: 0.29967862367630005, train_loss: 0.014174899086356163\n",
            "32010 val_loss: 0.24489766359329224, train_loss: 0.010579224675893784\n",
            "32020 val_loss: 0.2726638615131378, train_loss: 0.007717619650065899\n",
            "32030 val_loss: 0.26105037331581116, train_loss: 0.013091783039271832\n",
            "32040 val_loss: 0.29528453946113586, train_loss: 0.00801603402942419\n",
            "32050 val_loss: 0.27646490931510925, train_loss: 0.007441144436597824\n",
            "32060 val_loss: 0.29733458161354065, train_loss: 0.008243470452725887\n",
            "32070 val_loss: 0.3050060272216797, train_loss: 0.008779468946158886\n",
            "32080 val_loss: 0.25206074118614197, train_loss: 0.0092446468770504\n",
            "32090 val_loss: 0.26964864134788513, train_loss: 0.007878903299570084\n",
            "32100 val_loss: 0.2816082537174225, train_loss: 0.007273394614458084\n",
            "32110 val_loss: 0.28172698616981506, train_loss: 0.007533452473580837\n",
            "32120 val_loss: 0.26805540919303894, train_loss: 0.01106924656778574\n",
            "32130 val_loss: 0.263812392950058, train_loss: 0.008080183528363705\n",
            "32140 val_loss: 0.3249610662460327, train_loss: 0.011068261228501797\n",
            "32150 val_loss: 0.26330405473709106, train_loss: 0.007320871111005545\n",
            "32160 val_loss: 0.2535993754863739, train_loss: 0.007523297797888517\n",
            "32170 val_loss: 0.2588343918323517, train_loss: 0.007411939557641745\n",
            "32180 val_loss: 0.26795050501823425, train_loss: 0.007025720551609993\n",
            "32190 val_loss: 0.2720056176185608, train_loss: 0.007250084541738033\n",
            "32200 val_loss: 0.2663823962211609, train_loss: 0.007530038245022297\n",
            "32210 val_loss: 0.2754151523113251, train_loss: 0.007627583108842373\n",
            "32220 val_loss: 0.26672571897506714, train_loss: 0.007267598994076252\n",
            "32230 val_loss: 0.27156612277030945, train_loss: 0.007252922281622887\n",
            "32240 val_loss: 0.253726601600647, train_loss: 0.007645676378160715\n",
            "32250 val_loss: 0.2690504789352417, train_loss: 0.007059759460389614\n",
            "32260 val_loss: 0.2697761058807373, train_loss: 0.006765370257198811\n",
            "32270 val_loss: 0.2784630060195923, train_loss: 0.006718335207551718\n",
            "32280 val_loss: 0.25044897198677063, train_loss: 0.007145699113607407\n",
            "32290 val_loss: 0.2641794979572296, train_loss: 0.006840934045612812\n",
            "32300 val_loss: 0.26975634694099426, train_loss: 0.0065605309791862965\n",
            "32310 val_loss: 0.29000750184059143, train_loss: 0.0075368559919297695\n",
            "32320 val_loss: 0.23962566256523132, train_loss: 0.007941938936710358\n",
            "32330 val_loss: 0.25458312034606934, train_loss: 0.006620774511247873\n",
            "32340 val_loss: 0.24827273190021515, train_loss: 0.007828408852219582\n",
            "32350 val_loss: 0.2859551012516022, train_loss: 0.006513138301670551\n",
            "32360 val_loss: 0.30071932077407837, train_loss: 0.008027168922126293\n",
            "32370 val_loss: 0.2726746201515198, train_loss: 0.006862673442810774\n",
            "32380 val_loss: 0.2757996916770935, train_loss: 0.006652281153947115\n",
            "32390 val_loss: 0.2855667173862457, train_loss: 0.013159921392798424\n",
            "32400 val_loss: 0.29591432213783264, train_loss: 0.00738692469894886\n",
            "32410 val_loss: 0.3114897310733795, train_loss: 0.008227050304412842\n",
            "32420 val_loss: 0.31709665060043335, train_loss: 0.006515916902571917\n",
            "32430 val_loss: 0.25807738304138184, train_loss: 0.008722090162336826\n",
            "32440 val_loss: 0.27077561616897583, train_loss: 0.013075982220470905\n",
            "32450 val_loss: 0.31491121649742126, train_loss: 0.008731027133762836\n",
            "32460 val_loss: 0.27355465292930603, train_loss: 0.006518618669360876\n",
            "32470 val_loss: 0.2593802213668823, train_loss: 0.007448730990290642\n",
            "32480 val_loss: 0.295553058385849, train_loss: 0.007506879512220621\n",
            "32490 val_loss: 0.2717004418373108, train_loss: 0.006677599158138037\n",
            "32500 val_loss: 0.3087720572948456, train_loss: 0.008338920772075653\n",
            "32510 val_loss: 0.2589951157569885, train_loss: 0.007261286489665508\n",
            "32520 val_loss: 0.27569279074668884, train_loss: 0.006360967643558979\n",
            "32530 val_loss: 0.26432690024375916, train_loss: 0.006990061141550541\n",
            "32540 val_loss: 0.2674436867237091, train_loss: 0.0074691930785775185\n",
            "32550 val_loss: 0.22584211826324463, train_loss: 0.00940782856196165\n",
            "32560 val_loss: 0.2735043168067932, train_loss: 0.007627066690474749\n",
            "32570 val_loss: 0.24560832977294922, train_loss: 0.008383010514080524\n",
            "32580 val_loss: 0.27362799644470215, train_loss: 0.006677709519863129\n",
            "32590 val_loss: 0.2774050831794739, train_loss: 0.0070210956037044525\n",
            "32600 val_loss: 0.32672813534736633, train_loss: 0.011231907643377781\n",
            "32610 val_loss: 0.2590705454349518, train_loss: 0.007106540724635124\n",
            "32620 val_loss: 0.25640246272087097, train_loss: 0.006671225652098656\n",
            "32630 val_loss: 0.29694417119026184, train_loss: 0.008090012706816196\n",
            "32640 val_loss: 0.2564863860607147, train_loss: 0.007026242557913065\n",
            "32650 val_loss: 0.27948248386383057, train_loss: 0.007291956339031458\n",
            "32660 val_loss: 0.27435609698295593, train_loss: 0.006828174460679293\n",
            "32670 val_loss: 0.2656540274620056, train_loss: 0.0065443930216133595\n",
            "32680 val_loss: 0.2869879901409149, train_loss: 0.0071243103593587875\n",
            "32690 val_loss: 0.2732783854007721, train_loss: 0.006410303991287947\n",
            "32700 val_loss: 0.2913980484008789, train_loss: 0.0073089515790343285\n",
            "32710 val_loss: 0.2515496015548706, train_loss: 0.007031498942524195\n",
            "32720 val_loss: 0.2445879876613617, train_loss: 0.01195542048662901\n",
            "32730 val_loss: 0.2878609299659729, train_loss: 0.008507085964083672\n",
            "32740 val_loss: 0.29615432024002075, train_loss: 0.0073450300842523575\n",
            "32750 val_loss: 0.29143834114074707, train_loss: 0.007164348848164082\n",
            "32760 val_loss: 0.3233214020729065, train_loss: 0.04581759497523308\n",
            "32770 val_loss: 0.19017015397548676, train_loss: 0.022071078419685364\n",
            "32780 val_loss: 0.18945704400539398, train_loss: 0.018056241795420647\n",
            "32790 val_loss: 0.20550484955310822, train_loss: 0.016483604907989502\n",
            "32800 val_loss: 0.23596177995204926, train_loss: 0.013988729566335678\n",
            "32810 val_loss: 0.24098852276802063, train_loss: 0.011293251998722553\n",
            "32820 val_loss: 0.2912755012512207, train_loss: 0.012872863560914993\n",
            "32830 val_loss: 0.25781014561653137, train_loss: 0.008956382051110268\n",
            "32840 val_loss: 0.25215810537338257, train_loss: 0.009055464528501034\n",
            "32850 val_loss: 0.26361533999443054, train_loss: 0.008197329938411713\n",
            "32860 val_loss: 0.2458069622516632, train_loss: 0.008530344814062119\n",
            "32870 val_loss: 0.22859351336956024, train_loss: 0.012842691503465176\n",
            "32880 val_loss: 0.27337926626205444, train_loss: 0.007444407325237989\n",
            "32890 val_loss: 0.2567146122455597, train_loss: 0.007876119576394558\n",
            "32900 val_loss: 0.292512983083725, train_loss: 0.015334672294557095\n",
            "32910 val_loss: 0.26916152238845825, train_loss: 0.006981119979172945\n",
            "32920 val_loss: 0.2614386975765228, train_loss: 0.006844718940556049\n",
            "32930 val_loss: 0.32190680503845215, train_loss: 0.010450078174471855\n",
            "32940 val_loss: 0.2660039961338043, train_loss: 0.006491937208920717\n",
            "32950 val_loss: 0.2710219919681549, train_loss: 0.0065797860734164715\n",
            "32960 val_loss: 0.28789767622947693, train_loss: 0.007117091212421656\n",
            "32970 val_loss: 0.27093905210494995, train_loss: 0.006543394178152084\n",
            "32980 val_loss: 0.2787165343761444, train_loss: 0.006495497655123472\n",
            "32990 val_loss: 0.259707510471344, train_loss: 0.009603539481759071\n",
            "33000 val_loss: 0.2576223611831665, train_loss: 0.007148350588977337\n",
            "33010 val_loss: 0.2624596059322357, train_loss: 0.007117611821740866\n",
            "33020 val_loss: 0.24026592075824738, train_loss: 0.008653510361909866\n",
            "33030 val_loss: 0.26092350482940674, train_loss: 0.0068986061960458755\n",
            "33040 val_loss: 0.27166086435317993, train_loss: 0.006689182948321104\n",
            "33050 val_loss: 0.2810150384902954, train_loss: 0.0066727278754115105\n",
            "33060 val_loss: 0.25909653306007385, train_loss: 0.006985168904066086\n",
            "33070 val_loss: 0.28500521183013916, train_loss: 0.0064710769802331924\n",
            "33080 val_loss: 0.2921426296234131, train_loss: 0.006514760199934244\n",
            "33090 val_loss: 0.2589345872402191, train_loss: 0.006372366100549698\n",
            "33100 val_loss: 0.3016061782836914, train_loss: 0.008706895634531975\n",
            "33110 val_loss: 0.27706143260002136, train_loss: 0.006621553096920252\n",
            "33120 val_loss: 0.26269808411598206, train_loss: 0.006812743842601776\n",
            "33130 val_loss: 0.2804540693759918, train_loss: 0.00629342719912529\n",
            "33140 val_loss: 0.3073006868362427, train_loss: 0.006807198282331228\n",
            "33150 val_loss: 0.2655634880065918, train_loss: 0.008164329454302788\n",
            "33160 val_loss: 0.2755422294139862, train_loss: 0.009069559164345264\n",
            "33170 val_loss: 0.3216225802898407, train_loss: 0.008516513742506504\n",
            "33180 val_loss: 0.2958478331565857, train_loss: 0.006141300313174725\n",
            "33190 val_loss: 0.3267427086830139, train_loss: 0.039999108761548996\n",
            "33200 val_loss: 0.25758036971092224, train_loss: 0.00650996807962656\n",
            "33210 val_loss: 0.27729332447052, train_loss: 0.0061835842207074165\n",
            "33220 val_loss: 0.24812421202659607, train_loss: 0.007864654064178467\n",
            "33230 val_loss: 0.2614007592201233, train_loss: 0.0068309372290968895\n",
            "33240 val_loss: 0.26719212532043457, train_loss: 0.006459725089371204\n",
            "33250 val_loss: 0.31532931327819824, train_loss: 0.007133557926863432\n",
            "33260 val_loss: 0.2485668808221817, train_loss: 0.007734962273389101\n",
            "33270 val_loss: 0.3347988426685333, train_loss: 0.009669279679656029\n",
            "33280 val_loss: 0.30684828758239746, train_loss: 0.006509477272629738\n",
            "33290 val_loss: 0.2544403672218323, train_loss: 0.006991209927946329\n",
            "33300 val_loss: 0.2779688835144043, train_loss: 0.006043524015694857\n",
            "33310 val_loss: 0.24345843493938446, train_loss: 0.008386228233575821\n",
            "33320 val_loss: 0.2853315472602844, train_loss: 0.011916612274944782\n",
            "33330 val_loss: 0.3319246470928192, train_loss: 0.01093877013772726\n",
            "33340 val_loss: 0.25660645961761475, train_loss: 0.006952702533453703\n",
            "33350 val_loss: 0.25039100646972656, train_loss: 0.013213058933615685\n",
            "33360 val_loss: 0.2675209641456604, train_loss: 0.006201712880283594\n",
            "33370 val_loss: 0.2588094174861908, train_loss: 0.009593225084245205\n",
            "33380 val_loss: 0.29372870922088623, train_loss: 0.006380152888596058\n",
            "33390 val_loss: 0.38799986243247986, train_loss: 0.07600906491279602\n",
            "33400 val_loss: 0.26557594537734985, train_loss: 0.007062280550599098\n",
            "33410 val_loss: 0.3165489435195923, train_loss: 0.008316293358802795\n",
            "33420 val_loss: 0.2807316482067108, train_loss: 0.006162805948406458\n",
            "33430 val_loss: 0.2833067774772644, train_loss: 0.005951690021902323\n",
            "33440 val_loss: 0.34982940554618835, train_loss: 0.012252410873770714\n",
            "33450 val_loss: 0.2752920687198639, train_loss: 0.005763560067862272\n",
            "33460 val_loss: 0.24707555770874023, train_loss: 0.009194319136440754\n",
            "33470 val_loss: 0.2910833954811096, train_loss: 0.00574424909427762\n",
            "33480 val_loss: 0.2850877642631531, train_loss: 0.005798135884106159\n",
            "33490 val_loss: 0.2531725764274597, train_loss: 0.006810696795582771\n",
            "33500 val_loss: 0.31041058897972107, train_loss: 0.007344234734773636\n",
            "33510 val_loss: 0.32503142952919006, train_loss: 0.008796023204922676\n",
            "33520 val_loss: 0.2753201425075531, train_loss: 0.006408870220184326\n",
            "33530 val_loss: 0.2661042809486389, train_loss: 0.00635446747764945\n",
            "33540 val_loss: 0.29854875802993774, train_loss: 0.006475839763879776\n",
            "33550 val_loss: 0.2765367329120636, train_loss: 0.006061589810997248\n",
            "33560 val_loss: 0.26605647802352905, train_loss: 0.006220881827175617\n",
            "33570 val_loss: 0.25386151671409607, train_loss: 0.008566428907215595\n",
            "33580 val_loss: 0.25356003642082214, train_loss: 0.015339184552431107\n",
            "33590 val_loss: 0.27698376774787903, train_loss: 0.00610368512570858\n",
            "33600 val_loss: 0.26856496930122375, train_loss: 0.0064004831947386265\n",
            "33610 val_loss: 0.2716224789619446, train_loss: 0.0077284867875278\n",
            "33620 val_loss: 0.25501424074172974, train_loss: 0.009559855796396732\n",
            "33630 val_loss: 0.28622928261756897, train_loss: 0.006238204892724752\n",
            "33640 val_loss: 0.28558096289634705, train_loss: 0.006067309528589249\n",
            "33650 val_loss: 0.27026820182800293, train_loss: 0.00612592650577426\n",
            "33660 val_loss: 0.25716516375541687, train_loss: 0.006265800446271896\n",
            "33670 val_loss: 0.26379430294036865, train_loss: 0.005985885392874479\n",
            "33680 val_loss: 0.2961476743221283, train_loss: 0.006248148158192635\n",
            "33690 val_loss: 0.2856890857219696, train_loss: 0.005763484630733728\n",
            "33700 val_loss: 0.25673261284828186, train_loss: 0.0066054449416697025\n",
            "33710 val_loss: 0.25238919258117676, train_loss: 0.007743612863123417\n",
            "33720 val_loss: 0.2834351062774658, train_loss: 0.005715701729059219\n",
            "33730 val_loss: 0.32189851999282837, train_loss: 0.0074260421097278595\n",
            "33740 val_loss: 0.29178041219711304, train_loss: 0.005987128242850304\n",
            "33750 val_loss: 0.29732248187065125, train_loss: 0.006092894356697798\n",
            "33760 val_loss: 0.2653922438621521, train_loss: 0.006011477671563625\n",
            "33770 val_loss: 0.22988761961460114, train_loss: 0.01113433949649334\n",
            "33780 val_loss: 0.29729577898979187, train_loss: 0.005969133693724871\n",
            "33790 val_loss: 0.2858937978744507, train_loss: 0.005840568337589502\n",
            "33800 val_loss: 0.2547162175178528, train_loss: 0.009281739592552185\n",
            "33810 val_loss: 0.27577415108680725, train_loss: 0.01831398345530033\n",
            "33820 val_loss: 0.248433455824852, train_loss: 0.008089556358754635\n",
            "33830 val_loss: 0.26215660572052, train_loss: 0.006407787092030048\n",
            "33840 val_loss: 0.29494306445121765, train_loss: 0.011067472398281097\n",
            "33850 val_loss: 0.2830567955970764, train_loss: 0.00618364242836833\n",
            "33860 val_loss: 0.3004024922847748, train_loss: 0.0061879828572273254\n",
            "33870 val_loss: 0.2791684567928314, train_loss: 0.0056955344043672085\n",
            "33880 val_loss: 0.2951444983482361, train_loss: 0.005950882099568844\n",
            "33890 val_loss: 0.2901037633419037, train_loss: 0.006290258374065161\n",
            "33900 val_loss: 0.27715012431144714, train_loss: 0.0057831560261547565\n",
            "33910 val_loss: 0.27566391229629517, train_loss: 0.0058578308671712875\n",
            "33920 val_loss: 0.2862224578857422, train_loss: 0.006028749048709869\n",
            "33930 val_loss: 0.2956182360649109, train_loss: 0.006153471767902374\n",
            "33940 val_loss: 0.2713261842727661, train_loss: 0.005906684789806604\n",
            "33950 val_loss: 0.30606791377067566, train_loss: 0.006541599985212088\n",
            "33960 val_loss: 0.23260895907878876, train_loss: 0.01039945799857378\n",
            "33970 val_loss: 0.2409300059080124, train_loss: 0.009910741820931435\n",
            "33980 val_loss: 0.24564820528030396, train_loss: 0.01438705064356327\n",
            "33990 val_loss: 0.269512802362442, train_loss: 0.006620494183152914\n",
            "34000 val_loss: 0.2555973529815674, train_loss: 0.007930494844913483\n",
            "34010 val_loss: 0.26487797498703003, train_loss: 0.006447444204241037\n",
            "34020 val_loss: 0.27474701404571533, train_loss: 0.010225435718894005\n",
            "34030 val_loss: 0.33145973086357117, train_loss: 0.00836640689522028\n",
            "34040 val_loss: 0.30037426948547363, train_loss: 0.005984864663332701\n",
            "34050 val_loss: 0.29235827922821045, train_loss: 0.005406405311077833\n",
            "34060 val_loss: 0.28191933035850525, train_loss: 0.005566083826124668\n",
            "34070 val_loss: 0.28192973136901855, train_loss: 0.0070517295971512794\n",
            "34080 val_loss: 0.2753497064113617, train_loss: 0.006302485708147287\n",
            "34090 val_loss: 0.32356712222099304, train_loss: 0.006969209760427475\n",
            "34100 val_loss: 0.30449342727661133, train_loss: 0.005840547848492861\n",
            "34110 val_loss: 0.28762489557266235, train_loss: 0.005443572532385588\n",
            "34120 val_loss: 0.29781609773635864, train_loss: 0.011658653616905212\n",
            "34130 val_loss: 0.32992997765541077, train_loss: 0.007976917549967766\n",
            "34140 val_loss: 0.2834221422672272, train_loss: 0.005568619817495346\n",
            "34150 val_loss: 0.2895423173904419, train_loss: 0.005624393001198769\n",
            "34160 val_loss: 0.2991860806941986, train_loss: 0.005461891181766987\n",
            "34170 val_loss: 0.29836001992225647, train_loss: 0.005719453562051058\n",
            "34180 val_loss: 0.28480663895606995, train_loss: 0.005892392713576555\n",
            "34190 val_loss: 0.2769089341163635, train_loss: 0.010119703598320484\n",
            "34200 val_loss: 0.24635548889636993, train_loss: 0.009013578295707703\n",
            "34210 val_loss: 0.31044095754623413, train_loss: 0.0062962062656879425\n",
            "34220 val_loss: 0.28842827677726746, train_loss: 0.005770307499915361\n",
            "34230 val_loss: 0.27032986283302307, train_loss: 0.011317111551761627\n",
            "34240 val_loss: 0.2850077450275421, train_loss: 0.005552122835069895\n",
            "34250 val_loss: 0.2775794267654419, train_loss: 0.0059680636040866375\n",
            "34260 val_loss: 0.3239656686782837, train_loss: 0.008598056621849537\n",
            "34270 val_loss: 0.29643815755844116, train_loss: 0.005320035852491856\n",
            "34280 val_loss: 0.29652583599090576, train_loss: 0.005399646703153849\n",
            "34290 val_loss: 0.287862092256546, train_loss: 0.005451440345495939\n",
            "34300 val_loss: 0.285047322511673, train_loss: 0.005453179124742746\n",
            "34310 val_loss: 0.2746206820011139, train_loss: 0.006104250438511372\n",
            "34320 val_loss: 0.30945226550102234, train_loss: 0.0061710430309176445\n",
            "34330 val_loss: 0.34579434990882874, train_loss: 0.00892096571624279\n",
            "34340 val_loss: 0.4006431996822357, train_loss: 0.021861841902136803\n",
            "34350 val_loss: 0.29409661889076233, train_loss: 0.0057578301057219505\n",
            "34360 val_loss: 0.28055539727211, train_loss: 0.008987479843199253\n",
            "34370 val_loss: 0.2775023877620697, train_loss: 0.006254512816667557\n",
            "34380 val_loss: 0.29060131311416626, train_loss: 0.005493672098964453\n",
            "34390 val_loss: 0.2794974744319916, train_loss: 0.008177494630217552\n",
            "34400 val_loss: 0.26942184567451477, train_loss: 0.010227645747363567\n",
            "34410 val_loss: 0.3272716701030731, train_loss: 0.006981460843235254\n",
            "34420 val_loss: 0.27578940987586975, train_loss: 0.006557021755725145\n",
            "34430 val_loss: 0.2873867452144623, train_loss: 0.005373288877308369\n",
            "34440 val_loss: 0.29262015223503113, train_loss: 0.005333791486918926\n",
            "34450 val_loss: 0.31546491384506226, train_loss: 0.006233885418623686\n",
            "34460 val_loss: 0.28404054045677185, train_loss: 0.005092737730592489\n",
            "34470 val_loss: 0.3021601140499115, train_loss: 0.005373172461986542\n",
            "34480 val_loss: 0.2908722758293152, train_loss: 0.0051867784932255745\n",
            "34490 val_loss: 0.28196731209754944, train_loss: 0.005263699684292078\n",
            "34500 val_loss: 0.3020481467247009, train_loss: 0.005612420849502087\n",
            "34510 val_loss: 0.2798854410648346, train_loss: 0.006215580739080906\n",
            "34520 val_loss: 0.28222930431365967, train_loss: 0.005593892186880112\n",
            "34530 val_loss: 0.32115989923477173, train_loss: 0.007441983092576265\n",
            "34540 val_loss: 0.33733075857162476, train_loss: 0.007709607947617769\n",
            "34550 val_loss: 0.3087880611419678, train_loss: 0.005277934018522501\n",
            "34560 val_loss: 0.3403972089290619, train_loss: 0.008089596405625343\n",
            "34570 val_loss: 0.2919290363788605, train_loss: 0.00579522829502821\n",
            "34580 val_loss: 0.29419568181037903, train_loss: 0.005599724594503641\n",
            "34590 val_loss: 0.33443188667297363, train_loss: 0.007196883205324411\n",
            "34600 val_loss: 0.26130929589271545, train_loss: 0.006607361137866974\n",
            "34610 val_loss: 0.2597334682941437, train_loss: 0.010403497144579887\n",
            "34620 val_loss: 0.30488452315330505, train_loss: 0.006115184165537357\n",
            "34630 val_loss: 0.29510167241096497, train_loss: 0.005550393834710121\n",
            "34640 val_loss: 0.2919469177722931, train_loss: 0.005414134357124567\n",
            "34650 val_loss: 0.3134058117866516, train_loss: 0.00633786479011178\n",
            "34660 val_loss: 0.2637546956539154, train_loss: 0.0066534182988107204\n",
            "34670 val_loss: 0.27354732155799866, train_loss: 0.006037435960024595\n",
            "34680 val_loss: 0.30252760648727417, train_loss: 0.005378405097872019\n",
            "34690 val_loss: 0.2966022789478302, train_loss: 0.0054029240272939205\n",
            "34700 val_loss: 0.26591482758522034, train_loss: 0.007401627488434315\n",
            "34710 val_loss: 0.2642822861671448, train_loss: 0.010207858867943287\n",
            "34720 val_loss: 0.2597408890724182, train_loss: 0.008881594985723495\n",
            "34730 val_loss: 0.3447086215019226, train_loss: 0.010294650681316853\n",
            "34740 val_loss: 0.31108030676841736, train_loss: 0.006371766794472933\n",
            "34750 val_loss: 0.3069307208061218, train_loss: 0.005725460592657328\n",
            "34760 val_loss: 0.2823822796344757, train_loss: 0.005277368705719709\n",
            "34770 val_loss: 0.2835816442966461, train_loss: 0.0054407562129199505\n",
            "34780 val_loss: 0.34612804651260376, train_loss: 0.008669715374708176\n",
            "34790 val_loss: 0.27216869592666626, train_loss: 0.005545725580304861\n",
            "34800 val_loss: 0.2792322635650635, train_loss: 0.005362576339393854\n",
            "34810 val_loss: 0.3323014974594116, train_loss: 0.007983856834471226\n",
            "34820 val_loss: 0.2637447118759155, train_loss: 0.008724242448806763\n",
            "34830 val_loss: 0.31394317746162415, train_loss: 0.006432057823985815\n",
            "34840 val_loss: 0.270712286233902, train_loss: 0.006556408945471048\n",
            "34850 val_loss: 0.2632112205028534, train_loss: 0.007438206113874912\n",
            "34860 val_loss: 0.26225295662879944, train_loss: 0.008575843647122383\n",
            "34870 val_loss: 0.2647216320037842, train_loss: 0.014446036890149117\n",
            "34880 val_loss: 0.24560771882534027, train_loss: 0.008723985403776169\n",
            "34890 val_loss: 0.2859362065792084, train_loss: 0.005300247110426426\n",
            "34900 val_loss: 0.30278724431991577, train_loss: 0.0054334369488060474\n",
            "34910 val_loss: 0.2849719524383545, train_loss: 0.005331831518560648\n",
            "34920 val_loss: 0.2676423490047455, train_loss: 0.005873100366443396\n",
            "34930 val_loss: 0.2924712598323822, train_loss: 0.004914865829050541\n",
            "34940 val_loss: 0.26657456159591675, train_loss: 0.005686071235686541\n",
            "34950 val_loss: 0.2883244454860687, train_loss: 0.004992442671209574\n",
            "34960 val_loss: 0.25861290097236633, train_loss: 0.006861151661723852\n",
            "34970 val_loss: 0.3033832013607025, train_loss: 0.005249325651675463\n",
            "34980 val_loss: 0.29043859243392944, train_loss: 0.0060065314173698425\n",
            "34990 val_loss: 0.36038362979888916, train_loss: 0.013065585866570473\n",
            "35000 val_loss: 0.26086148619651794, train_loss: 0.00650053471326828\n",
            "35010 val_loss: 0.3055644631385803, train_loss: 0.005426154471933842\n",
            "35020 val_loss: 0.3038044273853302, train_loss: 0.005118815694004297\n",
            "35030 val_loss: 0.32324904203414917, train_loss: 0.00676310807466507\n",
            "35040 val_loss: 0.2903033196926117, train_loss: 0.005345551297068596\n",
            "35050 val_loss: 0.2851104736328125, train_loss: 0.006060004234313965\n",
            "35060 val_loss: 0.2811538279056549, train_loss: 0.00545078981667757\n",
            "35070 val_loss: 0.27400708198547363, train_loss: 0.007702937349677086\n",
            "35080 val_loss: 0.2966039180755615, train_loss: 0.004861404187977314\n",
            "35090 val_loss: 0.2929990291595459, train_loss: 0.00616149976849556\n",
            "35100 val_loss: 0.2774282395839691, train_loss: 0.006822308525443077\n",
            "35110 val_loss: 0.3079037368297577, train_loss: 0.0080922432243824\n",
            "35120 val_loss: 0.2806757092475891, train_loss: 0.005668434780091047\n",
            "35130 val_loss: 0.2821250259876251, train_loss: 0.00551380543038249\n",
            "35140 val_loss: 0.275705486536026, train_loss: 0.0057021332904696465\n",
            "35150 val_loss: 0.2978740930557251, train_loss: 0.00519650150090456\n",
            "35160 val_loss: 0.3171297311782837, train_loss: 0.007119662128388882\n",
            "35170 val_loss: 0.29476094245910645, train_loss: 0.007511164993047714\n",
            "35180 val_loss: 0.3350832462310791, train_loss: 0.006455391179770231\n",
            "35190 val_loss: 0.2892754375934601, train_loss: 0.005089475307613611\n",
            "35200 val_loss: 0.28606104850769043, train_loss: 0.005570625886321068\n",
            "35210 val_loss: 0.34587231278419495, train_loss: 0.008113212883472443\n",
            "35220 val_loss: 0.26959848403930664, train_loss: 0.007336747366935015\n",
            "35230 val_loss: 0.3024429678916931, train_loss: 0.005513779353350401\n",
            "35240 val_loss: 0.29248353838920593, train_loss: 0.005054259207099676\n",
            "35250 val_loss: 0.294375479221344, train_loss: 0.004866855219006538\n",
            "35260 val_loss: 0.33467087149620056, train_loss: 0.007116233929991722\n",
            "35270 val_loss: 0.3046945035457611, train_loss: 0.0047324663028120995\n",
            "35280 val_loss: 0.29014354944229126, train_loss: 0.005061898846179247\n",
            "35290 val_loss: 0.2767958641052246, train_loss: 0.005815879441797733\n",
            "35300 val_loss: 0.2959722876548767, train_loss: 0.004926482681185007\n",
            "35310 val_loss: 0.3078901469707489, train_loss: 0.005013075191527605\n",
            "35320 val_loss: 0.28414300084114075, train_loss: 0.0050146994180977345\n",
            "35330 val_loss: 0.2774711549282074, train_loss: 0.005178788676857948\n",
            "35340 val_loss: 0.3051030933856964, train_loss: 0.005134800914674997\n",
            "35350 val_loss: 0.38384783267974854, train_loss: 0.013759871013462543\n",
            "35360 val_loss: 0.3153834939002991, train_loss: 0.005574199836701155\n",
            "35370 val_loss: 0.3024703562259674, train_loss: 0.0048089660704135895\n",
            "35380 val_loss: 0.33827024698257446, train_loss: 0.013423187658190727\n",
            "35390 val_loss: 0.29172641038894653, train_loss: 0.005393660627305508\n",
            "35400 val_loss: 0.2762974798679352, train_loss: 0.0067791263572871685\n",
            "35410 val_loss: 0.28175193071365356, train_loss: 0.0062442985363304615\n",
            "35420 val_loss: 0.3186976909637451, train_loss: 0.005458833184093237\n",
            "35430 val_loss: 0.2940657138824463, train_loss: 0.005506340879946947\n",
            "35440 val_loss: 0.3071059584617615, train_loss: 0.0052192131988704205\n",
            "35450 val_loss: 0.2684813439846039, train_loss: 0.008490229025483131\n",
            "35460 val_loss: 0.3172335922718048, train_loss: 0.0052601927891373634\n",
            "35470 val_loss: 0.32341793179512024, train_loss: 0.013912271708250046\n",
            "35480 val_loss: 0.301155149936676, train_loss: 0.0051144822500646114\n",
            "35490 val_loss: 0.3004511296749115, train_loss: 0.009948382154107094\n",
            "35500 val_loss: 0.2949916422367096, train_loss: 0.004841995891183615\n",
            "35510 val_loss: 0.2907664477825165, train_loss: 0.0049055214039981365\n",
            "35520 val_loss: 0.2729206681251526, train_loss: 0.006146919447928667\n",
            "35530 val_loss: 0.3091825842857361, train_loss: 0.005307128187268972\n",
            "35540 val_loss: 0.3133554756641388, train_loss: 0.005078988615423441\n",
            "35550 val_loss: 0.2758053243160248, train_loss: 0.006166461389511824\n",
            "35560 val_loss: 0.27324724197387695, train_loss: 0.008543112315237522\n",
            "35570 val_loss: 0.30897632241249084, train_loss: 0.004715189803391695\n",
            "35580 val_loss: 0.3253922760486603, train_loss: 0.005025487393140793\n",
            "35590 val_loss: 0.2921266555786133, train_loss: 0.008490168489515781\n",
            "35600 val_loss: 0.3324550986289978, train_loss: 0.01586082950234413\n",
            "35610 val_loss: 0.2787317931652069, train_loss: 0.005367596633732319\n",
            "35620 val_loss: 0.26687514781951904, train_loss: 0.006442094221711159\n",
            "35630 val_loss: 0.28666043281555176, train_loss: 0.005232837051153183\n",
            "35640 val_loss: 0.2841520607471466, train_loss: 0.005205856170505285\n",
            "35650 val_loss: 0.3102271556854248, train_loss: 0.005127354990690947\n",
            "35660 val_loss: 0.2951298654079437, train_loss: 0.0050210230983793736\n",
            "35670 val_loss: 0.2917405068874359, train_loss: 0.004871636163443327\n",
            "35680 val_loss: 0.29257142543792725, train_loss: 0.004751045722514391\n",
            "35690 val_loss: 0.28079232573509216, train_loss: 0.005576400551944971\n",
            "35700 val_loss: 0.29339295625686646, train_loss: 0.004907726775854826\n",
            "35710 val_loss: 0.29310840368270874, train_loss: 0.006901036947965622\n",
            "35720 val_loss: 0.3004848062992096, train_loss: 0.00498529989272356\n",
            "35730 val_loss: 0.32146134972572327, train_loss: 0.0052543822675943375\n",
            "35740 val_loss: 0.3052077889442444, train_loss: 0.0045845056883990765\n",
            "35750 val_loss: 0.28537553548812866, train_loss: 0.005139094311743975\n",
            "35760 val_loss: 0.26296159625053406, train_loss: 0.01305560301989317\n",
            "35770 val_loss: 0.27778327465057373, train_loss: 0.004823802504688501\n",
            "35780 val_loss: 0.27326714992523193, train_loss: 0.00633838027715683\n",
            "35790 val_loss: 0.29375961422920227, train_loss: 0.004627011716365814\n",
            "35800 val_loss: 0.3502733111381531, train_loss: 0.007635623682290316\n",
            "35810 val_loss: 0.3042020797729492, train_loss: 0.004480130970478058\n",
            "35820 val_loss: 0.29223179817199707, train_loss: 0.0053612166084349155\n",
            "35830 val_loss: 0.32675355672836304, train_loss: 0.005337072070688009\n",
            "35840 val_loss: 0.29756656289100647, train_loss: 0.004754132591187954\n",
            "35850 val_loss: 0.2898057997226715, train_loss: 0.004800363909453154\n",
            "35860 val_loss: 0.28240078687667847, train_loss: 0.005237245466560125\n",
            "35870 val_loss: 0.2991551458835602, train_loss: 0.0046884589828550816\n",
            "35880 val_loss: 0.2816297709941864, train_loss: 0.006008684169501066\n",
            "35890 val_loss: 0.25920945405960083, train_loss: 0.007527283858507872\n",
            "35900 val_loss: 0.31132400035858154, train_loss: 0.005185429938137531\n",
            "35910 val_loss: 0.30532631278038025, train_loss: 0.004818858578801155\n",
            "35920 val_loss: 0.31398990750312805, train_loss: 0.005186829715967178\n",
            "35930 val_loss: 0.2929355502128601, train_loss: 0.004693159833550453\n",
            "35940 val_loss: 0.2821422219276428, train_loss: 0.007618830539286137\n",
            "35950 val_loss: 0.30293145775794983, train_loss: 0.004723875317722559\n",
            "35960 val_loss: 0.28677552938461304, train_loss: 0.005097324959933758\n",
            "35970 val_loss: 0.29889169335365295, train_loss: 0.004776543006300926\n",
            "35980 val_loss: 0.3895787298679352, train_loss: 0.013265978544950485\n",
            "35990 val_loss: 0.3298693597316742, train_loss: 0.005103818606585264\n",
            "36000 val_loss: 0.2898281514644623, train_loss: 0.007186172530055046\n",
            "36010 val_loss: 0.35754117369651794, train_loss: 0.00750373862683773\n",
            "36020 val_loss: 0.31088146567344666, train_loss: 0.004801947623491287\n",
            "36030 val_loss: 0.27014678716659546, train_loss: 0.007644569966942072\n",
            "36040 val_loss: 0.32934069633483887, train_loss: 0.0058277808129787445\n",
            "36050 val_loss: 0.28750520944595337, train_loss: 0.0050480240024626255\n",
            "36060 val_loss: 0.272407203912735, train_loss: 0.011373222805559635\n",
            "36070 val_loss: 0.3183491826057434, train_loss: 0.004924319684505463\n",
            "36080 val_loss: 0.2672283351421356, train_loss: 0.006338127423077822\n",
            "36090 val_loss: 0.31795480847358704, train_loss: 0.0045312843285501\n",
            "36100 val_loss: 0.31934815645217896, train_loss: 0.004937293473631144\n",
            "36110 val_loss: 0.28414976596832275, train_loss: 0.005638536531478167\n",
            "36120 val_loss: 0.29276925325393677, train_loss: 0.004973843228071928\n",
            "36130 val_loss: 0.30147022008895874, train_loss: 0.00482783280313015\n",
            "36140 val_loss: 0.38736453652381897, train_loss: 0.01248452253639698\n",
            "36150 val_loss: 0.37325164675712585, train_loss: 0.01017023716121912\n",
            "36160 val_loss: 0.30170267820358276, train_loss: 0.004844453185796738\n",
            "36170 val_loss: 0.36440300941467285, train_loss: 0.008654119446873665\n",
            "36180 val_loss: 0.33198463916778564, train_loss: 0.004783334210515022\n",
            "36190 val_loss: 0.3149576783180237, train_loss: 0.004354218952357769\n",
            "36200 val_loss: 0.289945125579834, train_loss: 0.006205495446920395\n",
            "36210 val_loss: 0.3391513228416443, train_loss: 0.017128825187683105\n",
            "36220 val_loss: 0.3236728310585022, train_loss: 0.005083255469799042\n",
            "36230 val_loss: 0.40072235465049744, train_loss: 0.014548884704709053\n",
            "36240 val_loss: 0.3604362905025482, train_loss: 0.007752195931971073\n",
            "36250 val_loss: 0.3579288721084595, train_loss: 0.007715289480984211\n",
            "36260 val_loss: 0.37410733103752136, train_loss: 0.0068167708814144135\n",
            "36270 val_loss: 0.30466413497924805, train_loss: 0.004915127530694008\n",
            "36280 val_loss: 0.37601935863494873, train_loss: 0.004517318680882454\n",
            "36290 val_loss: 0.32918500900268555, train_loss: 0.004556699190288782\n",
            "36300 val_loss: 0.3146146833896637, train_loss: 0.004716705996543169\n",
            "36310 val_loss: 0.2998313307762146, train_loss: 0.00543333450332284\n",
            "36320 val_loss: 0.2957819998264313, train_loss: 0.005501248873770237\n",
            "36330 val_loss: 0.2835257053375244, train_loss: 0.008501633070409298\n",
            "36340 val_loss: 0.2988423705101013, train_loss: 0.005647934973239899\n",
            "36350 val_loss: 0.32788941264152527, train_loss: 0.004836363717913628\n",
            "36360 val_loss: 0.3284996449947357, train_loss: 0.00430554011836648\n",
            "36370 val_loss: 0.2961103916168213, train_loss: 0.006973504554480314\n",
            "36380 val_loss: 0.32085248827934265, train_loss: 0.004400452133268118\n",
            "36390 val_loss: 0.34726929664611816, train_loss: 0.006797083653509617\n",
            "36400 val_loss: 0.31374624371528625, train_loss: 0.0046460190787911415\n",
            "36410 val_loss: 0.2856278717517853, train_loss: 0.005123061593621969\n",
            "36420 val_loss: 0.29693618416786194, train_loss: 0.0051716649904847145\n",
            "36430 val_loss: 0.32206112146377563, train_loss: 0.004773635417222977\n",
            "36440 val_loss: 0.3013303577899933, train_loss: 0.004953807219862938\n",
            "36450 val_loss: 0.29556095600128174, train_loss: 0.0049116346053779125\n",
            "36460 val_loss: 0.4037778973579407, train_loss: 0.014574947766959667\n",
            "36470 val_loss: 0.3303341269493103, train_loss: 0.005462056025862694\n",
            "36480 val_loss: 0.2892013192176819, train_loss: 0.00619761785492301\n",
            "36490 val_loss: 0.3207457959651947, train_loss: 0.004521859344094992\n",
            "36500 val_loss: 0.2888803482055664, train_loss: 0.005451307166367769\n",
            "36510 val_loss: 0.33957651257514954, train_loss: 0.004661485552787781\n",
            "36520 val_loss: 0.3425636291503906, train_loss: 0.006041412241756916\n",
            "36530 val_loss: 0.30800309777259827, train_loss: 0.005002007354050875\n",
            "36540 val_loss: 0.28648826479911804, train_loss: 0.006017126142978668\n",
            "36550 val_loss: 0.28267404437065125, train_loss: 0.006127083674073219\n",
            "36560 val_loss: 0.297346830368042, train_loss: 0.008057490922510624\n",
            "36570 val_loss: 0.3351377248764038, train_loss: 0.00601230701431632\n",
            "36580 val_loss: 0.2989777624607086, train_loss: 0.004598116036504507\n",
            "36590 val_loss: 0.3390292525291443, train_loss: 0.006312333047389984\n",
            "36600 val_loss: 0.27657550573349, train_loss: 0.007234805729240179\n",
            "36610 val_loss: 0.2774442136287689, train_loss: 0.0053249262273311615\n",
            "36620 val_loss: 0.2913290858268738, train_loss: 0.004587885923683643\n",
            "36630 val_loss: 0.2993321120738983, train_loss: 0.004418501630425453\n",
            "36640 val_loss: 0.3135416507720947, train_loss: 0.005059262737631798\n",
            "36650 val_loss: 0.2685769200325012, train_loss: 0.007236699108034372\n",
            "36660 val_loss: 0.31224367022514343, train_loss: 0.004621251951903105\n",
            "36670 val_loss: 0.4107934832572937, train_loss: 0.01850796304643154\n",
            "36680 val_loss: 0.28449636697769165, train_loss: 0.005219598300755024\n",
            "36690 val_loss: 0.28302109241485596, train_loss: 0.007769576273858547\n",
            "36700 val_loss: 0.3489230275154114, train_loss: 0.007199387066066265\n",
            "36710 val_loss: 0.31759119033813477, train_loss: 0.012192421592772007\n",
            "36720 val_loss: 0.31718531250953674, train_loss: 0.004793280735611916\n",
            "36730 val_loss: 0.3326289653778076, train_loss: 0.005634132772684097\n",
            "36740 val_loss: 0.31792983412742615, train_loss: 0.006858587730675936\n",
            "36750 val_loss: 0.3148519992828369, train_loss: 0.004276844672858715\n",
            "36760 val_loss: 0.30517151951789856, train_loss: 0.004675963427871466\n",
            "36770 val_loss: 0.2951602041721344, train_loss: 0.004457395523786545\n",
            "36780 val_loss: 0.2865636348724365, train_loss: 0.004983025137335062\n",
            "36790 val_loss: 0.28273963928222656, train_loss: 0.004808897152543068\n",
            "36800 val_loss: 0.28584447503089905, train_loss: 0.004499852657318115\n",
            "36810 val_loss: 0.33401358127593994, train_loss: 0.006440023425966501\n",
            "36820 val_loss: 0.2782961428165436, train_loss: 0.007038796320557594\n",
            "36830 val_loss: 0.37624385952949524, train_loss: 0.011679141782224178\n",
            "36840 val_loss: 0.319782018661499, train_loss: 0.00418095663189888\n",
            "36850 val_loss: 0.3456563353538513, train_loss: 0.020747486501932144\n",
            "36860 val_loss: 0.2921704649925232, train_loss: 0.005383665673434734\n",
            "36870 val_loss: 0.313812255859375, train_loss: 0.004935162607580423\n",
            "36880 val_loss: 0.3010447025299072, train_loss: 0.004866159986704588\n",
            "36890 val_loss: 0.28389549255371094, train_loss: 0.004435261711478233\n",
            "36900 val_loss: 0.31506553292274475, train_loss: 0.004915466532111168\n",
            "36910 val_loss: 0.2633713185787201, train_loss: 0.006915524136275053\n",
            "36920 val_loss: 0.29438164830207825, train_loss: 0.004179867450147867\n",
            "36930 val_loss: 0.4094853699207306, train_loss: 0.018927235156297684\n",
            "36940 val_loss: 0.30938562750816345, train_loss: 0.009672390297055244\n",
            "36950 val_loss: 0.2946225106716156, train_loss: 0.004309478681534529\n",
            "36960 val_loss: 0.30159229040145874, train_loss: 0.004125120583921671\n",
            "36970 val_loss: 0.2781328558921814, train_loss: 0.00514425290748477\n",
            "36980 val_loss: 0.30350562930107117, train_loss: 0.004622981417924166\n",
            "36990 val_loss: 0.3051174283027649, train_loss: 0.004377051256597042\n",
            "37000 val_loss: 0.3129027783870697, train_loss: 0.004543023649603128\n",
            "37010 val_loss: 0.3090857267379761, train_loss: 0.004239194095134735\n",
            "37020 val_loss: 0.3105486333370209, train_loss: 0.004278167150914669\n",
            "37030 val_loss: 0.2996155321598053, train_loss: 0.004742238204926252\n",
            "37040 val_loss: 0.2779136002063751, train_loss: 0.005754196550697088\n",
            "37050 val_loss: 0.2974066138267517, train_loss: 0.0044399709440767765\n",
            "37060 val_loss: 0.35698914527893066, train_loss: 0.008297931402921677\n",
            "37070 val_loss: 0.33153966069221497, train_loss: 0.008588984608650208\n",
            "37080 val_loss: 0.31671133637428284, train_loss: 0.004315280821174383\n",
            "37090 val_loss: 0.28832951188087463, train_loss: 0.005138114560395479\n",
            "37100 val_loss: 0.2865920066833496, train_loss: 0.004472982604056597\n",
            "37110 val_loss: 0.3100406229496002, train_loss: 0.004515614826232195\n",
            "37120 val_loss: 0.2917558252811432, train_loss: 0.013055670075118542\n",
            "37130 val_loss: 0.33805355429649353, train_loss: 0.0051064020954072475\n",
            "37140 val_loss: 0.31423139572143555, train_loss: 0.0045405542477965355\n",
            "37150 val_loss: 0.30919143557548523, train_loss: 0.00895748846232891\n",
            "37160 val_loss: 0.37685856223106384, train_loss: 0.012508180923759937\n",
            "37170 val_loss: 0.3144630789756775, train_loss: 0.004289007745683193\n",
            "37180 val_loss: 0.3187415599822998, train_loss: 0.0043071298860013485\n",
            "37190 val_loss: 0.2868116497993469, train_loss: 0.00888212863355875\n",
            "37200 val_loss: 0.3025659918785095, train_loss: 0.004105704370886087\n",
            "37210 val_loss: 0.28215643763542175, train_loss: 0.005101369693875313\n",
            "37220 val_loss: 0.2975815236568451, train_loss: 0.004206118639558554\n",
            "37230 val_loss: 0.3136540949344635, train_loss: 0.0055581931956112385\n",
            "37240 val_loss: 0.3029520511627197, train_loss: 0.004841031040996313\n",
            "37250 val_loss: 0.3179096579551697, train_loss: 0.01121697947382927\n",
            "37260 val_loss: 0.3561078906059265, train_loss: 0.005431169643998146\n",
            "37270 val_loss: 0.3025035560131073, train_loss: 0.007117146160453558\n",
            "37280 val_loss: 0.2975083589553833, train_loss: 0.004450859967619181\n",
            "37290 val_loss: 0.36329227685928345, train_loss: 0.009665641002357006\n",
            "37300 val_loss: 0.2846638858318329, train_loss: 0.005861806683242321\n",
            "37310 val_loss: 0.30763813853263855, train_loss: 0.006060829386115074\n",
            "37320 val_loss: 0.3612554371356964, train_loss: 0.006982050836086273\n",
            "37330 val_loss: 0.30618661642074585, train_loss: 0.012447436340153217\n",
            "37340 val_loss: 0.28158289194107056, train_loss: 0.006694904528558254\n",
            "37350 val_loss: 0.2971074879169464, train_loss: 0.00477125309407711\n",
            "37360 val_loss: 0.2985120713710785, train_loss: 0.004953552037477493\n",
            "37370 val_loss: 0.3019857406616211, train_loss: 0.004559161141514778\n",
            "37380 val_loss: 0.30280816555023193, train_loss: 0.0046010795049369335\n",
            "37390 val_loss: 0.291735976934433, train_loss: 0.004929717630147934\n",
            "37400 val_loss: 0.34732192754745483, train_loss: 0.004363221116364002\n",
            "37410 val_loss: 0.3094077706336975, train_loss: 0.004730350337922573\n",
            "37420 val_loss: 0.31203874945640564, train_loss: 0.004483161028474569\n",
            "37430 val_loss: 0.27870994806289673, train_loss: 0.005503895226866007\n",
            "37440 val_loss: 0.2970517873764038, train_loss: 0.00447582732886076\n",
            "37450 val_loss: 0.3094315826892853, train_loss: 0.004250582307577133\n",
            "37460 val_loss: 0.3127566874027252, train_loss: 0.004354563541710377\n",
            "37470 val_loss: 0.29030370712280273, train_loss: 0.01301103550940752\n",
            "37480 val_loss: 0.2928745746612549, train_loss: 0.005867247004061937\n",
            "37490 val_loss: 0.3710922300815582, train_loss: 0.01116057951003313\n",
            "37500 val_loss: 0.29685282707214355, train_loss: 0.0057035526260733604\n",
            "37510 val_loss: 0.28315168619155884, train_loss: 0.0052238344214856625\n",
            "37520 val_loss: 0.30927950143814087, train_loss: 0.005418115761131048\n",
            "37530 val_loss: 0.31401586532592773, train_loss: 0.0075141326524317265\n",
            "37540 val_loss: 0.3242470622062683, train_loss: 0.0049470895901322365\n",
            "37550 val_loss: 0.292574942111969, train_loss: 0.004580847453325987\n",
            "37560 val_loss: 0.28859829902648926, train_loss: 0.004935253411531448\n",
            "37570 val_loss: 0.3035200536251068, train_loss: 0.004307019058614969\n",
            "37580 val_loss: 0.3442453444004059, train_loss: 0.00447135791182518\n",
            "37590 val_loss: 0.3169020712375641, train_loss: 0.004181609023362398\n",
            "37600 val_loss: 0.343383252620697, train_loss: 0.0048719909973442554\n",
            "37610 val_loss: 0.32242441177368164, train_loss: 0.007844224572181702\n",
            "37620 val_loss: 0.3097519278526306, train_loss: 0.004198178183287382\n",
            "37630 val_loss: 0.32422083616256714, train_loss: 0.004777669440954924\n",
            "37640 val_loss: 0.28690391778945923, train_loss: 0.010044654831290245\n",
            "37650 val_loss: 0.3109600841999054, train_loss: 0.0041014663875103\n",
            "37660 val_loss: 0.3379921317100525, train_loss: 0.003993231803178787\n",
            "37670 val_loss: 0.33785271644592285, train_loss: 0.00625251280143857\n",
            "37680 val_loss: 0.31921643018722534, train_loss: 0.00591650977730751\n",
            "37690 val_loss: 0.30241402983665466, train_loss: 0.005707429256290197\n",
            "37700 val_loss: 0.3126920461654663, train_loss: 0.003980427514761686\n",
            "37710 val_loss: 0.3582160472869873, train_loss: 0.008215317502617836\n",
            "37720 val_loss: 0.3117533028125763, train_loss: 0.0042265900410711765\n",
            "37730 val_loss: 0.28243812918663025, train_loss: 0.006360113620758057\n",
            "37740 val_loss: 0.3197571635246277, train_loss: 0.0037572861183434725\n",
            "37750 val_loss: 0.39265215396881104, train_loss: 0.01246221736073494\n",
            "37760 val_loss: 0.3253009617328644, train_loss: 0.0038787839002907276\n",
            "37770 val_loss: 0.3062182664871216, train_loss: 0.004140628036111593\n",
            "37780 val_loss: 0.3787462115287781, train_loss: 0.01125433761626482\n",
            "37790 val_loss: 0.2943800985813141, train_loss: 0.005260224919766188\n",
            "37800 val_loss: 0.33821412920951843, train_loss: 0.0039367033168673515\n",
            "37810 val_loss: 0.3483196496963501, train_loss: 0.006258159875869751\n",
            "37820 val_loss: 0.28811419010162354, train_loss: 0.006791302934288979\n",
            "37830 val_loss: 0.32218611240386963, train_loss: 0.004350508563220501\n",
            "37840 val_loss: 0.30743926763534546, train_loss: 0.0049466765485703945\n",
            "37850 val_loss: 0.3686669170856476, train_loss: 0.009211819618940353\n",
            "37860 val_loss: 0.2994649410247803, train_loss: 0.004181753844022751\n",
            "37870 val_loss: 0.33536919951438904, train_loss: 0.005625991616398096\n",
            "37880 val_loss: 0.307768851518631, train_loss: 0.004898184910416603\n",
            "37890 val_loss: 0.32311177253723145, train_loss: 0.0039849900640547276\n",
            "37900 val_loss: 0.2940809726715088, train_loss: 0.0054132672958076\n",
            "37910 val_loss: 0.3196491599082947, train_loss: 0.004887028597295284\n",
            "37920 val_loss: 0.3148553967475891, train_loss: 0.004138866439461708\n",
            "37930 val_loss: 0.33588290214538574, train_loss: 0.0051947650499641895\n",
            "37940 val_loss: 0.33141589164733887, train_loss: 0.00446854205802083\n",
            "37950 val_loss: 0.32844504714012146, train_loss: 0.007079671137034893\n",
            "37960 val_loss: 0.32792139053344727, train_loss: 0.011172388680279255\n",
            "37970 val_loss: 0.33486539125442505, train_loss: 0.012303712777793407\n",
            "37980 val_loss: 0.31281033158302307, train_loss: 0.004271060694009066\n",
            "37990 val_loss: 0.33147501945495605, train_loss: 0.004597801715135574\n",
            "38000 val_loss: 0.3164113759994507, train_loss: 0.004335387144237757\n",
            "38010 val_loss: 0.34812769293785095, train_loss: 0.006301037035882473\n",
            "38020 val_loss: 0.35828155279159546, train_loss: 0.013002372346818447\n",
            "38030 val_loss: 0.344487726688385, train_loss: 0.004059499129652977\n",
            "38040 val_loss: 0.29984113574028015, train_loss: 0.004264647141098976\n",
            "38050 val_loss: 0.3148612976074219, train_loss: 0.003955964930355549\n",
            "38060 val_loss: 0.30684253573417664, train_loss: 0.00402931310236454\n",
            "38070 val_loss: 0.3170742392539978, train_loss: 0.003801847342401743\n",
            "38080 val_loss: 0.31829771399497986, train_loss: 0.003926088102161884\n",
            "38090 val_loss: 0.33878663182258606, train_loss: 0.0038133272901177406\n",
            "38100 val_loss: 0.33400672674179077, train_loss: 0.004136878531426191\n",
            "38110 val_loss: 0.3107512891292572, train_loss: 0.005609401501715183\n",
            "38120 val_loss: 0.2993210554122925, train_loss: 0.004449149593710899\n",
            "38130 val_loss: 0.3327465355396271, train_loss: 0.004187595099210739\n",
            "38140 val_loss: 0.3343522548675537, train_loss: 0.0045615509152412415\n",
            "38150 val_loss: 0.31091898679733276, train_loss: 0.004590298049151897\n",
            "38160 val_loss: 0.337481826543808, train_loss: 0.003603113815188408\n",
            "38170 val_loss: 0.3426720201969147, train_loss: 0.004699563607573509\n",
            "38180 val_loss: 0.318070650100708, train_loss: 0.0037175060715526342\n",
            "38190 val_loss: 0.31300321221351624, train_loss: 0.003617075737565756\n",
            "38200 val_loss: 0.312303364276886, train_loss: 0.004011161159723997\n",
            "38210 val_loss: 0.3527609407901764, train_loss: 0.012662437744438648\n",
            "38220 val_loss: 0.30048447847366333, train_loss: 0.004492206498980522\n",
            "38230 val_loss: 0.3065672516822815, train_loss: 0.004328582435846329\n",
            "38240 val_loss: 0.322676420211792, train_loss: 0.004061955027282238\n",
            "38250 val_loss: 0.30818480253219604, train_loss: 0.004199531394988298\n",
            "38260 val_loss: 0.3076716661453247, train_loss: 0.0049655442126095295\n",
            "38270 val_loss: 0.3205605149269104, train_loss: 0.004039825405925512\n",
            "38280 val_loss: 0.3295794129371643, train_loss: 0.005221826024353504\n",
            "38290 val_loss: 0.30599716305732727, train_loss: 0.004661539103835821\n",
            "38300 val_loss: 0.31741252541542053, train_loss: 0.0039147729985415936\n",
            "38310 val_loss: 0.30712276697158813, train_loss: 0.004252714104950428\n",
            "38320 val_loss: 0.3443847894668579, train_loss: 0.004118191543966532\n",
            "38330 val_loss: 0.3372015357017517, train_loss: 0.004339526407420635\n",
            "38340 val_loss: 0.31952208280563354, train_loss: 0.004481958691030741\n",
            "38350 val_loss: 0.30759844183921814, train_loss: 0.005554609000682831\n",
            "38360 val_loss: 0.320609986782074, train_loss: 0.003998668864369392\n",
            "38370 val_loss: 0.3421691656112671, train_loss: 0.008375449106097221\n",
            "38380 val_loss: 0.31352972984313965, train_loss: 0.0040745362639427185\n",
            "38390 val_loss: 0.30579495429992676, train_loss: 0.004675911273807287\n",
            "38400 val_loss: 0.3627432882785797, train_loss: 0.009639396332204342\n",
            "38410 val_loss: 0.34123098850250244, train_loss: 0.004342165309935808\n",
            "38420 val_loss: 0.3862845003604889, train_loss: 0.01068318635225296\n",
            "38430 val_loss: 0.3129398822784424, train_loss: 0.0041177538223564625\n",
            "38440 val_loss: 0.29848894476890564, train_loss: 0.005624990910291672\n",
            "38450 val_loss: 0.34622710943222046, train_loss: 0.004770372062921524\n",
            "38460 val_loss: 0.34249308705329895, train_loss: 0.004322141874581575\n",
            "38470 val_loss: 0.3174448013305664, train_loss: 0.004184368532150984\n",
            "38480 val_loss: 0.3414982259273529, train_loss: 0.004923964850604534\n",
            "38490 val_loss: 0.31220078468322754, train_loss: 0.004159736447036266\n",
            "38500 val_loss: 0.33105289936065674, train_loss: 0.0039390153251588345\n",
            "38510 val_loss: 0.3145315647125244, train_loss: 0.003991284407675266\n",
            "38520 val_loss: 0.3080817759037018, train_loss: 0.005672413855791092\n",
            "38530 val_loss: 0.3489358425140381, train_loss: 0.014793365262448788\n",
            "38540 val_loss: 0.34225597977638245, train_loss: 0.005129663273692131\n",
            "38550 val_loss: 0.3252290189266205, train_loss: 0.0038209203630685806\n",
            "38560 val_loss: 0.267599493265152, train_loss: 0.009077909402549267\n",
            "38570 val_loss: 0.3115605115890503, train_loss: 0.0041978927329182625\n",
            "38580 val_loss: 0.33815744519233704, train_loss: 0.003735694568604231\n",
            "38590 val_loss: 0.323776513338089, train_loss: 0.004427109844982624\n",
            "38600 val_loss: 0.32404381036758423, train_loss: 0.00366611173376441\n",
            "38610 val_loss: 0.3346802294254303, train_loss: 0.003942958079278469\n",
            "38620 val_loss: 0.31627413630485535, train_loss: 0.005209393799304962\n",
            "38630 val_loss: 0.368150919675827, train_loss: 0.008197449147701263\n",
            "38640 val_loss: 0.3565843999385834, train_loss: 0.0059624770656228065\n",
            "38650 val_loss: 0.3118952810764313, train_loss: 0.0036794226616621017\n",
            "38660 val_loss: 0.32521548867225647, train_loss: 0.003782715182751417\n",
            "38670 val_loss: 0.2837214767932892, train_loss: 0.009605706669390202\n",
            "38680 val_loss: 0.3290272355079651, train_loss: 0.004013040103018284\n",
            "38690 val_loss: 0.29216673970222473, train_loss: 0.01771492324769497\n",
            "38700 val_loss: 0.3179233968257904, train_loss: 0.004170983098447323\n",
            "38710 val_loss: 0.3200206160545349, train_loss: 0.003914662636816502\n",
            "38720 val_loss: 0.33249637484550476, train_loss: 0.004379517864435911\n",
            "38730 val_loss: 0.48672690987586975, train_loss: 0.10214551538228989\n",
            "38740 val_loss: 0.25482773780822754, train_loss: 0.07230689376592636\n",
            "38750 val_loss: 0.29815196990966797, train_loss: 0.05505766347050667\n",
            "38760 val_loss: 0.29251569509506226, train_loss: 0.04732641577720642\n",
            "38770 val_loss: 0.29858526587486267, train_loss: 0.040343932807445526\n",
            "38780 val_loss: 0.27043768763542175, train_loss: 0.02560507319867611\n",
            "38790 val_loss: 0.29380184412002563, train_loss: 0.018126240000128746\n",
            "38800 val_loss: 0.27905234694480896, train_loss: 0.014028241857886314\n",
            "38810 val_loss: 0.2992485463619232, train_loss: 0.01177535392343998\n",
            "38820 val_loss: 0.28571438789367676, train_loss: 0.01071494072675705\n",
            "38830 val_loss: 0.30710119009017944, train_loss: 0.009247069247066975\n",
            "38840 val_loss: 0.33925360441207886, train_loss: 0.010584620758891106\n",
            "38850 val_loss: 0.3057299256324768, train_loss: 0.007314164191484451\n",
            "38860 val_loss: 0.2929175794124603, train_loss: 0.008247632533311844\n",
            "38870 val_loss: 0.3250292241573334, train_loss: 0.005679171998053789\n",
            "38880 val_loss: 0.29311537742614746, train_loss: 0.005853679031133652\n",
            "38890 val_loss: 0.31525325775146484, train_loss: 0.004634518176317215\n",
            "38900 val_loss: 0.325253427028656, train_loss: 0.004692394752055407\n",
            "38910 val_loss: 0.30131056904792786, train_loss: 0.004918297752737999\n",
            "38920 val_loss: 0.309047669172287, train_loss: 0.004031268414109945\n",
            "38930 val_loss: 0.30843159556388855, train_loss: 0.004731505643576384\n",
            "38940 val_loss: 0.31439605355262756, train_loss: 0.003883528057485819\n",
            "38950 val_loss: 0.30453988909721375, train_loss: 0.004049366340041161\n",
            "38960 val_loss: 0.3060518503189087, train_loss: 0.004191969521343708\n",
            "38970 val_loss: 0.29742902517318726, train_loss: 0.011098548769950867\n",
            "38980 val_loss: 0.3897070586681366, train_loss: 0.040542520582675934\n",
            "38990 val_loss: 0.3235413730144501, train_loss: 0.004254554398357868\n",
            "39000 val_loss: 0.30543696880340576, train_loss: 0.00444016233086586\n",
            "39010 val_loss: 0.3000030815601349, train_loss: 0.005116266664117575\n",
            "39020 val_loss: 0.3051843047142029, train_loss: 0.003908706363290548\n",
            "39030 val_loss: 0.3252958655357361, train_loss: 0.0037846725899726152\n",
            "39040 val_loss: 0.31174036860466003, train_loss: 0.0037316682282835245\n",
            "39050 val_loss: 0.31667840480804443, train_loss: 0.004117715638130903\n",
            "39060 val_loss: 0.36667901277542114, train_loss: 0.008295265957713127\n",
            "39070 val_loss: 0.3134196102619171, train_loss: 0.0037140913773328066\n",
            "39080 val_loss: 0.2940026819705963, train_loss: 0.01426281500607729\n",
            "39090 val_loss: 0.3105791509151459, train_loss: 0.0034917593002319336\n",
            "39100 val_loss: 0.29664748907089233, train_loss: 0.007353261578828096\n",
            "39110 val_loss: 0.3473345637321472, train_loss: 0.0061164237558841705\n",
            "39120 val_loss: 0.35844194889068604, train_loss: 0.00840273592621088\n",
            "39130 val_loss: 0.2983373701572418, train_loss: 0.0046980674378573895\n",
            "39140 val_loss: 0.27380403876304626, train_loss: 0.011025689542293549\n",
            "39150 val_loss: 0.3143036663532257, train_loss: 0.004601714666932821\n",
            "39160 val_loss: 0.2986087203025818, train_loss: 0.004960074555128813\n",
            "39170 val_loss: 0.2963656485080719, train_loss: 0.005451689474284649\n",
            "39180 val_loss: 0.32228919863700867, train_loss: 0.00462342007085681\n",
            "39190 val_loss: 0.3183870315551758, train_loss: 0.013767329975962639\n",
            "39200 val_loss: 0.3255440294742584, train_loss: 0.004234081134200096\n",
            "39210 val_loss: 0.3591815233230591, train_loss: 0.008388889022171497\n",
            "39220 val_loss: 0.34119775891304016, train_loss: 0.0060413433238863945\n",
            "39230 val_loss: 0.35878077149391174, train_loss: 0.007314376533031464\n",
            "39240 val_loss: 0.30269014835357666, train_loss: 0.004785268101841211\n",
            "39250 val_loss: 0.31695836782455444, train_loss: 0.003677360014989972\n",
            "39260 val_loss: 0.33296388387680054, train_loss: 0.00389859639108181\n",
            "39270 val_loss: 0.3273699879646301, train_loss: 0.0034625378903001547\n",
            "39280 val_loss: 0.3365972638130188, train_loss: 0.004175225272774696\n",
            "39290 val_loss: 0.3225511610507965, train_loss: 0.003514721756801009\n",
            "39300 val_loss: 0.3220680356025696, train_loss: 0.0035340816248208284\n",
            "39310 val_loss: 0.36244815587997437, train_loss: 0.007494996301829815\n",
            "39320 val_loss: 0.3000105917453766, train_loss: 0.005130674224346876\n",
            "39330 val_loss: 0.2958589792251587, train_loss: 0.006085475906729698\n",
            "39340 val_loss: 0.3235831558704376, train_loss: 0.0036186708603054285\n",
            "39350 val_loss: 0.33365416526794434, train_loss: 0.004114584531635046\n",
            "39360 val_loss: 0.3010943830013275, train_loss: 0.004557549953460693\n",
            "39370 val_loss: 0.32251888513565063, train_loss: 0.004721113480627537\n",
            "39380 val_loss: 0.33631381392478943, train_loss: 0.005159412045031786\n",
            "39390 val_loss: 0.32405129075050354, train_loss: 0.00407769251614809\n",
            "39400 val_loss: 0.29676273465156555, train_loss: 0.011211131699383259\n",
            "39410 val_loss: 0.32611724734306335, train_loss: 0.0036887244787067175\n",
            "39420 val_loss: 0.3181849420070648, train_loss: 0.003965433686971664\n",
            "39430 val_loss: 0.3518383204936981, train_loss: 0.0038009590934962034\n",
            "39440 val_loss: 0.34250837564468384, train_loss: 0.003819688456133008\n",
            "39450 val_loss: 0.31995484232902527, train_loss: 0.003358648158609867\n",
            "39460 val_loss: 0.3381994962692261, train_loss: 0.006135143339633942\n",
            "39470 val_loss: 0.33876100182533264, train_loss: 0.003766536945477128\n",
            "39480 val_loss: 0.331259548664093, train_loss: 0.004134526476264\n",
            "39490 val_loss: 0.4409278631210327, train_loss: 0.02010084129869938\n",
            "39500 val_loss: 0.3179323673248291, train_loss: 0.003869913751259446\n",
            "39510 val_loss: 0.3071052134037018, train_loss: 0.004397616721689701\n",
            "39520 val_loss: 0.31658101081848145, train_loss: 0.003793486626818776\n",
            "39530 val_loss: 0.3556525707244873, train_loss: 0.014824957586824894\n",
            "39540 val_loss: 0.3210391402244568, train_loss: 0.003533080453053117\n",
            "39550 val_loss: 0.36435532569885254, train_loss: 0.007476037368178368\n",
            "39560 val_loss: 0.31489887833595276, train_loss: 0.0035867991391569376\n",
            "39570 val_loss: 0.31090980768203735, train_loss: 0.004185593221336603\n",
            "39580 val_loss: 0.3220099210739136, train_loss: 0.0034327413886785507\n",
            "39590 val_loss: 0.31709936261177063, train_loss: 0.003782479790970683\n",
            "39600 val_loss: 0.3187841475009918, train_loss: 0.0038686725310981274\n",
            "39610 val_loss: 0.32961106300354004, train_loss: 0.0036895142402499914\n",
            "39620 val_loss: 0.33351561427116394, train_loss: 0.004141412675380707\n",
            "39630 val_loss: 0.36929258704185486, train_loss: 0.007412191946059465\n",
            "39640 val_loss: 0.34983009099960327, train_loss: 0.0050099994987249374\n",
            "39650 val_loss: 0.3283179998397827, train_loss: 0.0036382328253239393\n",
            "39660 val_loss: 0.31878727674484253, train_loss: 0.0049718087539076805\n",
            "39670 val_loss: 0.3371577560901642, train_loss: 0.0033510823268443346\n",
            "39680 val_loss: 0.3303905129432678, train_loss: 0.003366935532540083\n",
            "39690 val_loss: 0.37002500891685486, train_loss: 0.007688702549785376\n",
            "39700 val_loss: 0.32199928164482117, train_loss: 0.0040764156728982925\n",
            "39710 val_loss: 0.3311890661716461, train_loss: 0.0037813044618815184\n",
            "39720 val_loss: 0.3684161603450775, train_loss: 0.006353527773171663\n",
            "39730 val_loss: 0.3468689024448395, train_loss: 0.004192017484456301\n",
            "39740 val_loss: 0.3556273579597473, train_loss: 0.0047219544649124146\n",
            "39750 val_loss: 0.314911425113678, train_loss: 0.004231189377605915\n",
            "39760 val_loss: 0.3284582495689392, train_loss: 0.0033442971762269735\n",
            "39770 val_loss: 0.3243032991886139, train_loss: 0.003251374466344714\n",
            "39780 val_loss: 0.3589943051338196, train_loss: 0.005521033890545368\n",
            "39790 val_loss: 0.31717079877853394, train_loss: 0.004834131803363562\n",
            "39800 val_loss: 0.3313961625099182, train_loss: 0.003931198734790087\n",
            "39810 val_loss: 0.3091663718223572, train_loss: 0.00543446559458971\n",
            "39820 val_loss: 0.3262099325656891, train_loss: 0.004065883345901966\n",
            "39830 val_loss: 0.3616536855697632, train_loss: 0.00541070057079196\n",
            "39840 val_loss: 0.3376959562301636, train_loss: 0.00389045849442482\n",
            "39850 val_loss: 0.3363319933414459, train_loss: 0.0034651991445571184\n",
            "39860 val_loss: 0.30608049035072327, train_loss: 0.008103398606181145\n",
            "39870 val_loss: 0.35110801458358765, train_loss: 0.004346618428826332\n",
            "39880 val_loss: 0.37191033363342285, train_loss: 0.006183185148984194\n",
            "39890 val_loss: 0.3279614746570587, train_loss: 0.0035986918956041336\n",
            "39900 val_loss: 0.33444660902023315, train_loss: 0.003351499792188406\n",
            "39910 val_loss: 0.3220770061016083, train_loss: 0.004273599945008755\n",
            "39920 val_loss: 0.3390241861343384, train_loss: 0.003455251222476363\n",
            "39930 val_loss: 0.3094925284385681, train_loss: 0.0047411308623850346\n",
            "39940 val_loss: 0.33495303988456726, train_loss: 0.003530117217451334\n",
            "39950 val_loss: 0.3193313181400299, train_loss: 0.003439305117353797\n",
            "39960 val_loss: 0.4315067529678345, train_loss: 0.017891012132167816\n",
            "39970 val_loss: 0.31313851475715637, train_loss: 0.00362608814612031\n",
            "39980 val_loss: 0.34770467877388, train_loss: 0.004617874510586262\n",
            "39990 val_loss: 0.31214311718940735, train_loss: 0.004224809352308512\n",
            "40000 val_loss: 0.33347320556640625, train_loss: 0.003600555006414652\n",
            "40010 val_loss: 0.33379998803138733, train_loss: 0.0032637659460306168\n",
            "40020 val_loss: 0.3051622211933136, train_loss: 0.005823913961648941\n",
            "40030 val_loss: 0.3137650489807129, train_loss: 0.004990815185010433\n",
            "40040 val_loss: 0.33621126413345337, train_loss: 0.0032605421729385853\n",
            "40050 val_loss: 0.3226974308490753, train_loss: 0.0034556053578853607\n",
            "40060 val_loss: 0.3090120851993561, train_loss: 0.004313123878091574\n",
            "40070 val_loss: 0.357959508895874, train_loss: 0.004322920925915241\n",
            "40080 val_loss: 0.3537059426307678, train_loss: 0.004607192240655422\n",
            "40090 val_loss: 0.32943958044052124, train_loss: 0.0037501619663089514\n",
            "40100 val_loss: 0.34608179330825806, train_loss: 0.0035349789541214705\n",
            "40110 val_loss: 0.308698445558548, train_loss: 0.005238089710474014\n",
            "40120 val_loss: 0.33954352140426636, train_loss: 0.004716011229902506\n",
            "40130 val_loss: 0.3307041525840759, train_loss: 0.0032546850852668285\n",
            "40140 val_loss: 0.3401075601577759, train_loss: 0.003324599238112569\n",
            "40150 val_loss: 0.32572051882743835, train_loss: 0.003130985191091895\n",
            "40160 val_loss: 0.34225335717201233, train_loss: 0.0033580539748072624\n",
            "40170 val_loss: 0.33397114276885986, train_loss: 0.0032837807666510344\n",
            "40180 val_loss: 0.34795209765434265, train_loss: 0.003612872678786516\n",
            "40190 val_loss: 0.3720204830169678, train_loss: 0.0063044424168765545\n",
            "40200 val_loss: 0.3505919277667999, train_loss: 0.003681890433654189\n",
            "40210 val_loss: 0.28571200370788574, train_loss: 0.009735358878970146\n",
            "40220 val_loss: 0.35124024748802185, train_loss: 0.0045341504737734795\n",
            "40230 val_loss: 0.3202747702598572, train_loss: 0.004592602141201496\n",
            "40240 val_loss: 0.318486750125885, train_loss: 0.004541195463389158\n",
            "40250 val_loss: 0.36104628443717957, train_loss: 0.005025113932788372\n",
            "40260 val_loss: 0.3253380060195923, train_loss: 0.004069561138749123\n",
            "40270 val_loss: 0.33074602484703064, train_loss: 0.003942301496863365\n",
            "40280 val_loss: 0.4089078903198242, train_loss: 0.03300942853093147\n",
            "40290 val_loss: 0.25074541568756104, train_loss: 0.03125178441405296\n",
            "40300 val_loss: 0.259231299161911, train_loss: 0.01921331323683262\n",
            "40310 val_loss: 0.2553175389766693, train_loss: 0.01481882855296135\n",
            "40320 val_loss: 0.2537042200565338, train_loss: 0.012020159512758255\n",
            "40330 val_loss: 0.260407030582428, train_loss: 0.010939467698335648\n",
            "40340 val_loss: 0.2823827862739563, train_loss: 0.010421005077660084\n",
            "40350 val_loss: 0.28501275181770325, train_loss: 0.008396945893764496\n",
            "40360 val_loss: 0.31821343302726746, train_loss: 0.006223267875611782\n",
            "40370 val_loss: 0.30968567728996277, train_loss: 0.006196499336510897\n",
            "40380 val_loss: 0.30352503061294556, train_loss: 0.00531753757968545\n",
            "40390 val_loss: 0.3118537962436676, train_loss: 0.0045270794071257114\n",
            "40400 val_loss: 0.3113854229450226, train_loss: 0.005350825842469931\n",
            "40410 val_loss: 0.32266661524772644, train_loss: 0.00365283596329391\n",
            "40420 val_loss: 0.3486555814743042, train_loss: 0.00527764018625021\n",
            "40430 val_loss: 0.3107115626335144, train_loss: 0.00589413195848465\n",
            "40440 val_loss: 0.30667856335639954, train_loss: 0.004148118197917938\n",
            "40450 val_loss: 0.35148680210113525, train_loss: 0.004682105965912342\n",
            "40460 val_loss: 0.3223299980163574, train_loss: 0.004689235705882311\n",
            "40470 val_loss: 0.3268321454524994, train_loss: 0.003590081352740526\n",
            "40480 val_loss: 0.32095447182655334, train_loss: 0.0037948002573102713\n",
            "40490 val_loss: 0.3112768530845642, train_loss: 0.007853659801185131\n",
            "40500 val_loss: 0.33351725339889526, train_loss: 0.003487139707431197\n",
            "40510 val_loss: 0.37288355827331543, train_loss: 0.003906481899321079\n",
            "40520 val_loss: 0.32327795028686523, train_loss: 0.003813906339928508\n",
            "40530 val_loss: 0.3180275559425354, train_loss: 0.007429073099046946\n",
            "40540 val_loss: 0.32668137550354004, train_loss: 0.003929764498025179\n",
            "40550 val_loss: 0.3363038897514343, train_loss: 0.003718700259923935\n",
            "40560 val_loss: 0.31328368186950684, train_loss: 0.005178449209779501\n",
            "40570 val_loss: 0.34323763847351074, train_loss: 0.003719690488651395\n",
            "40580 val_loss: 0.32456958293914795, train_loss: 0.0037064410280436277\n",
            "40590 val_loss: 0.30687981843948364, train_loss: 0.0500715933740139\n",
            "40600 val_loss: 0.2736486792564392, train_loss: 0.022517863661050797\n",
            "40610 val_loss: 0.2955228090286255, train_loss: 0.01602817513048649\n",
            "40620 val_loss: 0.28986647725105286, train_loss: 0.013413039036095142\n",
            "40630 val_loss: 0.28326743841171265, train_loss: 0.011010685935616493\n",
            "40640 val_loss: 0.2851543724536896, train_loss: 0.009525369852781296\n",
            "40650 val_loss: 0.300974577665329, train_loss: 0.008516873233020306\n",
            "40660 val_loss: 0.29807373881340027, train_loss: 0.0069946045987308025\n",
            "40670 val_loss: 0.2956474721431732, train_loss: 0.006386852823197842\n",
            "40680 val_loss: 0.3308953642845154, train_loss: 0.006105910055339336\n",
            "40690 val_loss: 0.3718326985836029, train_loss: 0.010859731584787369\n",
            "40700 val_loss: 0.3099115788936615, train_loss: 0.004973077215254307\n",
            "40710 val_loss: 0.3441304564476013, train_loss: 0.005569505039602518\n",
            "40720 val_loss: 0.3318019211292267, train_loss: 0.00426069600507617\n",
            "40730 val_loss: 0.31202617287635803, train_loss: 0.004674108233302832\n",
            "40740 val_loss: 0.3172571361064911, train_loss: 0.004327879752963781\n",
            "40750 val_loss: 0.3354436755180359, train_loss: 0.006454648450016975\n",
            "40760 val_loss: 0.34890249371528625, train_loss: 0.004713268019258976\n",
            "40770 val_loss: 0.31705212593078613, train_loss: 0.0040295058861374855\n",
            "40780 val_loss: 0.3445502817630768, train_loss: 0.004018835723400116\n",
            "40790 val_loss: 0.32774391770362854, train_loss: 0.003783618099987507\n",
            "40800 val_loss: 0.3366466164588928, train_loss: 0.0036728570703417063\n",
            "40810 val_loss: 0.33055970072746277, train_loss: 0.0035811476409435272\n",
            "40820 val_loss: 0.3151126503944397, train_loss: 0.004255198873579502\n",
            "40830 val_loss: 0.3316706120967865, train_loss: 0.003432266181334853\n",
            "40840 val_loss: 0.3207816481590271, train_loss: 0.007568951230496168\n",
            "40850 val_loss: 0.3390252888202667, train_loss: 0.003765326691791415\n",
            "40860 val_loss: 0.40254005789756775, train_loss: 0.010865016840398312\n",
            "40870 val_loss: 0.3203320801258087, train_loss: 0.0038015383761376143\n",
            "40880 val_loss: 0.29938939213752747, train_loss: 0.006270720157772303\n",
            "40890 val_loss: 0.3159773349761963, train_loss: 0.004174248315393925\n",
            "40900 val_loss: 0.3182697594165802, train_loss: 0.006698644254356623\n",
            "40910 val_loss: 0.3203192353248596, train_loss: 0.003324613207951188\n",
            "40920 val_loss: 0.3062483072280884, train_loss: 0.003966455347836018\n",
            "40930 val_loss: 0.2969318926334381, train_loss: 0.006028125062584877\n",
            "40940 val_loss: 0.3258075714111328, train_loss: 0.0032306520733982325\n",
            "40950 val_loss: 0.33343982696533203, train_loss: 0.0033480715937912464\n",
            "40960 val_loss: 0.327078640460968, train_loss: 0.0036046048626303673\n",
            "40970 val_loss: 0.3292698264122009, train_loss: 0.0031879364978522062\n",
            "40980 val_loss: 0.3674459457397461, train_loss: 0.014786889776587486\n",
            "40990 val_loss: 0.3480515480041504, train_loss: 0.003858617041260004\n",
            "41000 val_loss: 0.35942786931991577, train_loss: 0.005694522522389889\n",
            "41010 val_loss: 0.3254103362560272, train_loss: 0.0036514163948595524\n",
            "41020 val_loss: 0.3178254961967468, train_loss: 0.0036040418781340122\n",
            "41030 val_loss: 0.3144075870513916, train_loss: 0.004433180205523968\n",
            "41040 val_loss: 0.31482449173927307, train_loss: 0.004567999392747879\n",
            "41050 val_loss: 0.31710517406463623, train_loss: 0.005451269447803497\n",
            "41060 val_loss: 0.33241790533065796, train_loss: 0.003158582141622901\n",
            "41070 val_loss: 0.3177645206451416, train_loss: 0.00490031111985445\n",
            "41080 val_loss: 0.29832690954208374, train_loss: 0.01100159902125597\n",
            "41090 val_loss: 0.3229578733444214, train_loss: 0.006200870033353567\n",
            "41100 val_loss: 0.38742393255233765, train_loss: 0.010640664957463741\n",
            "41110 val_loss: 0.34001559019088745, train_loss: 0.0031556037720292807\n",
            "41120 val_loss: 0.469771146774292, train_loss: 0.045688312500715256\n",
            "41130 val_loss: 0.3452520966529846, train_loss: 0.0037787940818816423\n",
            "41140 val_loss: 0.3611411452293396, train_loss: 0.004390638787299395\n",
            "41150 val_loss: 0.43627965450286865, train_loss: 0.014589742757380009\n",
            "41160 val_loss: 0.34464290738105774, train_loss: 0.003033676417544484\n",
            "41170 val_loss: 0.3488055467605591, train_loss: 0.0031889465171843767\n",
            "41180 val_loss: 0.32046017050743103, train_loss: 0.004311696160584688\n",
            "41190 val_loss: 0.36221981048583984, train_loss: 0.003713382640853524\n",
            "41200 val_loss: 0.3631802499294281, train_loss: 0.003931846935302019\n",
            "41210 val_loss: 0.32325032353401184, train_loss: 0.005033615976572037\n",
            "41220 val_loss: 0.3363659381866455, train_loss: 0.003983272705227137\n",
            "41230 val_loss: 0.3368515372276306, train_loss: 0.006179968826472759\n",
            "41240 val_loss: 0.3457282781600952, train_loss: 0.003179877297952771\n",
            "41250 val_loss: 0.3356892764568329, train_loss: 0.0031068436801433563\n",
            "41260 val_loss: 0.34102198481559753, train_loss: 0.003112336853519082\n",
            "41270 val_loss: 0.4006836712360382, train_loss: 0.017859289422631264\n",
            "41280 val_loss: 0.32384613156318665, train_loss: 0.0035706053022295237\n",
            "41290 val_loss: 0.32088160514831543, train_loss: 0.003885357640683651\n",
            "41300 val_loss: 0.39772114157676697, train_loss: 0.0033802820835262537\n",
            "41310 val_loss: 0.340686172246933, train_loss: 0.0029985166620463133\n",
            "41320 val_loss: 0.3564889430999756, train_loss: 0.003494762582704425\n",
            "41330 val_loss: 0.36190083622932434, train_loss: 0.0035738893784582615\n",
            "41340 val_loss: 0.3185564875602722, train_loss: 0.00447365315631032\n",
            "41350 val_loss: 0.3343815207481384, train_loss: 0.003378368681296706\n",
            "41360 val_loss: 0.4088685214519501, train_loss: 0.010101120918989182\n",
            "41370 val_loss: 0.33267563581466675, train_loss: 0.003197172423824668\n",
            "41380 val_loss: 0.3568469285964966, train_loss: 0.0036308341659605503\n",
            "41390 val_loss: 0.3284355103969574, train_loss: 0.0034321406856179237\n",
            "41400 val_loss: 0.33021074533462524, train_loss: 0.004527281038463116\n",
            "41410 val_loss: 0.33254769444465637, train_loss: 0.003052904037758708\n",
            "41420 val_loss: 0.3423731327056885, train_loss: 0.0031881146132946014\n",
            "41430 val_loss: 0.33454659581184387, train_loss: 0.0033966312184929848\n",
            "41440 val_loss: 0.3339398503303528, train_loss: 0.0034544672816991806\n",
            "41450 val_loss: 0.33809030055999756, train_loss: 0.0032624343875795603\n",
            "41460 val_loss: 0.3024818003177643, train_loss: 0.010913670063018799\n",
            "41470 val_loss: 0.34987369179725647, train_loss: 0.0034700236283242702\n",
            "41480 val_loss: 0.35674673318862915, train_loss: 0.004042241256684065\n",
            "41490 val_loss: 0.3438124656677246, train_loss: 0.005199769977480173\n",
            "41500 val_loss: 0.3677515685558319, train_loss: 0.004343067295849323\n",
            "41510 val_loss: 0.3488663136959076, train_loss: 0.0040655420161783695\n",
            "41520 val_loss: 0.36058974266052246, train_loss: 0.004633708391338587\n",
            "41530 val_loss: 0.35443001985549927, train_loss: 0.0034672264009714127\n",
            "41540 val_loss: 0.34477096796035767, train_loss: 0.004549768753349781\n",
            "41550 val_loss: 0.34567582607269287, train_loss: 0.005433541722595692\n",
            "41560 val_loss: 0.3767111301422119, train_loss: 0.005681368988007307\n",
            "41570 val_loss: 0.42069441080093384, train_loss: 0.011509871110320091\n",
            "41580 val_loss: 0.3800758719444275, train_loss: 0.005263322498649359\n",
            "41590 val_loss: 0.3614330291748047, train_loss: 0.003346688812598586\n",
            "41600 val_loss: 0.35642576217651367, train_loss: 0.002946475287899375\n",
            "41610 val_loss: 0.36845260858535767, train_loss: 0.005240457598119974\n",
            "41620 val_loss: 0.3591921329498291, train_loss: 0.0031891316175460815\n",
            "41630 val_loss: 0.33595797419548035, train_loss: 0.0034088403917849064\n",
            "41640 val_loss: 0.3450205326080322, train_loss: 0.003126495983451605\n",
            "41650 val_loss: 0.33511051535606384, train_loss: 0.003598257899284363\n",
            "41660 val_loss: 0.3663537800312042, train_loss: 0.00861053355038166\n",
            "41670 val_loss: 0.3513675332069397, train_loss: 0.003539547324180603\n",
            "41680 val_loss: 0.34495019912719727, train_loss: 0.003805065294727683\n",
            "41690 val_loss: 0.3341481685638428, train_loss: 0.003358927322551608\n",
            "41700 val_loss: 0.45846810936927795, train_loss: 0.017459183931350708\n",
            "41710 val_loss: 0.3388059735298157, train_loss: 0.004618922248482704\n",
            "41720 val_loss: 0.33524784445762634, train_loss: 0.0029059727676212788\n",
            "41730 val_loss: 0.3473803400993347, train_loss: 0.003055491019040346\n",
            "41740 val_loss: 0.49691981077194214, train_loss: 0.02583269774913788\n",
            "41750 val_loss: 0.32665789127349854, train_loss: 0.005124774295836687\n",
            "41760 val_loss: 0.33926719427108765, train_loss: 0.004492213949561119\n",
            "41770 val_loss: 0.3828446567058563, train_loss: 0.005441776942461729\n",
            "41780 val_loss: 0.3507267236709595, train_loss: 0.0030935078393667936\n",
            "41790 val_loss: 0.33739131689071655, train_loss: 0.0033382654655724764\n",
            "41800 val_loss: 0.3491404950618744, train_loss: 0.0028455595020204782\n",
            "41810 val_loss: 0.3688676357269287, train_loss: 0.003600088879466057\n",
            "41820 val_loss: 0.3853447735309601, train_loss: 0.0028181651141494513\n",
            "41830 val_loss: 0.32241931557655334, train_loss: 0.004243703093379736\n",
            "41840 val_loss: 0.3591357469558716, train_loss: 0.006341930478811264\n",
            "41850 val_loss: 0.3455188274383545, train_loss: 0.0035453843884170055\n",
            "41860 val_loss: 0.34889084100723267, train_loss: 0.0031594960018992424\n",
            "41870 val_loss: 0.32478368282318115, train_loss: 0.006682165432721376\n",
            "41880 val_loss: 0.336500883102417, train_loss: 0.003109132871031761\n",
            "41890 val_loss: 0.35897260904312134, train_loss: 0.01648498699069023\n",
            "41900 val_loss: 0.3311116695404053, train_loss: 0.0037535366136580706\n",
            "41910 val_loss: 0.3366866409778595, train_loss: 0.003086739918217063\n",
            "41920 val_loss: 0.3262661397457123, train_loss: 0.005968243349343538\n",
            "41930 val_loss: 0.34927186369895935, train_loss: 0.0028781997971236706\n",
            "41940 val_loss: 0.40802130103111267, train_loss: 0.0030340005178004503\n",
            "41950 val_loss: 0.3602152466773987, train_loss: 0.0031305779702961445\n",
            "41960 val_loss: 0.3372781574726105, train_loss: 0.0031884547788649797\n",
            "41970 val_loss: 0.6093764305114746, train_loss: 0.0717499703168869\n",
            "41980 val_loss: 0.34486204385757446, train_loss: 0.0035803914070129395\n",
            "41990 val_loss: 0.3581518530845642, train_loss: 0.0036475288216024637\n",
            "42000 val_loss: 0.3628857135772705, train_loss: 0.004225069656968117\n",
            "42010 val_loss: 0.35221561789512634, train_loss: 0.00309991673566401\n",
            "42020 val_loss: 0.33495935797691345, train_loss: 0.003757220460101962\n",
            "42030 val_loss: 0.3454514145851135, train_loss: 0.006379925645887852\n",
            "42040 val_loss: 0.3658641278743744, train_loss: 0.0027997689321637154\n",
            "42050 val_loss: 0.35212281346321106, train_loss: 0.0029922467656433582\n",
            "42060 val_loss: 0.349957138299942, train_loss: 0.002930658869445324\n",
            "42070 val_loss: 0.3371807634830475, train_loss: 0.0032228061463683844\n",
            "42080 val_loss: 0.3524334728717804, train_loss: 0.0028943591751158237\n",
            "42090 val_loss: 0.3599162697792053, train_loss: 0.0033325902186334133\n",
            "42100 val_loss: 0.33809489011764526, train_loss: 0.008273341692984104\n",
            "42110 val_loss: 0.3524196743965149, train_loss: 0.0029211672954261303\n",
            "42120 val_loss: 0.3284529447555542, train_loss: 0.004465253558009863\n",
            "42130 val_loss: 0.3550598621368408, train_loss: 0.0032398432958871126\n",
            "42140 val_loss: 0.3887980282306671, train_loss: 0.005934258457273245\n",
            "42150 val_loss: 0.32377132773399353, train_loss: 0.007785513531416655\n",
            "42160 val_loss: 0.3945362865924835, train_loss: 0.007553464267402887\n",
            "42170 val_loss: 0.3408340513706207, train_loss: 0.0034385414328426123\n",
            "42180 val_loss: 0.32467180490493774, train_loss: 0.003879702417179942\n",
            "42190 val_loss: 0.3436289429664612, train_loss: 0.0030574880074709654\n",
            "42200 val_loss: 0.35468968749046326, train_loss: 0.002845245646312833\n",
            "42210 val_loss: 0.3773614466190338, train_loss: 0.004885080736130476\n",
            "42220 val_loss: 0.3407898545265198, train_loss: 0.0029125374276190996\n",
            "42230 val_loss: 0.33278489112854004, train_loss: 0.003978225868195295\n",
            "42240 val_loss: 0.3337639272212982, train_loss: 0.0036432514898478985\n",
            "42250 val_loss: 0.3568633496761322, train_loss: 0.002800310030579567\n",
            "42260 val_loss: 0.324483722448349, train_loss: 0.004283851943910122\n",
            "42270 val_loss: 0.424321711063385, train_loss: 0.010578450746834278\n",
            "42280 val_loss: 0.32476329803466797, train_loss: 0.005606585647910833\n",
            "42290 val_loss: 0.3315501809120178, train_loss: 0.003850641194730997\n",
            "42300 val_loss: 0.36619293689727783, train_loss: 0.003246442647650838\n",
            "42310 val_loss: 0.349081814289093, train_loss: 0.0026609261985868216\n",
            "42320 val_loss: 0.3346995711326599, train_loss: 0.004296264611184597\n",
            "42330 val_loss: 0.3549918830394745, train_loss: 0.003330362495034933\n",
            "42340 val_loss: 0.35686060786247253, train_loss: 0.0027608058881014585\n",
            "42350 val_loss: 0.3540685772895813, train_loss: 0.0027023348957300186\n",
            "42360 val_loss: 0.36617782711982727, train_loss: 0.013548292219638824\n",
            "42370 val_loss: 0.3372234106063843, train_loss: 0.004790851380676031\n",
            "42380 val_loss: 0.38146546483039856, train_loss: 0.003006529761478305\n",
            "42390 val_loss: 0.3707047998905182, train_loss: 0.002842356450855732\n",
            "42400 val_loss: 0.37186476588249207, train_loss: 0.002920532366260886\n",
            "42410 val_loss: 0.35786882042884827, train_loss: 0.002896274207159877\n",
            "42420 val_loss: 0.36274704337120056, train_loss: 0.002888117916882038\n",
            "42430 val_loss: 0.39448702335357666, train_loss: 0.017962709069252014\n",
            "42440 val_loss: 0.34419527649879456, train_loss: 0.0034385849721729755\n",
            "42450 val_loss: 0.3544121980667114, train_loss: 0.002738919807597995\n",
            "42460 val_loss: 0.3352125287055969, train_loss: 0.005192944779992104\n",
            "42470 val_loss: 0.3778161406517029, train_loss: 0.003337681293487549\n",
            "42480 val_loss: 0.3739694356918335, train_loss: 0.0026867978740483522\n",
            "42490 val_loss: 0.39354705810546875, train_loss: 0.005447100847959518\n",
            "42500 val_loss: 0.3408728241920471, train_loss: 0.002921701641753316\n",
            "42510 val_loss: 0.34760040044784546, train_loss: 0.002732050372287631\n",
            "42520 val_loss: 0.35533493757247925, train_loss: 0.0026390203274786472\n",
            "42530 val_loss: 0.3627757132053375, train_loss: 0.003575175069272518\n",
            "42540 val_loss: 0.39315828680992126, train_loss: 0.005519818514585495\n",
            "42550 val_loss: 0.3899874985218048, train_loss: 0.004638697020709515\n",
            "42560 val_loss: 0.3415026068687439, train_loss: 0.00483235577121377\n",
            "42570 val_loss: 0.331382691860199, train_loss: 0.00616110535338521\n",
            "42580 val_loss: 0.35642653703689575, train_loss: 0.002602351363748312\n",
            "42590 val_loss: 0.3433834910392761, train_loss: 0.003942761570215225\n",
            "42600 val_loss: 0.3537793755531311, train_loss: 0.013623821549117565\n",
            "42610 val_loss: 0.3498024046421051, train_loss: 0.003128047101199627\n",
            "42620 val_loss: 0.36658957600593567, train_loss: 0.0028596948832273483\n",
            "42630 val_loss: 0.39610517024993896, train_loss: 0.004577774088829756\n",
            "42640 val_loss: 0.33139723539352417, train_loss: 0.004953637253493071\n",
            "42650 val_loss: 0.36192935705184937, train_loss: 0.0025528136175125837\n",
            "42660 val_loss: 0.3938557207584381, train_loss: 0.004934997763484716\n",
            "42670 val_loss: 0.3349476456642151, train_loss: 0.009523043408989906\n",
            "42680 val_loss: 0.35549578070640564, train_loss: 0.003174965502694249\n",
            "42690 val_loss: 0.361043244600296, train_loss: 0.003891699481755495\n",
            "42700 val_loss: 0.32648783922195435, train_loss: 0.0037779761478304863\n",
            "42710 val_loss: 0.3404148817062378, train_loss: 0.0028374134562909603\n",
            "42720 val_loss: 0.3545092046260834, train_loss: 0.006477769464254379\n",
            "42730 val_loss: 0.35492920875549316, train_loss: 0.0027251997962594032\n",
            "42740 val_loss: 0.33733201026916504, train_loss: 0.0034020033199340105\n",
            "42750 val_loss: 0.32826438546180725, train_loss: 0.010468777269124985\n",
            "42760 val_loss: 0.34525761008262634, train_loss: 0.0027197860181331635\n",
            "42770 val_loss: 0.3445509374141693, train_loss: 0.002652455121278763\n",
            "42780 val_loss: 0.34643980860710144, train_loss: 0.0027594936545938253\n",
            "42790 val_loss: 0.41598838567733765, train_loss: 0.007019958458840847\n",
            "42800 val_loss: 0.3477678894996643, train_loss: 0.00278695416636765\n",
            "42810 val_loss: 0.3671160638332367, train_loss: 0.0025267365854233503\n",
            "42820 val_loss: 0.3546348512172699, train_loss: 0.01680641435086727\n",
            "42830 val_loss: 0.34569430351257324, train_loss: 0.0027074390091001987\n",
            "42840 val_loss: 0.4215206801891327, train_loss: 0.0026608838234096766\n",
            "42850 val_loss: 0.41052931547164917, train_loss: 0.002474808832630515\n",
            "42860 val_loss: 0.35413920879364014, train_loss: 0.0026477226056158543\n",
            "42870 val_loss: 0.3796764314174652, train_loss: 0.003539921483024955\n",
            "42880 val_loss: 0.3619650900363922, train_loss: 0.0026577888056635857\n",
            "42890 val_loss: 0.34538641571998596, train_loss: 0.003533851820975542\n",
            "42900 val_loss: 0.4349062740802765, train_loss: 0.01393789704889059\n",
            "42910 val_loss: 0.3693197965621948, train_loss: 0.0025026348885148764\n",
            "42920 val_loss: 0.3779708445072174, train_loss: 0.0034115086309611797\n",
            "42930 val_loss: 0.3712041974067688, train_loss: 0.003126309486106038\n",
            "42940 val_loss: 0.3368806540966034, train_loss: 0.0033213270362466574\n",
            "42950 val_loss: 0.3494894206523895, train_loss: 0.0027317889034748077\n",
            "42960 val_loss: 0.34799009561538696, train_loss: 0.0028077152092009783\n",
            "42970 val_loss: 0.34947139024734497, train_loss: 0.011689280159771442\n",
            "42980 val_loss: 0.3493521213531494, train_loss: 0.002800745889544487\n",
            "42990 val_loss: 0.3877710998058319, train_loss: 0.0037767142057418823\n",
            "43000 val_loss: 0.38000383973121643, train_loss: 0.0028237553779035807\n",
            "43010 val_loss: 0.3988242447376251, train_loss: 0.005538082215934992\n",
            "43020 val_loss: 0.37088415026664734, train_loss: 0.0029407721012830734\n",
            "43030 val_loss: 0.35867032408714294, train_loss: 0.002715078881010413\n",
            "43040 val_loss: 0.342213898897171, train_loss: 0.003429990028962493\n",
            "43050 val_loss: 0.37311577796936035, train_loss: 0.0027440472040325403\n",
            "43060 val_loss: 0.3663375675678253, train_loss: 0.002577700186520815\n",
            "43070 val_loss: 0.3638874590396881, train_loss: 0.002714385511353612\n",
            "43080 val_loss: 0.36527061462402344, train_loss: 0.005123929586261511\n",
            "43090 val_loss: 0.3670693039894104, train_loss: 0.002438403433188796\n",
            "43100 val_loss: 0.38679584860801697, train_loss: 0.003573337569832802\n",
            "43110 val_loss: 0.3630339205265045, train_loss: 0.0028883281629532576\n",
            "43120 val_loss: 0.3754575848579407, train_loss: 0.0032373806461691856\n",
            "43130 val_loss: 0.3794322609901428, train_loss: 0.0034324994776397943\n",
            "43140 val_loss: 0.3655121922492981, train_loss: 0.002662057988345623\n",
            "43150 val_loss: 0.3891269564628601, train_loss: 0.0037571184802800417\n",
            "43160 val_loss: 0.36478352546691895, train_loss: 0.003488856367766857\n",
            "43170 val_loss: 0.3849906027317047, train_loss: 0.003279163734987378\n",
            "43180 val_loss: 0.37142226099967957, train_loss: 0.0025682495906949043\n",
            "43190 val_loss: 0.39138326048851013, train_loss: 0.005777706392109394\n",
            "43200 val_loss: 0.37170517444610596, train_loss: 0.0038050927687436342\n",
            "43210 val_loss: 0.3671998381614685, train_loss: 0.002731539076194167\n",
            "43220 val_loss: 0.37794479727745056, train_loss: 0.0025186799466609955\n",
            "43230 val_loss: 0.36354345083236694, train_loss: 0.0026089658495038748\n",
            "43240 val_loss: 0.34659770131111145, train_loss: 0.004944283049553633\n",
            "43250 val_loss: 0.3459349572658539, train_loss: 0.003917694091796875\n",
            "43260 val_loss: 0.37320476770401, train_loss: 0.002580852247774601\n",
            "43270 val_loss: 0.34846287965774536, train_loss: 0.003375634551048279\n",
            "43280 val_loss: 0.346174955368042, train_loss: 0.006091555580496788\n",
            "43290 val_loss: 0.40991243720054626, train_loss: 0.005986152682453394\n",
            "43300 val_loss: 0.337056964635849, train_loss: 0.004388315603137016\n",
            "43310 val_loss: 0.3925023674964905, train_loss: 0.0030441435519605875\n",
            "43320 val_loss: 0.4575088918209076, train_loss: 0.013688147999346256\n",
            "43330 val_loss: 0.35286736488342285, train_loss: 0.003416737774387002\n",
            "43340 val_loss: 0.35854512453079224, train_loss: 0.0030137549620121717\n",
            "43350 val_loss: 0.364574670791626, train_loss: 0.0027115531265735626\n",
            "43360 val_loss: 0.3680914342403412, train_loss: 0.002557002240791917\n",
            "43370 val_loss: 0.364604115486145, train_loss: 0.0026694657281041145\n",
            "43380 val_loss: 0.35004478693008423, train_loss: 0.003157269209623337\n",
            "43390 val_loss: 0.37524542212486267, train_loss: 0.0029635594692081213\n",
            "43400 val_loss: 0.38106581568717957, train_loss: 0.009662438184022903\n",
            "43410 val_loss: 0.4151451885700226, train_loss: 0.013307320885360241\n",
            "43420 val_loss: 0.39101651310920715, train_loss: 0.009046867489814758\n",
            "43430 val_loss: 0.36382630467414856, train_loss: 0.0029516983777284622\n",
            "43440 val_loss: 0.3646554946899414, train_loss: 0.0026296605356037617\n",
            "43450 val_loss: 0.36214351654052734, train_loss: 0.0026075253263115883\n",
            "43460 val_loss: 0.3787885010242462, train_loss: 0.0028422968462109566\n",
            "43470 val_loss: 0.4910131096839905, train_loss: 0.01769561693072319\n",
            "43480 val_loss: 0.3651014268398285, train_loss: 0.0024493939708918333\n",
            "43490 val_loss: 0.38247862458229065, train_loss: 0.0034283713903278112\n",
            "43500 val_loss: 0.41890862584114075, train_loss: 0.007513648830354214\n",
            "43510 val_loss: 0.43129444122314453, train_loss: 0.009572247043251991\n",
            "43520 val_loss: 0.4064226746559143, train_loss: 0.0062066554091870785\n",
            "43530 val_loss: 0.3768661916255951, train_loss: 0.012259352020919323\n",
            "43540 val_loss: 0.3640051782131195, train_loss: 0.00509805278852582\n",
            "43550 val_loss: 0.3501032590866089, train_loss: 0.004159558564424515\n",
            "43560 val_loss: 0.3764638900756836, train_loss: 0.0029851344879716635\n",
            "43570 val_loss: 0.35238927602767944, train_loss: 0.002790525322780013\n",
            "43580 val_loss: 0.32355624437332153, train_loss: 0.01078981626778841\n",
            "43590 val_loss: 0.38064974546432495, train_loss: 0.005271377507597208\n",
            "43600 val_loss: 0.38786107301712036, train_loss: 0.004665588028728962\n",
            "43610 val_loss: 0.35891956090927124, train_loss: 0.0032546648290008307\n",
            "43620 val_loss: 0.3401639759540558, train_loss: 0.003582283155992627\n",
            "43630 val_loss: 0.3585880994796753, train_loss: 0.002570474287495017\n",
            "43640 val_loss: 0.34353190660476685, train_loss: 0.004451902117580175\n",
            "43650 val_loss: 0.39526262879371643, train_loss: 0.0023938152007758617\n",
            "43660 val_loss: 0.3807206451892853, train_loss: 0.0023709777742624283\n",
            "43670 val_loss: 0.5616757273674011, train_loss: 0.03520616888999939\n",
            "43680 val_loss: 0.3739599287509918, train_loss: 0.003010508604347706\n",
            "43690 val_loss: 0.3915809392929077, train_loss: 0.016824061051011086\n",
            "43700 val_loss: 0.4228234589099884, train_loss: 0.006113127805292606\n",
            "43710 val_loss: 0.39148852229118347, train_loss: 0.0035056648775935173\n",
            "43720 val_loss: 0.6426244974136353, train_loss: 0.06915879994630814\n",
            "43730 val_loss: 0.37631621956825256, train_loss: 0.005827088840305805\n",
            "43740 val_loss: 0.3623291552066803, train_loss: 0.002665234263986349\n",
            "43750 val_loss: 0.35351070761680603, train_loss: 0.0024875656235963106\n",
            "43760 val_loss: 0.3395279347896576, train_loss: 0.003921034280210733\n",
            "43770 val_loss: 0.34973856806755066, train_loss: 0.0030383337289094925\n",
            "43780 val_loss: 0.39697957038879395, train_loss: 0.004568823613226414\n",
            "43790 val_loss: 0.373308926820755, train_loss: 0.002602298278361559\n",
            "43800 val_loss: 0.3754757344722748, train_loss: 0.0029733083210885525\n",
            "43810 val_loss: 0.3458094000816345, train_loss: 0.003486339468508959\n",
            "43820 val_loss: 0.3605304956436157, train_loss: 0.002702905796468258\n",
            "43830 val_loss: 0.3683614730834961, train_loss: 0.0026512572076171637\n",
            "43840 val_loss: 0.36270013451576233, train_loss: 0.012968599796295166\n",
            "43850 val_loss: 0.39828115701675415, train_loss: 0.00436430936679244\n",
            "43860 val_loss: 0.35525575280189514, train_loss: 0.002612108364701271\n",
            "43870 val_loss: 0.35531845688819885, train_loss: 0.0031125489622354507\n",
            "43880 val_loss: 0.3924243450164795, train_loss: 0.0026628035120666027\n",
            "43890 val_loss: 0.3774186670780182, train_loss: 0.0025171127635985613\n",
            "43900 val_loss: 0.37163853645324707, train_loss: 0.0029367608949542046\n",
            "43910 val_loss: 0.37291160225868225, train_loss: 0.003389063524082303\n",
            "43920 val_loss: 0.3823864459991455, train_loss: 0.002671198220923543\n",
            "43930 val_loss: 0.3468419909477234, train_loss: 0.0036392859183251858\n",
            "43940 val_loss: 0.37827590107917786, train_loss: 0.002823729533702135\n",
            "43950 val_loss: 0.34820687770843506, train_loss: 0.00361454114317894\n",
            "43960 val_loss: 0.37123897671699524, train_loss: 0.0033439083490520716\n",
            "43970 val_loss: 0.36613067984580994, train_loss: 0.002668327186256647\n",
            "43980 val_loss: 0.4228920340538025, train_loss: 0.016169831156730652\n",
            "43990 val_loss: 0.39859262108802795, train_loss: 0.005230442155152559\n",
            "44000 val_loss: 0.37140440940856934, train_loss: 0.002682019956409931\n",
            "44010 val_loss: 0.3645346760749817, train_loss: 0.003286316990852356\n",
            "44020 val_loss: 0.368914932012558, train_loss: 0.002698047086596489\n",
            "44030 val_loss: 0.3850201964378357, train_loss: 0.0028067640960216522\n",
            "44040 val_loss: 0.352682501077652, train_loss: 0.0062248012982308865\n",
            "44050 val_loss: 0.4136664867401123, train_loss: 0.005213727708905935\n",
            "44060 val_loss: 0.3869161009788513, train_loss: 0.004206431098282337\n",
            "44070 val_loss: 0.370033323764801, train_loss: 0.0034900822211056948\n",
            "44080 val_loss: 0.3745456337928772, train_loss: 0.002362880390137434\n",
            "44090 val_loss: 0.4294032156467438, train_loss: 0.006946394685655832\n",
            "44100 val_loss: 0.3779367506504059, train_loss: 0.0027430597692728043\n",
            "44110 val_loss: 0.35139814019203186, train_loss: 0.0031948487740010023\n",
            "44120 val_loss: 0.4089151620864868, train_loss: 0.017646413296461105\n",
            "44130 val_loss: 0.35043075680732727, train_loss: 0.002968523185700178\n",
            "44140 val_loss: 0.3585089147090912, train_loss: 0.0026434112805873156\n",
            "44150 val_loss: 0.36175650358200073, train_loss: 0.002542504109442234\n",
            "44160 val_loss: 0.3952876925468445, train_loss: 0.003207217901945114\n",
            "44170 val_loss: 0.3672393560409546, train_loss: 0.002803235547617078\n",
            "44180 val_loss: 0.3739721477031708, train_loss: 0.0025696121156215668\n",
            "44190 val_loss: 0.345546156167984, train_loss: 0.0048678237944841385\n",
            "44200 val_loss: 0.4048900008201599, train_loss: 0.010234174318611622\n",
            "44210 val_loss: 0.37106817960739136, train_loss: 0.0022337553091347218\n",
            "44220 val_loss: 0.359965980052948, train_loss: 0.013320648111402988\n",
            "44230 val_loss: 0.37157633900642395, train_loss: 0.014489038847386837\n",
            "44240 val_loss: 0.3719433844089508, train_loss: 0.0032984756398946047\n",
            "44250 val_loss: 0.37164580821990967, train_loss: 0.002364558633416891\n",
            "44260 val_loss: 0.36509019136428833, train_loss: 0.0023572174832224846\n",
            "44270 val_loss: 0.35271763801574707, train_loss: 0.005718396510928869\n",
            "44280 val_loss: 0.35611391067504883, train_loss: 0.01102511864155531\n",
            "44290 val_loss: 0.35529109835624695, train_loss: 0.0032501323148608208\n",
            "44300 val_loss: 0.39715585112571716, train_loss: 0.0032498340588063\n",
            "44310 val_loss: 0.36906686425209045, train_loss: 0.0069253998808562756\n",
            "44320 val_loss: 0.3799343705177307, train_loss: 0.0021986686624586582\n",
            "44330 val_loss: 0.3881215453147888, train_loss: 0.0031251937616616488\n",
            "44340 val_loss: 0.38977935910224915, train_loss: 0.0031212028115987778\n",
            "44350 val_loss: 0.4061122238636017, train_loss: 0.005342415533959866\n",
            "44360 val_loss: 0.4002501666545868, train_loss: 0.02719717286527157\n",
            "44370 val_loss: 0.3314298987388611, train_loss: 0.006566444877535105\n",
            "44380 val_loss: 0.3542785346508026, train_loss: 0.0027110627852380276\n",
            "44390 val_loss: 0.3577307164669037, train_loss: 0.0027021938003599644\n",
            "44400 val_loss: 0.3540138602256775, train_loss: 0.009110821411013603\n",
            "44410 val_loss: 0.3626834750175476, train_loss: 0.002429637126624584\n",
            "44420 val_loss: 0.43626630306243896, train_loss: 0.009607838466763496\n",
            "44430 val_loss: 0.3645778298377991, train_loss: 0.0025360507424920797\n",
            "44440 val_loss: 0.36159050464630127, train_loss: 0.007683865260332823\n",
            "44450 val_loss: 0.36729511618614197, train_loss: 0.0045055062510073185\n",
            "44460 val_loss: 0.40685445070266724, train_loss: 0.017726844176650047\n",
            "44470 val_loss: 0.39199239015579224, train_loss: 0.0026018174830824137\n",
            "44480 val_loss: 0.38507792353630066, train_loss: 0.0028113166335970163\n",
            "44490 val_loss: 0.3621905744075775, train_loss: 0.011511790566146374\n",
            "44500 val_loss: 0.38502761721611023, train_loss: 0.0027290084399282932\n",
            "44510 val_loss: 0.3545132875442505, train_loss: 0.009828073903918266\n",
            "44520 val_loss: 0.3708323538303375, train_loss: 0.002509806538000703\n",
            "44530 val_loss: 0.47335296869277954, train_loss: 0.017797043547034264\n",
            "44540 val_loss: 0.35797393321990967, train_loss: 0.002734527224674821\n",
            "44550 val_loss: 0.35857290029525757, train_loss: 0.002703883918002248\n",
            "44560 val_loss: 0.44349971413612366, train_loss: 0.010472811758518219\n",
            "44570 val_loss: 0.35712969303131104, train_loss: 0.003937709145247936\n",
            "44580 val_loss: 0.38543701171875, train_loss: 0.002981547499075532\n",
            "44590 val_loss: 0.3689475655555725, train_loss: 0.002531144767999649\n",
            "44600 val_loss: 0.36613813042640686, train_loss: 0.014496480114758015\n",
            "44610 val_loss: 0.3591850697994232, train_loss: 0.0029934707563370466\n",
            "44620 val_loss: 0.46713370084762573, train_loss: 0.012884089723229408\n",
            "44630 val_loss: 0.37571918964385986, train_loss: 0.0024952867534011602\n",
            "44640 val_loss: 0.3804084062576294, train_loss: 0.0028712842613458633\n",
            "44650 val_loss: 0.3832551836967468, train_loss: 0.002179518109187484\n",
            "44660 val_loss: 0.39193350076675415, train_loss: 0.0025504091754555702\n",
            "44670 val_loss: 0.39870190620422363, train_loss: 0.002157824579626322\n",
            "44680 val_loss: 0.38823559880256653, train_loss: 0.004849380347877741\n",
            "44690 val_loss: 0.37749943137168884, train_loss: 0.0020677971187978983\n",
            "44700 val_loss: 0.37602248787879944, train_loss: 0.002036557300016284\n",
            "44710 val_loss: 0.370216965675354, train_loss: 0.0024621111806482077\n",
            "44720 val_loss: 0.3643709719181061, train_loss: 0.002633275929838419\n",
            "44730 val_loss: 0.5002261400222778, train_loss: 0.04022732749581337\n",
            "44740 val_loss: 0.4237089157104492, train_loss: 0.00954420492053032\n",
            "44750 val_loss: 0.39866527915000916, train_loss: 0.002201808150857687\n",
            "44760 val_loss: 0.39808258414268494, train_loss: 0.002971345093101263\n",
            "44770 val_loss: 0.3930090069770813, train_loss: 0.0024794950149953365\n",
            "44780 val_loss: 0.37798523902893066, train_loss: 0.003467775648459792\n",
            "44790 val_loss: 0.38692307472229004, train_loss: 0.0022968309931457043\n",
            "44800 val_loss: 0.4054640829563141, train_loss: 0.00999209750443697\n",
            "44810 val_loss: 0.39063239097595215, train_loss: 0.0026754974387586117\n",
            "44820 val_loss: 0.3810651898384094, train_loss: 0.0034667826257646084\n",
            "44830 val_loss: 0.3624292016029358, train_loss: 0.0030415840446949005\n",
            "44840 val_loss: 0.34455960988998413, train_loss: 0.012072090059518814\n",
            "44850 val_loss: 0.3687429130077362, train_loss: 0.0025098430924117565\n",
            "44860 val_loss: 0.3586103022098541, train_loss: 0.00384544744156301\n",
            "44870 val_loss: 0.3985464572906494, train_loss: 0.0034885236527770758\n",
            "44880 val_loss: 0.36830803751945496, train_loss: 0.002486188430339098\n",
            "44890 val_loss: 0.27330413460731506, train_loss: 0.025658700615167618\n",
            "44900 val_loss: 0.3644905388355255, train_loss: 0.003374026855453849\n",
            "44910 val_loss: 0.3672937750816345, train_loss: 0.002927485154941678\n",
            "44920 val_loss: 0.3591136336326599, train_loss: 0.004574873019009829\n",
            "44930 val_loss: 0.3673974573612213, train_loss: 0.0028247637674212456\n",
            "44940 val_loss: 0.35565462708473206, train_loss: 0.0035232019145041704\n",
            "44950 val_loss: 0.35438138246536255, train_loss: 0.0037948081735521555\n",
            "44960 val_loss: 0.3999989926815033, train_loss: 0.004320132080465555\n",
            "44970 val_loss: 0.3699728548526764, train_loss: 0.0025437178555876017\n",
            "44980 val_loss: 0.4506852328777313, train_loss: 0.014479112811386585\n",
            "44990 val_loss: 0.40574005246162415, train_loss: 0.0026300502941012383\n",
            "45000 val_loss: 0.4000146985054016, train_loss: 0.002612209180369973\n",
            "45010 val_loss: 0.3810913562774658, train_loss: 0.0024399850517511368\n",
            "45020 val_loss: 0.3872179388999939, train_loss: 0.002226300071924925\n",
            "45030 val_loss: 0.3804611265659332, train_loss: 0.0026972691994160414\n",
            "45040 val_loss: 0.3926677703857422, train_loss: 0.0024526729248464108\n",
            "45050 val_loss: 0.3840998709201813, train_loss: 0.002156528178602457\n",
            "45060 val_loss: 0.38807588815689087, train_loss: 0.0024049452040344477\n",
            "45070 val_loss: 0.41504740715026855, train_loss: 0.019460853189229965\n",
            "45080 val_loss: 0.3713896572589874, train_loss: 0.002945106942206621\n",
            "45090 val_loss: 0.3812009394168854, train_loss: 0.00239090109243989\n",
            "45100 val_loss: 0.3694828450679779, train_loss: 0.002450454980134964\n",
            "45110 val_loss: 0.3798987567424774, train_loss: 0.002132927067577839\n",
            "45120 val_loss: 0.3525236248970032, train_loss: 0.006621195934712887\n",
            "45130 val_loss: 0.37639573216438293, train_loss: 0.0022012575063854456\n",
            "45140 val_loss: 0.400640070438385, train_loss: 0.0025358933489769697\n",
            "45150 val_loss: 0.37949585914611816, train_loss: 0.0021238569170236588\n",
            "45160 val_loss: 0.3971264362335205, train_loss: 0.0020481704268604517\n",
            "45170 val_loss: 0.39449822902679443, train_loss: 0.012723748572170734\n",
            "45180 val_loss: 0.3883814513683319, train_loss: 0.013817299157381058\n",
            "45190 val_loss: 0.503629744052887, train_loss: 0.016960104927420616\n",
            "45200 val_loss: 0.4573073983192444, train_loss: 0.010737414471805096\n",
            "45210 val_loss: 0.3894500136375427, train_loss: 0.0022702207788825035\n",
            "45220 val_loss: 0.4054586887359619, train_loss: 0.0021136929281055927\n",
            "45230 val_loss: 0.3972459137439728, train_loss: 0.0022410855162888765\n",
            "45240 val_loss: 0.38285568356513977, train_loss: 0.0025017124135047197\n",
            "45250 val_loss: 0.3864786624908447, train_loss: 0.0023634962271898985\n",
            "45260 val_loss: 0.36066365242004395, train_loss: 0.003655898617580533\n",
            "45270 val_loss: 0.36759427189826965, train_loss: 0.0027363004628568888\n",
            "45280 val_loss: 0.3961547315120697, train_loss: 0.002146031241863966\n",
            "45290 val_loss: 0.3843691349029541, train_loss: 0.002559603890404105\n",
            "45300 val_loss: 0.38867706060409546, train_loss: 0.0023502414114773273\n",
            "45310 val_loss: 0.38606157898902893, train_loss: 0.002945819403976202\n",
            "45320 val_loss: 0.41972070932388306, train_loss: 0.004564732778817415\n",
            "45330 val_loss: 0.37201371788978577, train_loss: 0.002860556123778224\n",
            "45340 val_loss: 0.42783719301223755, train_loss: 0.0056936247274279594\n",
            "45350 val_loss: 0.40802568197250366, train_loss: 0.004236368928104639\n",
            "45360 val_loss: 0.4068044126033783, train_loss: 0.013973967172205448\n",
            "45370 val_loss: 0.3733105957508087, train_loss: 0.0025249882601201534\n",
            "45380 val_loss: 0.4108200669288635, train_loss: 0.0042647612281143665\n",
            "45390 val_loss: 0.3740907311439514, train_loss: 0.0025373673997819424\n",
            "45400 val_loss: 0.39127376675605774, train_loss: 0.0022969378624111414\n",
            "45410 val_loss: 0.3743356466293335, train_loss: 0.0027489562053233385\n",
            "45420 val_loss: 0.44207608699798584, train_loss: 0.0055950661189854145\n",
            "45430 val_loss: 0.41899314522743225, train_loss: 0.002275818958878517\n",
            "45440 val_loss: 0.39274874329566956, train_loss: 0.007189210969954729\n",
            "45450 val_loss: 0.39373478293418884, train_loss: 0.00202254974283278\n",
            "45460 val_loss: 0.3717917203903198, train_loss: 0.004223175346851349\n",
            "45470 val_loss: 0.34022003412246704, train_loss: 0.006537250243127346\n",
            "45480 val_loss: 0.3745712637901306, train_loss: 0.0023096881341189146\n",
            "45490 val_loss: 0.36961233615875244, train_loss: 0.0022725025191903114\n",
            "45500 val_loss: 0.3800674080848694, train_loss: 0.002171069150790572\n",
            "45510 val_loss: 0.37769296765327454, train_loss: 0.0025729776825755835\n",
            "45520 val_loss: 0.37045955657958984, train_loss: 0.0024060739669948816\n",
            "45530 val_loss: 0.3592248558998108, train_loss: 0.0033145297784358263\n",
            "45540 val_loss: 0.3736897110939026, train_loss: 0.0021582457702606916\n",
            "45550 val_loss: 0.3618997037410736, train_loss: 0.004599361680448055\n",
            "45560 val_loss: 0.37483516335487366, train_loss: 0.002668962813913822\n",
            "45570 val_loss: 0.39931386709213257, train_loss: 0.002534632571041584\n",
            "45580 val_loss: 0.40128540992736816, train_loss: 0.0028306881431490183\n",
            "45590 val_loss: 0.3924775719642639, train_loss: 0.002944550011307001\n",
            "45600 val_loss: 0.3914962410926819, train_loss: 0.002374565927311778\n",
            "45610 val_loss: 0.38777250051498413, train_loss: 0.0023085426073521376\n",
            "45620 val_loss: 0.4168980121612549, train_loss: 0.01850016415119171\n",
            "45630 val_loss: 0.368679016828537, train_loss: 0.003105386160314083\n",
            "45640 val_loss: 0.38738200068473816, train_loss: 0.0021256678737699986\n",
            "45650 val_loss: 0.3769659399986267, train_loss: 0.002668952802196145\n",
            "45660 val_loss: 0.3765183985233307, train_loss: 0.003553691552951932\n",
            "45670 val_loss: 0.41743770241737366, train_loss: 0.003592145163565874\n",
            "45680 val_loss: 0.3770294785499573, train_loss: 0.003423229092732072\n",
            "45690 val_loss: 0.4013184905052185, train_loss: 0.002705140272155404\n",
            "45700 val_loss: 0.44429734349250793, train_loss: 0.0072444346733391285\n",
            "45710 val_loss: 0.3796365559101105, train_loss: 0.0030258281622081995\n",
            "45720 val_loss: 0.40023475885391235, train_loss: 0.0023201184812933207\n",
            "45730 val_loss: 0.3976598381996155, train_loss: 0.0023656333796679974\n",
            "45740 val_loss: 0.38823336362838745, train_loss: 0.0023143442813307047\n",
            "45750 val_loss: 0.3970814347267151, train_loss: 0.0025526650715619326\n",
            "45760 val_loss: 0.37643009424209595, train_loss: 0.008359060622751713\n",
            "45770 val_loss: 0.3789304792881012, train_loss: 0.004884093534201384\n",
            "45780 val_loss: 0.3893733620643616, train_loss: 0.00214963941834867\n",
            "45790 val_loss: 0.39673274755477905, train_loss: 0.002129513071849942\n",
            "45800 val_loss: 0.38158145546913147, train_loss: 0.002244368428364396\n",
            "45810 val_loss: 0.4000929892063141, train_loss: 0.0024463036097586155\n",
            "45820 val_loss: 0.3802202641963959, train_loss: 0.0020893155597150326\n",
            "45830 val_loss: 0.3833727538585663, train_loss: 0.0021928546484559774\n",
            "45840 val_loss: 0.3849954605102539, train_loss: 0.0020831648726016283\n",
            "45850 val_loss: 0.37299320101737976, train_loss: 0.0035347153898328543\n",
            "45860 val_loss: 0.39245110750198364, train_loss: 0.00202813558280468\n",
            "45870 val_loss: 0.3779115676879883, train_loss: 0.0038477026391774416\n",
            "45880 val_loss: 0.4524732828140259, train_loss: 0.007268110290169716\n",
            "45890 val_loss: 0.40203604102134705, train_loss: 0.01595376431941986\n",
            "45900 val_loss: 0.3642922341823578, train_loss: 0.0032978085801005363\n",
            "45910 val_loss: 0.36662983894348145, train_loss: 0.0026238441932946444\n",
            "45920 val_loss: 0.42897525429725647, train_loss: 0.006934384349733591\n",
            "45930 val_loss: 0.38624778389930725, train_loss: 0.0022731104400008917\n",
            "45940 val_loss: 0.37573114037513733, train_loss: 0.002207848010584712\n",
            "45950 val_loss: 0.387029230594635, train_loss: 0.0022149584256112576\n",
            "45960 val_loss: 0.389266699552536, train_loss: 0.0022522611543536186\n",
            "45970 val_loss: 0.3791699707508087, train_loss: 0.0023644447792321444\n",
            "45980 val_loss: 0.38707002997398376, train_loss: 0.0022003778722137213\n",
            "45990 val_loss: 0.3745955228805542, train_loss: 0.0028746260795742273\n",
            "46000 val_loss: 0.3815045654773712, train_loss: 0.002235759049654007\n",
            "46010 val_loss: 0.4097657799720764, train_loss: 0.0030272374860942364\n",
            "46020 val_loss: 0.36399728059768677, train_loss: 0.004634012468159199\n",
            "46030 val_loss: 0.3983250558376312, train_loss: 0.0019712806679308414\n",
            "46040 val_loss: 0.39995694160461426, train_loss: 0.0021234210580587387\n",
            "46050 val_loss: 0.3982846438884735, train_loss: 0.0021816648077219725\n",
            "46060 val_loss: 0.3859483301639557, train_loss: 0.004577166400849819\n",
            "46070 val_loss: 0.399310827255249, train_loss: 0.0021025475580245256\n",
            "46080 val_loss: 0.38961029052734375, train_loss: 0.0029972849879413843\n",
            "46090 val_loss: 0.3724396526813507, train_loss: 0.017232250422239304\n",
            "46100 val_loss: 0.3651468753814697, train_loss: 0.0027426956221461296\n",
            "46110 val_loss: 0.3597201704978943, train_loss: 0.003834852483123541\n",
            "46120 val_loss: 0.4455516040325165, train_loss: 0.007373923435807228\n",
            "46130 val_loss: 0.3686782419681549, train_loss: 0.0034312366042286158\n",
            "46140 val_loss: 0.39453670382499695, train_loss: 0.0022851366084069014\n",
            "46150 val_loss: 0.3926461637020111, train_loss: 0.003898915834724903\n",
            "46160 val_loss: 0.44119125604629517, train_loss: 0.18968844413757324\n",
            "46170 val_loss: 0.28676527738571167, train_loss: 0.05130933225154877\n",
            "46180 val_loss: 0.25655192136764526, train_loss: 0.025790352374315262\n",
            "46190 val_loss: 0.25138241052627563, train_loss: 0.014340516179800034\n",
            "46200 val_loss: 0.2578718662261963, train_loss: 0.01177169568836689\n",
            "46210 val_loss: 0.2693004012107849, train_loss: 0.010550810024142265\n",
            "46220 val_loss: 0.26650166511535645, train_loss: 0.010475761257112026\n",
            "46230 val_loss: 0.27559709548950195, train_loss: 0.00959849078208208\n",
            "46240 val_loss: 0.31423982977867126, train_loss: 0.009707735851407051\n",
            "46250 val_loss: 0.3097628951072693, train_loss: 0.007667408790439367\n",
            "46260 val_loss: 0.3366836905479431, train_loss: 0.00542503222823143\n",
            "46270 val_loss: 0.33202803134918213, train_loss: 0.004859707783907652\n",
            "46280 val_loss: 0.33728623390197754, train_loss: 0.004331064876168966\n",
            "46290 val_loss: 0.3290742337703705, train_loss: 0.007058748975396156\n",
            "46300 val_loss: 0.3474506139755249, train_loss: 0.004074155818670988\n",
            "46310 val_loss: 0.3566855788230896, train_loss: 0.0032836974132806063\n",
            "46320 val_loss: 0.3531981110572815, train_loss: 0.0035777012817561626\n",
            "46330 val_loss: 0.3775743544101715, train_loss: 0.0027216337621212006\n",
            "46340 val_loss: 0.37624391913414, train_loss: 0.0029742408078163862\n",
            "46350 val_loss: 0.3553619384765625, train_loss: 0.01363416574895382\n",
            "46360 val_loss: 0.34426578879356384, train_loss: 0.004660278093069792\n",
            "46370 val_loss: 0.3620569705963135, train_loss: 0.0028232820332050323\n",
            "46380 val_loss: 0.3581123352050781, train_loss: 0.0030796723440289497\n",
            "46390 val_loss: 0.35935917496681213, train_loss: 0.0038165636360645294\n",
            "46400 val_loss: 0.3677302300930023, train_loss: 0.008648528717458248\n",
            "46410 val_loss: 0.394353449344635, train_loss: 0.004132445901632309\n",
            "46420 val_loss: 0.4380417764186859, train_loss: 0.010572534054517746\n",
            "46430 val_loss: 0.39900994300842285, train_loss: 0.00314678018912673\n",
            "46440 val_loss: 0.3805847764015198, train_loss: 0.008027059957385063\n",
            "46450 val_loss: 0.33012595772743225, train_loss: 0.013150369748473167\n",
            "46460 val_loss: 0.36106374859809875, train_loss: 0.002983897225931287\n",
            "46470 val_loss: 0.4001316428184509, train_loss: 0.0028019852470606565\n",
            "46480 val_loss: 0.3840833902359009, train_loss: 0.01506047509610653\n",
            "46490 val_loss: 0.3929714858531952, train_loss: 0.003726228838786483\n",
            "46500 val_loss: 0.36062586307525635, train_loss: 0.0034336603712290525\n",
            "46510 val_loss: 0.3804510533809662, train_loss: 0.002454057801514864\n",
            "46520 val_loss: 0.37667399644851685, train_loss: 0.002356132725253701\n",
            "46530 val_loss: 0.38571497797966003, train_loss: 0.0025682190898805857\n",
            "46540 val_loss: 0.4202148914337158, train_loss: 0.006179811432957649\n",
            "46550 val_loss: 0.38210028409957886, train_loss: 0.0023351460695266724\n",
            "46560 val_loss: 0.4181842803955078, train_loss: 0.006524520460516214\n",
            "46570 val_loss: 0.3635445237159729, train_loss: 0.0028165969997644424\n",
            "46580 val_loss: 0.3792615532875061, train_loss: 0.002184514421969652\n",
            "46590 val_loss: 0.36380836367607117, train_loss: 0.003312833374366164\n",
            "46600 val_loss: 0.5870774388313293, train_loss: 0.056483667343854904\n",
            "46610 val_loss: 0.36073386669158936, train_loss: 0.0028961317148059607\n",
            "46620 val_loss: 0.4449693560600281, train_loss: 0.014020980335772038\n",
            "46630 val_loss: 0.3394337594509125, train_loss: 0.007651003543287516\n",
            "46640 val_loss: 0.37062010169029236, train_loss: 0.0023629963397979736\n",
            "46650 val_loss: 0.4667043089866638, train_loss: 0.01526632346212864\n",
            "46660 val_loss: 0.29549387097358704, train_loss: 0.052675649523735046\n",
            "46670 val_loss: 0.281780868768692, train_loss: 0.02612120285630226\n",
            "46680 val_loss: 0.27761605381965637, train_loss: 0.01882312446832657\n",
            "46690 val_loss: 0.26582640409469604, train_loss: 0.015842439606785774\n",
            "46700 val_loss: 0.27389341592788696, train_loss: 0.014078839682042599\n",
            "46710 val_loss: 0.27165862917900085, train_loss: 0.012963607907295227\n",
            "46720 val_loss: 0.2777727544307709, train_loss: 0.012372985482215881\n",
            "46730 val_loss: 0.2765410840511322, train_loss: 0.012003839947283268\n",
            "46740 val_loss: 0.30917996168136597, train_loss: 0.011242453008890152\n",
            "46750 val_loss: 0.3078306317329407, train_loss: 0.010609699413180351\n",
            "46760 val_loss: 0.32803481817245483, train_loss: 0.00899498537182808\n",
            "46770 val_loss: 0.32821276783943176, train_loss: 0.008273378014564514\n",
            "46780 val_loss: 0.3357497751712799, train_loss: 0.0073477718979120255\n",
            "46790 val_loss: 0.36082708835601807, train_loss: 0.005701160989701748\n",
            "46800 val_loss: 0.3550592362880707, train_loss: 0.005057693459093571\n",
            "46810 val_loss: 0.37509170174598694, train_loss: 0.004530392587184906\n",
            "46820 val_loss: 0.3679887056350708, train_loss: 0.003963586408644915\n",
            "46830 val_loss: 0.3767262101173401, train_loss: 0.0037574090529233217\n",
            "46840 val_loss: 0.4079853296279907, train_loss: 0.0060155196115374565\n",
            "46850 val_loss: 0.3462236225605011, train_loss: 0.0055783032439649105\n",
            "46860 val_loss: 0.36211639642715454, train_loss: 0.0034545492380857468\n",
            "46870 val_loss: 0.3839113712310791, train_loss: 0.0027823052369058132\n",
            "46880 val_loss: 0.3995489478111267, train_loss: 0.0047731962986290455\n",
            "46890 val_loss: 0.37519973516464233, train_loss: 0.0024684572126716375\n",
            "46900 val_loss: 0.43680834770202637, train_loss: 0.009606244042515755\n",
            "46910 val_loss: 0.3516641855239868, train_loss: 0.0057136295363307\n",
            "46920 val_loss: 0.3596706986427307, train_loss: 0.003533980343490839\n",
            "46930 val_loss: 0.33993107080459595, train_loss: 0.004922471009194851\n",
            "46940 val_loss: 0.37797507643699646, train_loss: 0.0028276098892092705\n",
            "46950 val_loss: 0.38892045617103577, train_loss: 0.003212783019989729\n",
            "46960 val_loss: 0.395729124546051, train_loss: 0.0031767887994647026\n",
            "46970 val_loss: 0.38265541195869446, train_loss: 0.0029225654434412718\n",
            "46980 val_loss: 0.37605515122413635, train_loss: 0.0029100796673446894\n",
            "46990 val_loss: 0.3768753409385681, train_loss: 0.0025334672536700964\n",
            "47000 val_loss: 0.3989032506942749, train_loss: 0.0034824856556952\n",
            "47010 val_loss: 0.35437002778053284, train_loss: 0.004505525343120098\n",
            "47020 val_loss: 0.3783300817012787, train_loss: 0.002448505721986294\n",
            "47030 val_loss: 0.3937568664550781, train_loss: 0.002939927624538541\n",
            "47040 val_loss: 0.38109317421913147, train_loss: 0.002331754192709923\n",
            "47050 val_loss: 0.363862544298172, train_loss: 0.0031961165368556976\n",
            "47060 val_loss: 0.36685535311698914, train_loss: 0.0026467295829206705\n",
            "47070 val_loss: 0.3556404411792755, train_loss: 0.004545319825410843\n",
            "47080 val_loss: 0.3816267251968384, train_loss: 0.0022910942789167166\n",
            "47090 val_loss: 0.35381633043289185, train_loss: 0.004598559346050024\n",
            "47100 val_loss: 0.3858025074005127, train_loss: 0.013102995231747627\n",
            "47110 val_loss: 0.3646376132965088, train_loss: 0.0036059028934687376\n",
            "47120 val_loss: 0.3759090006351471, train_loss: 0.0022441891487687826\n",
            "47130 val_loss: 0.3752899169921875, train_loss: 0.0023285746574401855\n",
            "47140 val_loss: 0.3749130666255951, train_loss: 0.0021025943569839\n",
            "47150 val_loss: 0.37189629673957825, train_loss: 0.002800306538119912\n",
            "47160 val_loss: 0.4305557608604431, train_loss: 0.007042524870485067\n",
            "47170 val_loss: 0.36454254388809204, train_loss: 0.0037006663624197245\n",
            "47180 val_loss: 0.3452480733394623, train_loss: 0.0055353082716465\n",
            "47190 val_loss: 0.46169766783714294, train_loss: 0.01276424340903759\n",
            "47200 val_loss: 0.375176340341568, train_loss: 0.0022042898926883936\n",
            "47210 val_loss: 0.38806432485580444, train_loss: 0.0023406418040394783\n",
            "47220 val_loss: 0.35878247022628784, train_loss: 0.0030657420866191387\n",
            "47230 val_loss: 0.3860604465007782, train_loss: 0.002661383245140314\n",
            "47240 val_loss: 0.3629603385925293, train_loss: 0.002652615075930953\n",
            "47250 val_loss: 0.42666536569595337, train_loss: 0.007218829356133938\n",
            "47260 val_loss: 0.4866795837879181, train_loss: 0.01889641024172306\n",
            "47270 val_loss: 0.37094831466674805, train_loss: 0.005160200409591198\n",
            "47280 val_loss: 0.3771519064903259, train_loss: 0.002668576780706644\n",
            "47290 val_loss: 0.3847444951534271, train_loss: 0.002124706283211708\n",
            "47300 val_loss: 0.3814653754234314, train_loss: 0.0021260238718241453\n",
            "47310 val_loss: 0.3985764682292938, train_loss: 0.002904583001509309\n",
            "47320 val_loss: 0.37617799639701843, train_loss: 0.002216600114479661\n",
            "47330 val_loss: 0.367314875125885, train_loss: 0.002977599622681737\n",
            "47340 val_loss: 0.3722856342792511, train_loss: 0.0024741818197071552\n",
            "47350 val_loss: 0.36797747015953064, train_loss: 0.0023928519804030657\n",
            "47360 val_loss: 0.38625776767730713, train_loss: 0.0026354780420660973\n",
            "47370 val_loss: 0.41322341561317444, train_loss: 0.005646952427923679\n",
            "47380 val_loss: 0.3723513185977936, train_loss: 0.002505967626348138\n",
            "47390 val_loss: 0.37525859475135803, train_loss: 0.0022752140648663044\n",
            "47400 val_loss: 0.39430174231529236, train_loss: 0.0032245225738734007\n",
            "47410 val_loss: 0.35689061880111694, train_loss: 0.0032433795277029276\n",
            "47420 val_loss: 0.3757765293121338, train_loss: 0.002250228077173233\n",
            "47430 val_loss: 0.37025848031044006, train_loss: 0.0025179716758430004\n",
            "47440 val_loss: 0.36068016290664673, train_loss: 0.003958942834287882\n",
            "47450 val_loss: 0.4032530188560486, train_loss: 0.0034466981887817383\n",
            "47460 val_loss: 0.3689478635787964, train_loss: 0.0029144606087356806\n",
            "47470 val_loss: 0.4543982446193695, train_loss: 0.010525261983275414\n",
            "47480 val_loss: 0.35579633712768555, train_loss: 0.004780085291713476\n",
            "47490 val_loss: 0.372843474149704, train_loss: 0.0026853212621062994\n",
            "47500 val_loss: 0.3840225636959076, train_loss: 0.015232793986797333\n",
            "47510 val_loss: 0.3749595284461975, train_loss: 0.0024358935188502073\n",
            "47520 val_loss: 0.4587607979774475, train_loss: 0.011140391230583191\n",
            "47530 val_loss: 0.35806021094322205, train_loss: 0.003569250460714102\n",
            "47540 val_loss: 0.38409656286239624, train_loss: 0.002166873076930642\n",
            "47550 val_loss: 0.39079469442367554, train_loss: 0.0023396380711346865\n",
            "47560 val_loss: 0.3937208652496338, train_loss: 0.0026240842416882515\n",
            "47570 val_loss: 0.38585105538368225, train_loss: 0.0022063113283365965\n",
            "47580 val_loss: 0.4010204076766968, train_loss: 0.0029615818057209253\n",
            "47590 val_loss: 0.35456472635269165, train_loss: 0.012691240757703781\n",
            "47600 val_loss: 0.3697274923324585, train_loss: 0.002238433575257659\n",
            "47610 val_loss: 0.3950394093990326, train_loss: 0.00240545766428113\n",
            "47620 val_loss: 0.3975718915462494, train_loss: 0.0024495399557054043\n",
            "47630 val_loss: 0.3511435091495514, train_loss: 0.006959233433008194\n",
            "47640 val_loss: 0.49523720145225525, train_loss: 0.01711180806159973\n",
            "47650 val_loss: 0.37058812379837036, train_loss: 0.0024432374630123377\n",
            "47660 val_loss: 0.3605446219444275, train_loss: 0.002821330213919282\n",
            "47670 val_loss: 0.3336593508720398, train_loss: 0.007307515013962984\n",
            "47680 val_loss: 0.36163845658302307, train_loss: 0.0024992136750370264\n",
            "47690 val_loss: 0.39147040247917175, train_loss: 0.002698110416531563\n",
            "47700 val_loss: 0.37647539377212524, train_loss: 0.002152756555005908\n",
            "47710 val_loss: 0.37306809425354004, train_loss: 0.002267997246235609\n",
            "47720 val_loss: 0.3797810971736908, train_loss: 0.0020149913616478443\n",
            "47730 val_loss: 0.38988345861434937, train_loss: 0.014995011501014233\n",
            "47740 val_loss: 0.3929692208766937, train_loss: 0.0027145727071911097\n",
            "47750 val_loss: 0.3842918276786804, train_loss: 0.002219803398475051\n",
            "47760 val_loss: 0.38762030005455017, train_loss: 0.00214249175041914\n",
            "47770 val_loss: 0.38632452487945557, train_loss: 0.0019910349510610104\n",
            "47780 val_loss: 0.44683870673179626, train_loss: 0.0025601976085454226\n",
            "47790 val_loss: 0.40731343626976013, train_loss: 0.0024603549391031265\n",
            "47800 val_loss: 0.3982340395450592, train_loss: 0.0023406874388456345\n",
            "47810 val_loss: 0.3708688020706177, train_loss: 0.0030104322358965874\n",
            "47820 val_loss: 0.3955918252468109, train_loss: 0.0022293468937277794\n",
            "47830 val_loss: 0.39224597811698914, train_loss: 0.0018940174486488104\n",
            "47840 val_loss: 0.3866805136203766, train_loss: 0.0023080287501215935\n",
            "47850 val_loss: 0.4079558849334717, train_loss: 0.003043597098439932\n",
            "47860 val_loss: 0.41665881872177124, train_loss: 0.0037654649931937456\n",
            "47870 val_loss: 0.4006935656070709, train_loss: 0.002603456610813737\n",
            "47880 val_loss: 0.3965085744857788, train_loss: 0.0020454407203942537\n",
            "47890 val_loss: 0.4070824682712555, train_loss: 0.005202382802963257\n",
            "47900 val_loss: 0.38861727714538574, train_loss: 0.0019088506232947111\n",
            "47910 val_loss: 0.3736325800418854, train_loss: 0.0026605187449604273\n",
            "47920 val_loss: 0.35222622752189636, train_loss: 0.008711020462214947\n",
            "47930 val_loss: 0.3931533694267273, train_loss: 0.0019089430570602417\n",
            "47940 val_loss: 0.38126251101493835, train_loss: 0.008179779164493084\n",
            "47950 val_loss: 0.4264346957206726, train_loss: 0.005631816573441029\n",
            "47960 val_loss: 0.3879795968532562, train_loss: 0.0017959425458684564\n",
            "47970 val_loss: 0.39343026280403137, train_loss: 0.001846121740527451\n",
            "47980 val_loss: 0.371478796005249, train_loss: 0.003361958544701338\n",
            "47990 val_loss: 0.4019988477230072, train_loss: 0.002274889498949051\n",
            "48000 val_loss: 0.38229575753211975, train_loss: 0.0025653839111328125\n",
            "48010 val_loss: 0.38153156638145447, train_loss: 0.004997294396162033\n",
            "48020 val_loss: 0.4115515649318695, train_loss: 0.002683897502720356\n",
            "48030 val_loss: 0.3811549246311188, train_loss: 0.013731224462389946\n",
            "48040 val_loss: 0.3937801122665405, train_loss: 0.0018843138823285699\n",
            "48050 val_loss: 0.394408643245697, train_loss: 0.0020135543309152126\n",
            "48060 val_loss: 0.37865883111953735, train_loss: 0.005892956629395485\n",
            "48070 val_loss: 0.3932499289512634, train_loss: 0.001995987957343459\n",
            "48080 val_loss: 0.39117521047592163, train_loss: 0.00284529197961092\n",
            "48090 val_loss: 0.3792859613895416, train_loss: 0.0030407386366277933\n",
            "48100 val_loss: 0.36109215021133423, train_loss: 0.003546983003616333\n",
            "48110 val_loss: 0.5342312455177307, train_loss: 0.020070543512701988\n",
            "48120 val_loss: 0.3728395700454712, train_loss: 0.0022538634948432446\n",
            "48130 val_loss: 0.3700648546218872, train_loss: 0.002688678912818432\n",
            "48140 val_loss: 0.3805777132511139, train_loss: 0.0020673794206231833\n",
            "48150 val_loss: 0.35160505771636963, train_loss: 0.009878363460302353\n",
            "48160 val_loss: 0.41398462653160095, train_loss: 0.0019462828058749437\n",
            "48170 val_loss: 0.4062342941761017, train_loss: 0.001983738737180829\n",
            "48180 val_loss: 0.4065168499946594, train_loss: 0.0019302329747006297\n",
            "48190 val_loss: 0.3695036768913269, train_loss: 0.002989220665767789\n",
            "48200 val_loss: 0.38912367820739746, train_loss: 0.002143222838640213\n",
            "48210 val_loss: 0.3967059850692749, train_loss: 0.0022214038763195276\n",
            "48220 val_loss: 0.37602415680885315, train_loss: 0.002735055750235915\n",
            "48230 val_loss: 0.38715890049934387, train_loss: 0.002012483077123761\n",
            "48240 val_loss: 0.3879515826702118, train_loss: 0.0034016419667750597\n",
            "48250 val_loss: 0.37863343954086304, train_loss: 0.0021621668711304665\n",
            "48260 val_loss: 0.38397547602653503, train_loss: 0.002159441588446498\n",
            "48270 val_loss: 0.38133320212364197, train_loss: 0.0027218512259423733\n",
            "48280 val_loss: 0.37706810235977173, train_loss: 0.004525917116552591\n",
            "48290 val_loss: 0.390526682138443, train_loss: 0.0019297306425869465\n",
            "48300 val_loss: 0.3988546133041382, train_loss: 0.001848616637289524\n",
            "48310 val_loss: 0.3950161635875702, train_loss: 0.0039954460225999355\n",
            "48320 val_loss: 0.39100977778434753, train_loss: 0.0023206688929349184\n",
            "48330 val_loss: 0.40678301453590393, train_loss: 0.0021169644314795732\n",
            "48340 val_loss: 0.46348661184310913, train_loss: 0.008506052196025848\n",
            "48350 val_loss: 0.38734737038612366, train_loss: 0.004749699030071497\n",
            "48360 val_loss: 0.39148280024528503, train_loss: 0.002875306410714984\n",
            "48370 val_loss: 0.41663020849227905, train_loss: 0.0025085676461458206\n",
            "48380 val_loss: 0.4469068944454193, train_loss: 0.004573127254843712\n",
            "48390 val_loss: 0.4368302524089813, train_loss: 0.0031761527061462402\n",
            "48400 val_loss: 0.4363090991973877, train_loss: 0.004969214089214802\n",
            "48410 val_loss: 0.41724440455436707, train_loss: 0.0018079901346936822\n",
            "48420 val_loss: 0.3812751770019531, train_loss: 0.001993222162127495\n",
            "48430 val_loss: 0.41895413398742676, train_loss: 0.00397273525595665\n",
            "48440 val_loss: 0.37785622477531433, train_loss: 0.002784698037430644\n",
            "48450 val_loss: 0.38192108273506165, train_loss: 0.002283197594806552\n",
            "48460 val_loss: 0.38109925389289856, train_loss: 0.0036931054200977087\n",
            "48470 val_loss: 0.38810011744499207, train_loss: 0.0039889938198029995\n",
            "48480 val_loss: 0.41387611627578735, train_loss: 0.0025072037242352962\n",
            "48490 val_loss: 0.4036485552787781, train_loss: 0.0022373462561517954\n",
            "48500 val_loss: 0.4084300100803375, train_loss: 0.00228162482380867\n",
            "48510 val_loss: 0.3820737302303314, train_loss: 0.002407944994047284\n",
            "48520 val_loss: 0.4049862027168274, train_loss: 0.002104709856212139\n",
            "48530 val_loss: 0.5008524656295776, train_loss: 0.014867051504552364\n",
            "48540 val_loss: 0.3780692517757416, train_loss: 0.002714945236220956\n",
            "48550 val_loss: 0.4149111211299896, train_loss: 0.002521033165976405\n",
            "48560 val_loss: 0.39097315073013306, train_loss: 0.0018917853012681007\n",
            "48570 val_loss: 0.5719000697135925, train_loss: 0.0272410549223423\n",
            "48580 val_loss: 0.37938663363456726, train_loss: 0.006238363683223724\n",
            "48590 val_loss: 0.3865834176540375, train_loss: 0.0029742552433162928\n",
            "48600 val_loss: 0.364385187625885, train_loss: 0.01391697209328413\n",
            "48610 val_loss: 0.4010046422481537, train_loss: 0.0021766116842627525\n",
            "48620 val_loss: 0.4102618396282196, train_loss: 0.0019426655489951372\n",
            "48630 val_loss: 0.4221175014972687, train_loss: 0.0025997962802648544\n",
            "48640 val_loss: 0.3822908401489258, train_loss: 0.007472548168152571\n",
            "48650 val_loss: 0.3879585266113281, train_loss: 0.0018927471246570349\n",
            "48660 val_loss: 0.39071542024612427, train_loss: 0.0017817090265452862\n",
            "48670 val_loss: 0.5030084848403931, train_loss: 0.016815608367323875\n",
            "48680 val_loss: 0.4514523446559906, train_loss: 0.006415450945496559\n",
            "48690 val_loss: 0.3845096826553345, train_loss: 0.0018268519779667258\n",
            "48700 val_loss: 0.38814863562583923, train_loss: 0.002644934458658099\n",
            "48710 val_loss: 0.52301424741745, train_loss: 0.019971653819084167\n",
            "48720 val_loss: 0.37665191292762756, train_loss: 0.0032400290947407484\n",
            "48730 val_loss: 0.4084413945674896, train_loss: 0.002483345801010728\n",
            "48740 val_loss: 0.42272335290908813, train_loss: 0.0031613530591130257\n",
            "48750 val_loss: 0.3853060305118561, train_loss: 0.0032970814500004053\n",
            "48760 val_loss: 0.4045111835002899, train_loss: 0.0018287065904587507\n",
            "48770 val_loss: 0.4188390374183655, train_loss: 0.0024812286719679832\n",
            "48780 val_loss: 0.39033961296081543, train_loss: 0.002752911066636443\n",
            "48790 val_loss: 0.43422359228134155, train_loss: 0.004158425610512495\n",
            "48800 val_loss: 0.41494423151016235, train_loss: 0.002135906834155321\n",
            "48810 val_loss: 0.3933420181274414, train_loss: 0.0030588945373892784\n",
            "48820 val_loss: 0.38763636350631714, train_loss: 0.002947942353785038\n",
            "48830 val_loss: 0.3884257674217224, train_loss: 0.002904797438532114\n",
            "48840 val_loss: 0.40475404262542725, train_loss: 0.0019051547860726714\n",
            "48850 val_loss: 0.40318426489830017, train_loss: 0.001774942851625383\n",
            "48860 val_loss: 0.4172026813030243, train_loss: 0.0026900731027126312\n",
            "48870 val_loss: 0.4358527660369873, train_loss: 0.004765922669321299\n",
            "48880 val_loss: 0.3658025860786438, train_loss: 0.011783805675804615\n",
            "48890 val_loss: 0.40244928002357483, train_loss: 0.0017969530308619142\n",
            "48900 val_loss: 0.376049280166626, train_loss: 0.014158718287944794\n",
            "48910 val_loss: 0.38429564237594604, train_loss: 0.00213101739063859\n",
            "48920 val_loss: 0.3963100016117096, train_loss: 0.0017623702296987176\n",
            "48930 val_loss: 0.3836787939071655, train_loss: 0.0028520110063254833\n",
            "48940 val_loss: 0.4095548987388611, train_loss: 0.001932375249452889\n",
            "48950 val_loss: 0.3869651257991791, train_loss: 0.002460281364619732\n",
            "48960 val_loss: 0.410907506942749, train_loss: 0.0019933274015784264\n",
            "48970 val_loss: 0.3837754428386688, train_loss: 0.0033794520422816277\n",
            "48980 val_loss: 0.40385740995407104, train_loss: 0.0021546257194131613\n",
            "48990 val_loss: 0.4065941274166107, train_loss: 0.0016832015244290233\n",
            "49000 val_loss: 0.47393158078193665, train_loss: 0.0020265423227101564\n",
            "49010 val_loss: 0.4156884551048279, train_loss: 0.001880793715827167\n",
            "49020 val_loss: 0.417527437210083, train_loss: 0.0022023236379027367\n",
            "49030 val_loss: 0.43916261196136475, train_loss: 0.0045826914720237255\n",
            "49040 val_loss: 0.39153361320495605, train_loss: 0.0022329348139464855\n",
            "49050 val_loss: 0.4244316518306732, train_loss: 0.0034536500461399555\n",
            "49060 val_loss: 0.414983332157135, train_loss: 0.0021060900762677193\n",
            "49070 val_loss: 0.42347925901412964, train_loss: 0.002318932907655835\n",
            "49080 val_loss: 0.4048783481121063, train_loss: 0.002274247817695141\n",
            "49090 val_loss: 0.4057539105415344, train_loss: 0.0019265601877123117\n",
            "49100 val_loss: 0.42373529076576233, train_loss: 0.0025208245497196913\n",
            "49110 val_loss: 0.40319252014160156, train_loss: 0.0017658157739788294\n",
            "49120 val_loss: 0.5101172924041748, train_loss: 0.001638631452806294\n",
            "49130 val_loss: 0.4357883930206299, train_loss: 0.0024028418119996786\n",
            "49140 val_loss: 0.4252563714981079, train_loss: 0.003449809504672885\n",
            "49150 val_loss: 0.39748167991638184, train_loss: 0.00193409260828048\n",
            "49160 val_loss: 0.3968122601509094, train_loss: 0.0021045852918177843\n",
            "49170 val_loss: 0.4009108245372772, train_loss: 0.0019846423529088497\n",
            "49180 val_loss: 0.3980506360530853, train_loss: 0.0023355833254754543\n",
            "49190 val_loss: 0.3913264572620392, train_loss: 0.0092664435505867\n",
            "49200 val_loss: 0.4904736876487732, train_loss: 0.0022295766975730658\n",
            "49210 val_loss: 0.4167079031467438, train_loss: 0.0018481690203770995\n",
            "49220 val_loss: 0.4786902070045471, train_loss: 0.010615766048431396\n",
            "49230 val_loss: 0.40521857142448425, train_loss: 0.002250193851068616\n",
            "49240 val_loss: 0.39344164729118347, train_loss: 0.0034289348404854536\n",
            "49250 val_loss: 0.4025137424468994, train_loss: 0.0019028945825994015\n",
            "49260 val_loss: 0.3972841799259186, train_loss: 0.0018477351404726505\n",
            "49270 val_loss: 0.40382876992225647, train_loss: 0.0017727575032040477\n",
            "49280 val_loss: 0.4038750231266022, train_loss: 0.0020915870554745197\n",
            "49290 val_loss: 0.4152826964855194, train_loss: 0.0018018726259469986\n",
            "49300 val_loss: 0.3977779150009155, train_loss: 0.0020277139265090227\n",
            "49310 val_loss: 0.42748361825942993, train_loss: 0.0029340318869799376\n",
            "49320 val_loss: 0.3996223211288452, train_loss: 0.001826786552555859\n",
            "49330 val_loss: 0.43579134345054626, train_loss: 0.003937928471714258\n",
            "49340 val_loss: 0.40220198035240173, train_loss: 0.0018410891061648726\n",
            "49350 val_loss: 0.40371575951576233, train_loss: 0.0017911919858306646\n",
            "49360 val_loss: 0.3910456597805023, train_loss: 0.0038535099010914564\n",
            "49370 val_loss: 0.3899998962879181, train_loss: 0.0023868733551353216\n",
            "49380 val_loss: 0.385903000831604, train_loss: 0.002932619769126177\n",
            "49390 val_loss: 0.38776373863220215, train_loss: 0.0025739490520209074\n",
            "49400 val_loss: 0.42410945892333984, train_loss: 0.0021723799873143435\n",
            "49410 val_loss: 0.39197975397109985, train_loss: 0.002612590091302991\n",
            "49420 val_loss: 0.36526796221733093, train_loss: 0.005796033889055252\n",
            "49430 val_loss: 0.48185285925865173, train_loss: 0.009452384896576405\n",
            "49440 val_loss: 0.4484451711177826, train_loss: 0.004847036674618721\n",
            "49450 val_loss: 0.3974754214286804, train_loss: 0.0018797734519466758\n",
            "49460 val_loss: 0.40651917457580566, train_loss: 0.00170232099480927\n",
            "49470 val_loss: 0.4056474566459656, train_loss: 0.0024480170104652643\n",
            "49480 val_loss: 0.4049072265625, train_loss: 0.0017368580447509885\n",
            "49490 val_loss: 0.4013069272041321, train_loss: 0.0016471088165417314\n",
            "49500 val_loss: 0.38638490438461304, train_loss: 0.002683489816263318\n",
            "49510 val_loss: 0.37571951746940613, train_loss: 0.002918274374678731\n",
            "49520 val_loss: 0.3847551941871643, train_loss: 0.0020392066799104214\n",
            "49530 val_loss: 0.3869369626045227, train_loss: 0.002123715355992317\n",
            "49540 val_loss: 0.4144425094127655, train_loss: 0.0022411702666431665\n",
            "49550 val_loss: 0.4087568521499634, train_loss: 0.0019277251558378339\n",
            "49560 val_loss: 0.39240583777427673, train_loss: 0.001976028550416231\n",
            "49570 val_loss: 0.45264294743537903, train_loss: 0.0033227503299713135\n",
            "49580 val_loss: 0.42369693517684937, train_loss: 0.0025753655936568975\n",
            "49590 val_loss: 0.41876888275146484, train_loss: 0.002030340489000082\n",
            "49600 val_loss: 0.42651209235191345, train_loss: 0.0021297780331224203\n",
            "49610 val_loss: 0.42150750756263733, train_loss: 0.0016711169155314565\n",
            "49620 val_loss: 0.3985118269920349, train_loss: 0.0017325134249404073\n",
            "49630 val_loss: 0.38576480746269226, train_loss: 0.005445869639515877\n",
            "49640 val_loss: 0.40446436405181885, train_loss: 0.0021497351117432117\n",
            "49650 val_loss: 0.3967878222465515, train_loss: 0.0019707700703293085\n",
            "49660 val_loss: 0.4128803610801697, train_loss: 0.00222934246994555\n",
            "49670 val_loss: 0.48819947242736816, train_loss: 0.014561334624886513\n",
            "49680 val_loss: 0.4153806269168854, train_loss: 0.002114188624545932\n",
            "49690 val_loss: 0.4110621511936188, train_loss: 0.002084338804706931\n",
            "49700 val_loss: 0.41127094626426697, train_loss: 0.001829332672059536\n",
            "49710 val_loss: 0.4124864339828491, train_loss: 0.0019728110637515783\n",
            "49720 val_loss: 0.41206881403923035, train_loss: 0.00170193612575531\n",
            "49730 val_loss: 0.4221094250679016, train_loss: 0.0023305194918066263\n",
            "49740 val_loss: 0.41530853509902954, train_loss: 0.0016848713858053088\n",
            "49750 val_loss: 0.4686948359012604, train_loss: 0.008291664533317089\n",
            "49760 val_loss: 0.4155673384666443, train_loss: 0.001819537254050374\n",
            "49770 val_loss: 0.42149510979652405, train_loss: 0.0017474695341661572\n",
            "49780 val_loss: 0.40491563081741333, train_loss: 0.0019436212023720145\n",
            "49790 val_loss: 0.3911331295967102, train_loss: 0.007001761347055435\n",
            "49800 val_loss: 0.4219614267349243, train_loss: 0.0042351060546934605\n",
            "49810 val_loss: 0.40704482793807983, train_loss: 0.0017085028812289238\n",
            "49820 val_loss: 0.41048043966293335, train_loss: 0.0018043393502011895\n",
            "49830 val_loss: 0.4008113443851471, train_loss: 0.002007355447858572\n",
            "49840 val_loss: 0.4141107201576233, train_loss: 0.0018881527939811349\n",
            "49850 val_loss: 0.437381386756897, train_loss: 0.017359454184770584\n",
            "49860 val_loss: 0.43240904808044434, train_loss: 0.003765729023143649\n",
            "49870 val_loss: 0.42517393827438354, train_loss: 0.0027477783150970936\n",
            "49880 val_loss: 0.3925817608833313, train_loss: 0.0019356454722583294\n",
            "49890 val_loss: 0.426410436630249, train_loss: 0.0027449182234704494\n",
            "49900 val_loss: 0.4152604043483734, train_loss: 0.0018757962388917804\n",
            "49910 val_loss: 0.39566731452941895, train_loss: 0.0020672965329140425\n",
            "49920 val_loss: 0.4000363051891327, train_loss: 0.0030754529871046543\n",
            "49930 val_loss: 0.40638813376426697, train_loss: 0.002155628986656666\n",
            "49940 val_loss: 0.4316161870956421, train_loss: 0.014256573282182217\n",
            "49950 val_loss: 0.41481539607048035, train_loss: 0.0023276456631720066\n",
            "49960 val_loss: 0.39791548252105713, train_loss: 0.003467538161203265\n",
            "49970 val_loss: 0.41524672508239746, train_loss: 0.004114573355764151\n",
            "49980 val_loss: 0.44741883873939514, train_loss: 0.003484418150037527\n",
            "49990 val_loss: 0.38181158900260925, train_loss: 0.006461494602262974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assumes `t_losses` and `val_losses` are lists of loss values\n",
        "plt.plot(t_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.xlabel('Steps (x10)')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "UXuCSev9X20N",
        "outputId": "1c828d3c-c8ee-4efa-97e8-725b6f4f17ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Validation에서 early stopping 값을 조정함"
      ],
      "metadata": {
        "id": "JhAQRE42cC6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "g = torch.Generator().manual_seed(42)\n",
        "g.manual_seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class DNet(nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
        "        super().__init__()\n",
        "        self.seq_model = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.seq_model(x)\n",
        "\n",
        "\n",
        "dnet = DNet(input_size=2,hidden_size=16,output_size=1)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(dnet.parameters(), lr=0.01)\n",
        "\n",
        "t_losses = []\n",
        "val_losses = []\n",
        "\n",
        "min_val_loss : float = float('inf')\n",
        "patience : int = 100  # Number of epochs to wait for improvement before stopping\n",
        "steps_no_improve : int= 0\n",
        "min_step : int = 0\n",
        "\n",
        "for steps in range(50000):\n",
        "    dnet.train()\n",
        "\n",
        "    output = dnet(train_data)\n",
        "    train_loss = loss_fn(output, train_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if steps % 10 == 0:\n",
        "        dnet.eval()\n",
        "        output = dnet(val_data)\n",
        "        val_loss = loss_fn(output, val_labels)\n",
        "        output = dnet(train_data)\n",
        "        t_loss = loss_fn(output,train_labels)\n",
        "\n",
        "        if val_loss < min_val_loss:\n",
        "            min_val_loss = val_loss\n",
        "            steps_no_improve = 0\n",
        "            min_step = steps\n",
        "            #save model here\n",
        "        else:\n",
        "            steps_no_improve += 1\n",
        "            if steps_no_improve == patience:\n",
        "                print(f'Early stopping! min step : {min_step}')\n",
        "                break  # Early stop\n",
        "\n",
        "\n",
        "        t_losses.append(t_loss.item())\n",
        "        val_losses.append(val_loss.item())\n",
        "        # print(f\"{steps} val_loss: {val_loss.item()}, train_loss: {t_loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJw6Bp9XX3T9",
        "outputId": "cc8f2808-55e1-4f54-a5b0-1066789e6742"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping! min step : 22520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assumes `t_losses` and `val_losses` are lists of loss values\n",
        "plt.plot(t_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.xlabel('Steps (x100)')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "mMiTbLkDX5Jm",
        "outputId": "36eb71ce-ab8b-454f-d460-8649cc5d46b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}